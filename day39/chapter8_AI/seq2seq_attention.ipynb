{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.10.3\n",
      "numpy 1.26.4\n",
      "pandas 2.3.0\n",
      "sklearn 1.7.0\n",
      "torch 2.7.1+cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82b4e9",
   "metadata": {},
   "source": [
    "# 1. preprocessing data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e324758",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf6cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May I borrow, this book?\n",
      "¿Puedo tomar prestado este libro?\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "#因为西班牙语有一些是特殊字符，所以我们需要unicode转ascii，\n",
    "# 这样值变小了，因为unicode太大\n",
    "def unicode_to_ascii(s):\n",
    "    #NFD是转换方法，把每一个字节拆开，Mn是重音，所以去除\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "#下面我们找个样本测试一下\n",
    "# 加u代表对字符串进行unicode编码\n",
    "en_sentence = u\"May I borrow, this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "\n",
    "print(unicode_to_ascii(en_sentence))\n",
    "print(unicode_to_ascii(sp_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52ca34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may i borrow , this book ?\n",
      "¿ puedo tomar prestado este libro ?\n",
      "b'\\xc2\\xbf puedo tomar prestado este libro ?'\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(w):\n",
    "    #变为小写，去掉多余的空格，变成小写，id少一些\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # 在单词与跟在其后的标点符号之间插入一个空格\n",
    "    # eg: \"he is a boy.\" => \"he is a boy . \"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "\n",
    "\n",
    "    # 除了 (a-z, A-Z, \".\", \"?\", \"!\", \",\")，将所有字符替换为空格，你可以保留一些标点符号\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    #因为可能有多余空格，替换为一个空格，所以处理一下\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    w = w.strip() #strip是去掉两边的空格\n",
    "\n",
    "    return w\n",
    "\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))  #¿是占用两个字节的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7670c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'test', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'train', 'train', 'train', 'test', 'train', 'train',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'train', 'train', 'train', 'train', 'test', 'test',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'test', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'test', 'train', 'test', 'train', 'train', 'test',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'test',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'train', 'train', 'train', 'train', 'train', 'train',\n",
       "       'train', 'train'], dtype='<U5')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#划分训练集和测试集的一个方法\n",
    "split_index1 = np.random.choice(a=[\"train\", \"test\"], replace=True, p=[0.9, 0.1], size=100)\n",
    "split_index1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc5e69",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915b8809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从缓存文件加载train数据...\n",
      "从缓存文件加载test数据...\n"
     ]
    }
   ],
   "source": [
    "# 创建一个继承自torch.utils.data.Dataset的数据集类\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    用于加载和处理英语-西班牙语翻译数据集的自定义Dataset类\n",
    "    参数:\n",
    "        path: 数据文件路径\n",
    "        num_examples: 要使用的样本数量，None表示使用全部\n",
    "        split: 数据集划分，可选'train'或'test'\n",
    "    \"\"\"\n",
    "    def __init__(self, path, num_examples=None, split=None):\n",
    "        # 检查是否存在缓存文件\n",
    "        cache_file_en = f'{split}_en_sentences.npy' if split else 'all_en_sentences.npy'\n",
    "        cache_file_sp = f'{split}_sp_sentences.npy' if split else 'all_sp_sentences.npy'\n",
    "        \n",
    "        # 如果缓存文件存在，直接加载\n",
    "        if os.path.exists(cache_file_en) and os.path.exists(cache_file_sp):\n",
    "            print(f\"从缓存文件加载{split}数据...\")\n",
    "            self.trg = np.load(cache_file_en)\n",
    "            self.src = np.load(cache_file_sp)\n",
    "        else:\n",
    "            print(f\"从{path}读取数据并创建{split}数据集...\")\n",
    "            # 读取文件\n",
    "            lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "            \n",
    "            # 创建空列表存储英语和西班牙语句子对\n",
    "            self.en_sentences = []\n",
    "            self.sp_sentences = []\n",
    "            \n",
    "            # 生成训练集和测试集的索引,如果num_examples为None，则使用所有行，否则使用num_examples行\n",
    "            total_examples = len(lines) if num_examples is None else min(num_examples, len(lines)) \n",
    "            # 使用9:1的比例划分训练集和测试集\n",
    "            split_index = np.random.choice(a=[\"train\", \"test\"], replace=True, p=[0.9, 0.1], size=total_examples)\n",
    "            \n",
    "            # 遍历每一行，按tab分隔英语和西班牙语\n",
    "            for i, line in enumerate(lines[:total_examples]):\n",
    "                # 如果指定了split，则只保留对应的数据\n",
    "                if split is not None and split_index[i] != split:\n",
    "                    continue\n",
    "                    \n",
    "                # 按tab分隔获取英语和西班牙语句子\n",
    "                en, sp = line.split('\\t')\n",
    "                \n",
    "                # 对句子进行预处理（清理、标准化等）\n",
    "                en = preprocess_sentence(en)\n",
    "                sp = preprocess_sentence(sp)\n",
    "                \n",
    "                # 将处理后的句子添加到对应列表\n",
    "                self.en_sentences.append(en)\n",
    "                self.sp_sentences.append(sp)\n",
    "            \n",
    "            # 转换为numpy数组以提高效率\n",
    "            self.trg = np.array(self.en_sentences) #英语(目标语言)\n",
    "            self.src = np.array(self.sp_sentences) #西班牙语(源语言)\n",
    "            \n",
    "            # 将处理后的数据保存为numpy文件以加速后续加载\n",
    "            np.save(cache_file_en, self.trg)\n",
    "            np.save(cache_file_sp, self.src)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集中的样本数量\"\"\"\n",
    "        return len(self.trg)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"返回指定索引的源语言和目标语言句子对\"\"\"\n",
    "        return self.src[idx],self.trg[idx]\n",
    "    \n",
    "\n",
    "# 从spa.txt创建训练集和测试集\n",
    "train_dataset = TranslationDataset('spa.txt', split='train')  # 创建训练数据集\n",
    "test_dataset = TranslationDataset('spa.txt', split='test')    # 创建测试数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ffe83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado .\n",
      "target: if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo .\n"
     ]
    }
   ],
   "source": [
    "print(\"source: {}\\ntarget: {}\".format(*train_dataset[-1])) # print the last training example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b17140",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c973165",
   "metadata": {},
   "source": [
    "这里有两种处理方式，分别对应着 encoder 和 decoder 的 word embedding 是否共享，这里实现不共享的方案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04dc44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(sentences_pairs):\n",
    "    \"\"\"\n",
    "    构建英语和西班牙语的词典\n",
    "    Args:\n",
    "        sentences_pairs: 包含英语和西班牙语句子对的列表\n",
    "    Returns:\n",
    "        en_vocab: 英语词典\n",
    "        sp_vocab: 西班牙语词典\n",
    "    \"\"\"\n",
    "    # 分别存储英语和西班牙语的单词\n",
    "    en_words = []\n",
    "    sp_words = []\n",
    "    \n",
    "    # 遍历所有句子对，分别提取单词\n",
    "    for en, sp in sentences_pairs:\n",
    "        en_words.extend(en.split())\n",
    "        sp_words.extend(sp.split())\n",
    "    \n",
    "    # 使用Counter统计词频\n",
    "    en_vocab = Counter(en_words)\n",
    "    sp_vocab = Counter(sp_words)\n",
    "    \n",
    "    return en_vocab, sp_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07575987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英语词典大小: 12504\n",
      "西班牙语词典大小: 23719\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# 构建英语和西班牙语的词典\n",
    "def build_vocab(sentences, min_freq=1):\n",
    "    \"\"\"\n",
    "    构建词典函数\n",
    "    参数:\n",
    "        sentences: 句子列表\n",
    "        min_freq: 最小词频,默认为1\n",
    "    返回:\n",
    "        word2idx: 词到索引的映射字典\n",
    "    \"\"\"\n",
    "    # 初始化词典，包含特殊标记\n",
    "    word2idx = {\n",
    "        \"[PAD]\": 0,     # 填充 token\n",
    "        \"[BOS]\": 1,     # begin of sentence\n",
    "        \"[UNK]\": 2,     # 未知 token\n",
    "        \"[EOS]\": 3,     # end of sentence\n",
    "    }\n",
    "    \n",
    "    # 使用Counter统计词频\n",
    "    # Counter类可以自动统计可迭代对象中每个元素出现的次数\n",
    "    counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        counter.update(sentence.split())  # split()将句子分割成单词列表\n",
    "    \n",
    "    # 按词频排序并添加到词典中\n",
    "    idx = len(word2idx)  # 从特殊标记数量开始编号\n",
    "    # 返回计数最高的前 n 个元素及其计数，若未指定 n 则返回所有元素\n",
    "    for word, count in counter.most_common():\n",
    "        # 只添加频率大于等于min_freq的词\n",
    "        if count >= min_freq:\n",
    "            word2idx[word] = idx\n",
    "            idx += 1\n",
    "    \n",
    "    return word2idx\n",
    "\n",
    "# 构建英语(目标语言)和西班牙语(源语言)词典\n",
    "# trg代表target(目标), src代表source(源)\n",
    "trg_word2idx = build_vocab(train_dataset.trg) #英语\n",
    "src_word2idx = build_vocab(train_dataset.src) #西班牙语\n",
    "\n",
    "# 创建反向映射（索引到词）\n",
    "# 用于之后将模型输出的索引转换回单词\n",
    "trg_idx2word = {idx: word for word, idx in trg_word2idx.items()}\n",
    "src_idx2word = {idx: word for word, idx in src_word2idx.items()}\n",
    "# 打印词典大小，用于检查词典构建是否正确\n",
    "print(f\"英语词典大小: {len(trg_word2idx)}\")\n",
    "print(f\"西班牙语词典大小: {len(src_word2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c175fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_text----------\n",
      "['hello', 'world']\n",
      "['tokenize', 'text', 'datas', 'with', 'batch']\n",
      "['this', 'is', 'a', 'test']\n",
      "mask----------\n",
      "tensor([0, 0, 0, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1])\n",
      "indices----------\n",
      "tensor([   1, 1745,  309,    3,    0,    0,    0])\n",
      "tensor([   1,    2, 2103,    2,   39,    2,    3])\n",
      "tensor([  1,  23,  12,  10, 924,   3,   0])\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, word2idx, idx2word, max_length=500, pad_idx=0, bos_idx=1, eos_idx=3, unk_idx=2):\n",
    "        self.word2idx = word2idx  # 词到索引的映射字典\n",
    "        self.idx2word = idx2word  # 索引到词的映射字典\n",
    "        self.max_length = max_length  # 序列的最大长度\n",
    "        self.pad_idx = pad_idx  # 填充标记的索引\n",
    "        self.bos_idx = bos_idx  # 句子开始标记的索引\n",
    "        self.eos_idx = eos_idx  # 句子结束标记的索引\n",
    "        self.unk_idx = unk_idx  # 未知词标记的索引\n",
    "\n",
    "    def encode(self, text_list, padding_first=False, add_bos=True, add_eos=True, return_mask=False):\n",
    "        \"\"\"如果padding_first == True，则padding加载前面，否则加载后面\n",
    "        return_mask: 是否返回mask(掩码），mask用于指示哪些是padding的，哪些是真实的token\n",
    "        \"\"\"\n",
    "        max_length = min(self.max_length, add_eos + add_bos + max([len(text) for text in text_list]))  # 计算实际需要的最大长度\n",
    "        indices_list = []  # 初始化索引列表\n",
    "        for text in text_list:  # 遍历每个文本\n",
    "            indices = [self.word2idx.get(word, self.unk_idx) for word in text[:max_length - add_bos - add_eos]]  # 将文本中的词转换为索引，如果词不在词表中则使用unk_idx\n",
    "            if add_bos:  # 如果需要添加句子开始标记\n",
    "                indices = [self.bos_idx] + indices  # 在序列开头添加BOS标记\n",
    "            if add_eos:  # 如果需要添加句子结束标记\n",
    "                indices = indices + [self.eos_idx]  # 在序列末尾添加EOS标记\n",
    "            if padding_first:  # 如果padding需要加在前面\n",
    "                indices = [self.pad_idx] * (max_length - len(indices)) + indices  # 在序列前面添加padding\n",
    "            else:  # 如果padding需要加在后面\n",
    "                indices = indices + [self.pad_idx] * (max_length - len(indices))  # 在序列后面添加padding\n",
    "            indices_list.append(indices)  # 将处理后的索引添加到列表中\n",
    "        input_ids = torch.tensor(indices_list)  # 将索引列表转换为tensor\n",
    "        masks = (input_ids == self.pad_idx).to(dtype=torch.int64)  # 创建mask，1表示padding位置，0表示实际token位置\n",
    "        return input_ids if not return_mask else (input_ids, masks)  # 根据return_mask参数决定返回值\n",
    "\n",
    "    def decode(self, indices_list, remove_bos=True, remove_eos=True, remove_pad=True, split=False):\n",
    "        text_list = []  # 初始化文本列表\n",
    "        for indices in indices_list:  # 遍历每个索引序列\n",
    "            text = []  # 初始化当前文本\n",
    "            for index in indices:  # 遍历序列中的每个索引\n",
    "                word = self.idx2word.get(index, \"[UNK]\")  # 将索引转换为词，如果索引不在词表中则使用\"[UNK]\"\n",
    "                if remove_bos and word == \"[BOS]\":  # 如果需要移除BOS标记且当前词是BOS\n",
    "                    continue  # 跳过这个词\n",
    "                if remove_eos and word == \"[EOS]\":  # 如果需要移除EOS标记且当前词是EOS\n",
    "                    break  # 结束当前序列的处理\n",
    "                if remove_pad and word == \"[PAD]\":  # 如果需要移除PAD标记且当前词是PAD\n",
    "                    break  # 结束当前序列的处理\n",
    "                text.append(word)  # 将词添加到当前文本中\n",
    "            text_list.append(\" \".join(text) if not split else text)  # 根据split参数决定返回连接后的字符串还是词列表\n",
    "        return text_list  # 返回处理后的文本列表\n",
    "\n",
    "# 两个相对于1个tokenizer的好处是embedding的参数量减少\n",
    "src_tokenizer = Tokenizer(word2idx=src_word2idx, idx2word=src_idx2word)  # 创建源语言(西班牙语)的tokenizer\n",
    "trg_tokenizer = Tokenizer(word2idx=trg_word2idx, idx2word=trg_idx2word)  # 创建目标语言(英语)的tokenizer\n",
    "\n",
    "batch_text = [\"hello world\".split(), \"tokenize text datas with batch\".split(), \"this is a test\".split()]\n",
    "indices,mask = trg_tokenizer.encode(batch_text, padding_first=False, add_bos=True, add_eos=True,return_mask=True)\n",
    "\n",
    "print(\"batch_text\"+'-'*10)\n",
    "for raw in batch_text:\n",
    "    print(raw)\n",
    "print(\"mask\"+'-'*10)\n",
    "for m in mask:\n",
    "    print(m)\n",
    "print(\"indices\"+'-'*10)\n",
    "for index in indices:\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de27713",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38104f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    数据批处理函数\n",
    "    \n",
    "    Args:\n",
    "        batch: 批次数据\n",
    "        src_tokenizer: 源语言tokenizer\n",
    "        trg_tokenizer: 目标语言tokenizer\n",
    "        device: 设备，如果指定则将tensor移至该设备\n",
    "    \n",
    "    Returns:\n",
    "        包含编码后的tensor的字典\n",
    "    \"\"\"\n",
    "    src_texts = [pair[0].split() for pair in batch] #取batch内第0列进行分词，赋给src_words\n",
    "    trg_texts = [pair[1].split() for pair in batch] #取batch内第1列进行分词，赋给trg_words\n",
    "    \n",
    "    # 编码源语言输入\n",
    "    encoder_inputs, encoder_inputs_mask = src_tokenizer.encode(\n",
    "        src_texts, \n",
    "        padding_first=True, #padding加在前面\n",
    "        add_bos=True, \n",
    "        add_eos=True, \n",
    "        return_mask=True\n",
    "    )\n",
    "    \n",
    "    # 编码目标语言输入（用于训练时的teacher forcing）\n",
    "    decoder_inputs= trg_tokenizer.encode(\n",
    "        trg_texts, \n",
    "        padding_first=False, #padding加在后面\n",
    "        add_bos=True, \n",
    "        add_eos=False, \n",
    "        return_mask=False\n",
    "    )\n",
    "    \n",
    "    # 编码目标语言标签（用于计算损失）\n",
    "    decoder_labels, decoder_labels_mask = trg_tokenizer.encode(\n",
    "        trg_texts, \n",
    "        padding_first=False, \n",
    "        add_bos=False, \n",
    "        add_eos=True, \n",
    "        return_mask=True\n",
    "    )\n",
    "    \n",
    "    result = {\n",
    "        \"encoder_inputs\": encoder_inputs,\n",
    "        \"encoder_inputs_mask\": encoder_inputs_mask,\n",
    "        \"decoder_inputs\": decoder_inputs,\n",
    "        \"decoder_labels\": decoder_labels,\n",
    "        \"decoder_labels_mask\": decoder_labels_mask\n",
    "    }\n",
    "    \n",
    "    # 如果指定了设备，将所有tensor移至该设备\n",
    "    if device is not None:\n",
    "        result = {k: v.to(device=device) for k, v in result.items()}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "194e457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs\n",
      "tensor([[   0,    1,   17,    6,   72,   15,    7,    4,    3],\n",
      "        [   1,   10, 3919,    7, 1753,  142, 2999,    4,    3]])\n",
      "encoder_inputs_mask\n",
      "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "decoder_inputs\n",
      "tensor([[   1,    5,   46,   91,   14,  494,   71,    4,    0],\n",
      "        [   1,    9, 2038,    6, 2008,  261,  373,   15,    4]])\n",
      "decoder_labels\n",
      "tensor([[   5,   46,   91,   14,  494,   71,    4,    3,    0],\n",
      "        [   9, 2038,    6, 2008,  261,  373,   15,    4,    3]])\n",
      "decoder_labels_mask\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "sample_dl = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "#两次执行这个代码效果不一样，因为每次执行都会shuffle\n",
    "for batch in sample_dl:\n",
    "    for key, value in batch.items():\n",
    "        print(key)\n",
    "        print(value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc3fd4",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2829d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    序列到序列模型的编码器部分\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1, dropout=0.0):\n",
    "        \"\"\"\n",
    "        初始化编码器\n",
    "        \n",
    "        参数:\n",
    "        - vocab_size: 源语言词汇表大小\n",
    "        - embedding_dim: 词嵌入维度\n",
    "        - hidden_size: 隐藏状态维度\n",
    "        - num_layers: GRU层数\n",
    "        - dropout: Dropout比率\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 词嵌入层 - 将输入的词索引转换为密集向量表示\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # GRU层,batch_first=True表示输入的形状为[batch_size, seq_len]\n",
    "        # GRU是LSTM的简化版本,只有两个门控单元(更新门和重置门)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,  # 输入维度,等于词嵌入维度\n",
    "            hidden_size=hidden_size,   # 隐藏状态维度\n",
    "            num_layers=num_layers,     # GRU层数,可以堆叠多层\n",
    "            batch_first=True,          # 输入张量的第一个维度是batch_size\n",
    "            dropout=dropout if num_layers > 1 else 0  # 多层时才在层间使用dropout\n",
    "        )\n",
    "        \n",
    "        # dropout层 - 用于防止过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 保存配置参数供其他地方使用\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "    def forward(self, src, src_mask=None, src_lengths=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        参数:\n",
    "        - src: 源语言序列 [batch_size, seq_len]\n",
    "        - src_mask: 源语言序列的掩码 [batch_size, seq_len]\n",
    "        - src_lengths: 源语言序列的实际长度 [batch_size]\n",
    "        \n",
    "        返回:\n",
    "        - encoder_outputs: 编码器所有时间步的输出 [batch_size, seq_len, hidden_size]\n",
    "        - hidden: 解码器初始隐藏状态 [num_layers, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        # 词嵌入并应用dropout正则化\n",
    "        embedded = self.dropout(self.embedding(src))  #[batch_size, seq_len] -> [batch_size, seq_len, embedding_dim]\n",
    "        \n",
    "        # 通过GRU层处理序列\n",
    "        # GRU的两个输出:\n",
    "        # 1. encoder_outputs包含每个时间步的隐藏状态,用于注意力机制\n",
    "        # 2. hidden是最后一个时间步的隐藏状态,用作解码器的初始状态\n",
    "        # 通过GRU\n",
    "        #[batch_size, seq_len, embedding_dim]-> encoder_outputs [batch_size, seq_len, hidden_dim]\n",
    "        #[batch_size, seq_len, embedding_dim]-> hidden [num_layers, batch_size, hidden_dim]\n",
    "        encoder_outputs, hidden = self.gru(embedded) \n",
    "        \n",
    "        # 返回编码器所有时间步的输出和解码器初始隐藏状态\n",
    "        return encoder_outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fee7b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源序列形状: torch.Size([64, 20])\n",
      "编码器输出形状: torch.Size([64, 20, 512])\n",
      "隐藏状态形状: torch.Size([2, 64, 512])\n",
      "Encoder测试通过!\n"
     ]
    }
   ],
   "source": [
    "# 测试Encoder\n",
    "import torch\n",
    "\n",
    "# 创建测试参数\n",
    "vocab_size = len(src_tokenizer.word2idx)\n",
    "embedding_dim = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "batch_size = 64\n",
    "seq_len = 20\n",
    "\n",
    "# 实例化Encoder\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_size, num_layers, dropout)\n",
    "\n",
    "# 创建测试输入\n",
    "src = torch.randint(0, vocab_size, (batch_size, seq_len))  # [batch_size, seq_len]\n",
    "\n",
    "# 前向传播\n",
    "encoder_outputs, hidden = encoder(src)\n",
    "\n",
    "# 打印输出形状\n",
    "print(f\"源序列形状: {src.shape}\")\n",
    "print(f\"编码器输出形状: {encoder_outputs.shape}\")\n",
    "print(f\"隐藏状态形状: {hidden.shape}\")\n",
    "\n",
    "# 验证输出维度是否符合预期\n",
    "assert encoder_outputs.shape == (batch_size, seq_len, hidden_size)\n",
    "assert hidden.shape == (num_layers, batch_size, hidden_size)\n",
    "\n",
    "print(\"Encoder测试通过!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493b22a",
   "metadata": {},
   "source": [
    "# Bahdanau注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "990d9a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., -inf, -inf]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟 logits 和 mask\n",
    "logits = torch.tensor([[1.0, 2.0, 3.0, 4.0]])\n",
    "mask = torch.tensor([[1, 1, 0, 0]])  # 只让前两个位置有效\n",
    "\n",
    "# 把无效位置设为 -inf\n",
    "masked_logits = logits.masked_fill(mask == 0, float('-inf'))\n",
    "masked_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e9e931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bahdanau注意力机制\n",
    "    \n",
    "    参数:\n",
    "        hidden_size: 隐藏状态的维度\n",
    "        key_size: 键向量的维度（如果与隐藏状态不同）\n",
    "        value_size: 值向量的维度（如果与隐藏状态不同）\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, key_size=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 如果key_size和value_size未指定，则默认与hidden_size相同\n",
    "        if key_size is None:\n",
    "            key_size = hidden_size\n",
    "            \n",
    "        # 定义注意力层\n",
    "        self.Wq = nn.Linear(hidden_size, hidden_size)  \n",
    "        self.Wk = nn.Linear(key_size, hidden_size)  \n",
    "        self.V = nn.Linear(hidden_size, 1, bias=False)  \n",
    "        \n",
    "    def forward(self, query, keys, values, attn_mask=None):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "            query:decoder的隐藏状态 查询向量 [batch_size, hidden_size]\n",
    "            keys: EO 键向量 [batch_size, src_len, key_size]\n",
    "            values:EO  值向量 [batch_size, src_len, value_size]\n",
    "            attn_mask: 注意力掩码 [batch_size, src_len]\n",
    "            \n",
    "        返回:\n",
    "            context: 上下文向量 [batch_size, value_size]\n",
    "            attention_weights: 注意力权重 [batch_size, src_len]\n",
    "        \"\"\"\n",
    "        src_len = keys.size(1)  # 输入序列的长度\n",
    "        \n",
    "        # 将query从[batch_size, hidden_size]转换为[batch_size, 1, hidden_size]\n",
    "        query = self.Wq(query).unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        # 转换keys,shape=[batch_size, src_len, hidden_size]\n",
    "        keys = self.Wk(keys)\n",
    "        \n",
    "        # 计算注意力分数\n",
    "        energy = torch.tanh(keys+query)\n",
    "        # [batch_size, src_len, hidden_size] -> [batch_size, src_len, 1] -> [batch_size, src_len]\n",
    "        attention = self.V(energy).squeeze(2) \n",
    "        \n",
    "        # 应用注意力掩码（如果提供）\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask * -1e16 \n",
    "            attention += attn_mask #加上一个负无穷，让padding部分经过softmax后为0\n",
    "        \n",
    "        # 使用softmax归一化注意力权重  [batch_size, src_len]\n",
    "        attention_weights = F.softmax(attention, dim=1)\n",
    "        \n",
    "        # 计算上下文向量,values是EO,shape=[batch_size, src_len, hidden_dim]\n",
    "        context_vector = torch.mul(attention_weights.unsqueeze(-1), values).sum(dim=1) #对每一个词的score和对应的value做乘法，然后在seq_len维度上求和，得到context_vector\n",
    "        # context_vector.shape = [batch size, hidden_dim]\n",
    "        #attention_weights用于最后的画图\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79afe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query shape: torch.Size([2, 8])\n",
      "Keys shape: torch.Size([2, 4, 8])\n",
      "Values shape: torch.Size([2, 4, 8])\n",
      "Context vector shape: torch.Size([2, 8])\n",
      "Attention weights shape: torch.Size([2, 4])\n",
      "\n",
      "Attention weights:\n",
      "tensor([[0.0000, 0.3741, 0.3568, 0.2692],\n",
      "        [0.2865, 0.2280, 0.2505, 0.2350]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试BahdanauAttention\n",
    "def test_bahdanau_attention():\n",
    "    # 设置参数\n",
    "    batch_size = 2\n",
    "    hidden_size = 8\n",
    "    src_len = 4\n",
    "    \n",
    "    # 创建输入数据\n",
    "    query = torch.randn(batch_size, hidden_size)  # Decoder的隐藏状态\n",
    "    keys = torch.randn(batch_size, src_len, hidden_size)  # Encoder输出\n",
    "    values = torch.randn(batch_size, src_len, hidden_size)  # 通常与keys相同\n",
    "    \n",
    "    # 创建注意力掩码，模拟序列填充的情况\n",
    "    attn_mask = torch.zeros(batch_size, src_len)\n",
    "    attn_mask[0, 0] = 1  # 假设第一个样本的最后一个token是padding\n",
    "    # attn_mask[1, 2:] = 1  # 假设第二个样本的最后两个tokens是padding\n",
    "    \n",
    "    # 初始化Bahdanau注意力机制\n",
    "    attention = BahdanauAttention(hidden_size, hidden_size)\n",
    "    \n",
    "    # 前向传播\n",
    "    context, attn_weights = attention(query, keys, values, attn_mask)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"Query shape: {query.shape}\") # (batch_size, hidden_size)\n",
    "    print(f\"Keys shape: {keys.shape}\") # (batch_size, src_len, hidden_size)\n",
    "    print(f\"Values shape: {values.shape}\") # (batch_size, src_len, hidden_size)\n",
    "    print(f\"Context vector shape: {context.shape}\") # (batch_size, hidden_size)\n",
    "    print(f\"Attention weights shape: {attn_weights.shape}\") # (batch_size, src_len)\n",
    "    \n",
    "    # 验证注意力权重是否在掩码位置接近于0\n",
    "    print(\"\\nAttention weights:\")\n",
    "    print(attn_weights)\n",
    "    \n",
    "    # 可视化注意力权重\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(attn_weights.detach().numpy(), cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title('Attention Weights')\n",
    "    plt.xlabel('Source Sequence Position')\n",
    "    plt.ylabel('Batch Sample')\n",
    "    \n",
    "    return context, attn_weights\n",
    "\n",
    "# 运行测试\n",
    "context, attn_weights = test_bahdanau_attention()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7ac23",
   "metadata": {},
   "source": [
    "# Decoder 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79e2e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim=256,\n",
    "        hidden_dim=1024,\n",
    "        num_layers=1,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim + hidden_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size) #最后分类,词典大小是多少，就输出多少个分类\n",
    "        self.dropout = nn.Dropout(0.6) #0.6可以调整的超参数\n",
    "        self.attention = BahdanauAttention(hidden_dim) #注意力得到的context_vector\n",
    "\n",
    "    def forward(self, decoder_input, hidden, encoder_outputs, attn_mask=None):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "            decoder_input: 解码器的输入，形状为 [batch_size, 1]\n",
    "            hidden: 解码器的隐藏状态，形状为 [batch_size, hidden_dim],第一次使用的是encoder的hidden\n",
    "            encoder_outputs: 编码器的输出，形状为 [batch_size, sequence_length, hidden_dim]\n",
    "            attn_mask: 注意力掩码，形状为 [batch_size, sequence_length],是encoder_inputs_mask\n",
    "        \n",
    "        返回:\n",
    "            logits: 解码器的输出，形状为 [batch_size, 1, vocab_size]\n",
    "            hidden: 解码器的隐藏状态，形状为 [batch_size, hidden_dim]\n",
    "            attention_score: 注意力权重，形状为 [batch_size, sequence_length, 1]\n",
    "        \"\"\"\n",
    "        #断言，确保输入的形状是正确的\n",
    "        # decoder_input.shape = [batch size, 1]\n",
    "        assert len(decoder_input.shape) == 2 and decoder_input.shape[-1] == 1, f\"decoder_input.shape = {decoder_input.shape} is not valid\"\n",
    "        # hidden.shape = [num_layers, batch size, hidden_dim]，decoder_hidden,而第一次使用的是encoder的hidden\n",
    "        assert len(hidden.shape) == 3, f\"hidden.shape = {hidden.shape} is not valid\"\n",
    "        # encoder_outputs.shape = [batch size, sequence length, hidden_dim]\n",
    "        assert len(encoder_outputs.shape) == 3, f\"encoder_outputs.shape = {encoder_outputs.shape} is not valid\"\n",
    "        # context_vector.shape = [batch_size, hidden_dim]\n",
    "        \n",
    "        # 注意力机制\n",
    "        context_vector, attention_score = self.attention(\n",
    "            query=hidden[-1], keys=encoder_outputs, values=encoder_outputs, attn_mask=attn_mask)\n",
    "        # decoder_input.shape = [batch size, 1]-->embeds.shape = [batch size, 1, embedding_dim]\n",
    "        embeds = self.embedding(decoder_input)\n",
    "\n",
    "        # context_vector.shape = [batch size, hidden_dim] -->unsqueeze(-2)增加维度 [batch size, 1, hidden_dim]\n",
    "        embeds = torch.cat([context_vector.unsqueeze(-2), embeds], dim=-1)\n",
    "        # 新的embeds.shape = [batch size, 1, embedding_dim + hidden_dim]\n",
    "        seq_output, hidden = self.gru(embeds, hidden) #这里可以把hidden去掉对比一下最终的bleu指标\n",
    "        # seq_output.shape = [batch size, 1, hidden_dim]\n",
    "        logits = self.fc(self.dropout(seq_output))\n",
    "        # logits.shape = [batch size, 1, vocab size]，attention_score = [batch size, sequence length, 1]\n",
    "        return logits, hidden, attention_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13078c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_input.shape: torch.Size([2, 1])\n",
      "decoder_hidden.shape: torch.Size([1, 2, 32])\n",
      "encoder_outputs.shape: torch.Size([2, 5, 32])\n",
      "logits.shape: torch.Size([2, 1, 1000])\n",
      "hidden.shape: torch.Size([1, 2, 32])\n",
      "attention_score.shape: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "# 前向计算验证Decoder是否ok\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "hidden_dim = 32\n",
    "vocab_size = 1000\n",
    "embedding_dim = 64\n",
    "num_layers = 1\n",
    "\n",
    "# 创建模拟数据\n",
    "decoder_input = torch.randint(0, vocab_size, (batch_size, 1))  # [batch_size, 1]\n",
    "decoder_hidden = torch.randn(num_layers, batch_size, hidden_dim)  # [num_layers, batch_size, hidden_dim]\n",
    "encoder_outputs = torch.randn(batch_size, seq_len, hidden_dim)  # [batch_size, seq_len, hidden_dim]\n",
    "attn_mask = torch.ones(batch_size, seq_len)  # [batch_size, seq_len]\n",
    "\n",
    "# 创建Decoder模型\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_dim)\n",
    "\n",
    "# 前向计算\n",
    "logits, hidden, attention_score = decoder(decoder_input, decoder_hidden, encoder_outputs, attn_mask)\n",
    "\n",
    "# 打印输出形状\n",
    "print(f\"decoder_input.shape: {decoder_input.shape}\")  # [batch_size, 1]\n",
    "print(f\"decoder_hidden.shape: {decoder_hidden.shape}\")  # [num_layers, batch_size, hidden_dim]\n",
    "print(f\"encoder_outputs.shape: {encoder_outputs.shape}\")  # [batch_size, seq_len, hidden_dim]\n",
    "print(f\"logits.shape: {logits.shape}\")  # [batch_size, vocab_size]\n",
    "print(f\"hidden.shape: {hidden.shape}\")  # [num_layers, batch_size, hidden_dim]\n",
    "print(f\"attention_score.shape: {attention_score.shape}\")  # [batch_size, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6633ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_vocab_size, output_vocab_size, embedding_dim, hidden_dim, num_layers=1, bidirectional=False, dropout=0.1):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "        # 如果是双向的，则Decoder的hidden_dim是encoder的两倍\n",
    "        decoder_hidden_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.decoder = Decoder(output_vocab_size, embedding_dim, decoder_hidden_dim, num_layers)\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask=None, teacher_forcing_ratio=0.5):\n",
    "        # src: [batch_size, src_len]\n",
    "        # tgt: [batch_size, tgt_len]\n",
    "        # src_mask: [batch_size, src_len]\n",
    "        batch_size = src.shape[0]\n",
    "        tgt_len = tgt.shape[1]\n",
    "        \n",
    "        # 编码\n",
    "        encoder_outputs, encoder_hidden = self.encoder(src, src_mask)\n",
    "        \n",
    "        # 初始化解码器输入和隐藏状态\n",
    "        decoder_input = tgt[:, 0:1]  # 使用目标序列的第一个token作为初始输入\n",
    "        # 获取encoder_hidden的最后一层\n",
    "        if len(encoder_hidden.shape) == 3:\n",
    "            # 如果encoder_hidden形状为[num_layers, batch_size, hidden_dim]\n",
    "            decoder_hidden = encoder_hidden[-1]  # 只使用最后一层的隐藏状态\n",
    "        else:\n",
    "            # 如果已经是[batch_size, hidden_dim]\n",
    "            decoder_hidden = encoder_hidden\n",
    "            \n",
    "        # 存储所有解码器输出\n",
    "        outputs = torch.zeros(batch_size, tgt_len, self.output_vocab_size).to(src.device)\n",
    "        attention_scores = torch.zeros(batch_size, tgt_len, src.shape[1]).to(src.device)\n",
    "        \n",
    "        # 逐个时间步解码\n",
    "        for t in range(1, tgt_len):\n",
    "            # 解码器前向传播\n",
    "            decoder_output, decoder_hidden, attention_score = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs, src_mask\n",
    "            )\n",
    "            \n",
    "            # 存储当前输出和注意力分数\n",
    "            outputs[:, t-1:t, :] = decoder_output\n",
    "            attention_scores[:, t-1:t, :] = attention_score\n",
    "            \n",
    "            # 决定是否使用教师强制\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # 获取当前预测的token\n",
    "            top1 = decoder_output.argmax(2)\n",
    "            \n",
    "            # 下一个输入：如果使用教师强制，则使用实际目标；否则使用预测\n",
    "            decoder_input = tgt[:, t:t+1] if teacher_force else top1\n",
    "        \n",
    "        # 处理最后一个时间步\n",
    "        decoder_output, _, attention_score = self.decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs, src_mask\n",
    "        )\n",
    "        outputs[:, -1:, :] = decoder_output\n",
    "        attention_scores[:, -1:, :] = attention_score\n",
    "        \n",
    "        return outputs, attention_scores\n",
    "    \n",
    "    def translate(self, src, src_mask=None, max_len=50, sos_idx=1, eos_idx=3):\n",
    "        \"\"\"\n",
    "        用于推理/翻译\n",
    "        \n",
    "        参数:\n",
    "            src: 源语言输入 [batch_size, src_len]\n",
    "            src_mask: 源语言掩码 [batch_size, src_len]\n",
    "            max_len: 生成的最大长度\n",
    "            sos_idx: 起始符索引\n",
    "            eos_idx: 结束符索引\n",
    "            \n",
    "        返回:\n",
    "            predictions: 预测的目标语言序列 [batch_size, max_len]\n",
    "            attention_scores: 注意力分数 [batch_size, max_len, src_len]\n",
    "        \"\"\"\n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        \n",
    "        # 编码\n",
    "        encoder_outputs, encoder_hidden = self.encoder(src, src_mask)\n",
    "        \n",
    "        # 初始化解码器输入（起始符）\n",
    "        decoder_input = torch.LongTensor([[sos_idx]] * batch_size).to(src.device)\n",
    "        \n",
    "        # 获取encoder_hidden的最后一层\n",
    "        if len(encoder_hidden.shape) == 3:\n",
    "            # 如果encoder_hidden形状为[num_layers, batch_size, hidden_dim]\n",
    "            decoder_hidden = encoder_hidden[-1]  # 只使用最后一层的隐藏状态\n",
    "        else:\n",
    "            # 如果已经是[batch_size, hidden_dim]\n",
    "            decoder_hidden = encoder_hidden\n",
    "        \n",
    "        # 存储预测和注意力分数\n",
    "        predictions = torch.zeros(batch_size, max_len, dtype=torch.long).to(src.device)\n",
    "        attention_scores = torch.zeros(batch_size, max_len, src_len).to(src.device)\n",
    "        \n",
    "        # 记录每个样本是否已完成生成（遇到EOS）\n",
    "        finished = torch.zeros(batch_size, dtype=torch.bool).to(src.device)\n",
    "        \n",
    "        # 逐步解码\n",
    "        for t in range(max_len):\n",
    "            # 解码器前向传播\n",
    "            decoder_output, decoder_hidden, attention_score = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs, src_mask\n",
    "            )\n",
    "            \n",
    "            # 获取当前步的预测和注意力分数\n",
    "            top1 = decoder_output.argmax(2)\n",
    "            predictions[:, t:t+1] = top1\n",
    "            attention_scores[:, t:t+1, :] = attention_score\n",
    "            \n",
    "            # 检查是否所有样本都已完成\n",
    "            finished = finished | (top1.squeeze(1) == eos_idx)\n",
    "            if finished.all():\n",
    "                break\n",
    "                \n",
    "            # 使用当前预测作为下一步的输入\n",
    "            decoder_input = top1\n",
    "            \n",
    "        return predictions, attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84490c4",
   "metadata": {},
   "source": [
    "# Sequence2Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13cf49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size, #输入词典大小\n",
    "        trg_vocab_size, #输出词典大小\n",
    "        encoder_embedding_dim=256, #编码器词嵌入维度\n",
    "        encoder_hidden_dim=1024, #encoder_hidden_dim和decoder_hidden_dim必须相同，是因为BahdanauAttention设计的\n",
    "        encoder_num_layers=1, #编码器LSTM层数\n",
    "        decoder_embedding_dim=256, #解码器词嵌入维度\n",
    "        decoder_hidden_dim=1024, #解码器隐藏层维度\n",
    "        decoder_num_layers=1, #解码器LSTM层数\n",
    "        bos_idx=1, #句子开始符号的索引\n",
    "        eos_idx=3, #句子结束符号的索引\n",
    "        max_length=512, #生成序列的最大长度\n",
    "        device=None, #运行设备(CPU/GPU)\n",
    "        ):\n",
    "        super().__init__()\n",
    "        # 初始化各种参数\n",
    "        self.bos_idx = bos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.max_length = max_length\n",
    "        self.device = device\n",
    "        \n",
    "        # 初始化编码器\n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size,\n",
    "            embedding_dim=encoder_embedding_dim,\n",
    "            hidden_size=encoder_hidden_dim,\n",
    "            num_layers=encoder_num_layers,\n",
    "            )\n",
    "        \n",
    "        # 初始化解码器\n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size,\n",
    "            embedding_dim=decoder_embedding_dim,\n",
    "            hidden_dim=decoder_hidden_dim,\n",
    "            num_layers=decoder_num_layers,\n",
    "            )\n",
    "        \n",
    "    def forward(self, src, decoder_input, src_mask=None, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        训练时的前向传播\n",
    "        \n",
    "        Args:\n",
    "            src: 源序列 [batch_size, src_len]\n",
    "            tgt: 目标序列 [batch_size, tgt_len]\n",
    "            src_mask: 源序列的mask [batch_size, src_len]\n",
    "            teacher_forcing_ratio: 使用teacher forcing的概率\n",
    "            \n",
    "        Returns:\n",
    "            outputs: 所有时间步的输出 [batch_size, tgt_len, vocab_size]\n",
    "        \"\"\"\n",
    "        # 获取batch大小和目标序列长度\n",
    "        batch_size = src.shape[0] \n",
    "        tgt_len = decoder_input.shape[1]\n",
    "        \n",
    "        # 编码器前向传播\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        # 用于存储每个时间步的输出和注意力分数\n",
    "        logits_list = []\n",
    "        scores_list = []\n",
    "        \n",
    "        # 逐个时间步解码\n",
    "        for t in range(tgt_len):\n",
    "            # 解码器前向传播,output.shape = [batch_size, 1, vocab_size]\n",
    "            #attention_scores.shape = [batch_size, src_len, 1]\n",
    "            logits, hidden, attention_scores = self.decoder(decoder_input[:, t:t+1], hidden, encoder_outputs, src_mask) # decoder_input[:, t:t+1] shape (bs,1) hidden shape (num_layers,bs,hidden_dim) encoder_outputs shape (bs,src_len,hidden_dim) src_mask shape (bs,src_len)\n",
    "            \n",
    "            # 收集每个时间步的输出和注意力分数\n",
    "            logits_list.append(logits)\n",
    "            scores_list.append(attention_scores)\n",
    "            \n",
    "        # 返回输出和注意力分数\n",
    "        #scores_list.shape (batch_size, src_len, tgt_len)\n",
    "        return torch.cat(logits_list, dim=-2), torch.cat(scores_list, dim=-1) # cat是进行维度拼接\n",
    "    \n",
    "    @torch.no_grad() # 推理时不需要计算梯度,目的是节省内存\n",
    "    def infer(self, src, src_mask=None):\n",
    "        \"\"\"\n",
    "        推理时的前向传播\n",
    "        \n",
    "        Args:\n",
    "            src: 源序列 [batch_size, src_len]\n",
    "            src_mask: 源序列的mask [batch_size, src_len],一个样本mask没有用，多个样本mask有用\n",
    "            \n",
    "        Returns:\n",
    "            outputs: 生成的序列 [batch_size, max_len]\n",
    "            attention_scores: 注意力分数 [batch_size, src_len, max_len]\n",
    "        \"\"\"\n",
    "        # 获取输入的batch大小和序列长度\n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        \n",
    "        # 编码器前向传播\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        \n",
    "        # 存储生成的序列\n",
    "        outputs = torch.zeros(batch_size, self.max_length).long().to(self.device) #shape (bs, max_length)\n",
    "        \n",
    "        # 第一个解码器输入是特殊的开始符号 shape (bs,1)\n",
    "        decoder_input = torch.tensor([[self.bos_idx]] * batch_size).to(self.device)\n",
    "        \n",
    "        # 记录每个序列是否已经生成了结束符号，shape (bs,)，做结束标记用，如果为True，则表示该序列已经生成了结束符号\n",
    "        finished = torch.zeros(batch_size).bool().to(self.device)\n",
    "        score_list = [] #为了画图，记录注意力分数\n",
    "        \n",
    "        # 自回归生成序列\n",
    "        for t in range(self.max_length):\n",
    "            # 解码器前向传播,output.shape = [batch_size, 1, vocab_size]\n",
    "            output, hidden, scores = self.decoder(decoder_input, hidden, encoder_outputs, src_mask)\n",
    "            \n",
    "            # 存储注意力分数 scores.shape = [batch_size, src_len, 1]\n",
    "            score_list.append(scores)\n",
    "            \n",
    "            # 获取最可能的单词索引\n",
    "            pred = output.argmax(dim=-1) #pred shape (bs,1)\n",
    "            \n",
    "            # 保存预测\n",
    "            outputs[:, t] = pred.squeeze(1) #squeeze(1)是去掉维度为1的维度\n",
    "            \n",
    "            # 如果所有序列都生成了结束符号，则提前结束\n",
    "            finished = finished | (pred.squeeze(1) == self.eos_idx)\n",
    "            if finished.all():#finished.all()是判断finished是否全为True\n",
    "                break\n",
    "                \n",
    "            # 使用当前预测作为下一个输入\n",
    "            decoder_input = pred\n",
    "            \n",
    "        return outputs, torch.cat(score_list, dim=-1) #cat是进行维度拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "920c7b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 60, 12504])\n",
      "torch.Size([2, 3000])\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(src_vocab_size=len(src_word2idx), trg_vocab_size=len(trg_word2idx))\n",
    "#做model的前向传播，看看输出的shape\n",
    "encoder_inputs = torch.randint(0, 100, (2, 50)) #shape (bs, src_len) (2,50)\n",
    "decoder_inputs = torch.randint(0, 100, (2, 60)) #shape (bs, tgt_len) (2,60)\n",
    "attn_mask = torch.randint(0, 2, (2, 50)) #shape (bs, src_len) (2,50)\n",
    "logits, scores = model(src=encoder_inputs, decoder_input=decoder_inputs, src_mask=attn_mask)\n",
    "print(logits.shape)\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d8ed5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数量: 35,212,248\n",
      "编码器参数量: 10,010,368 (28.43%)\n",
      "解码器参数量: 25,201,880 (71.57%)\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的参数量\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# 统计总参数量\n",
    "total_params = count_parameters(model)\n",
    "print(f\"模型总参数量: {total_params:,}\")\n",
    "\n",
    "# 统计每个组件的参数量\n",
    "encoder_params = count_parameters(model.encoder)\n",
    "decoder_params = count_parameters(model.decoder)\n",
    "\n",
    "print(f\"编码器参数量: {encoder_params:,} ({encoder_params/total_params:.2%})\")\n",
    "print(f\"解码器参数量: {decoder_params:,} ({decoder_params/total_params:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9381e296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4层模型总参数量: 72,997,848\n",
      "4层编码器参数量: 28,903,168 (39.59%)\n",
      "4层解码器参数量: 44,094,680 (60.41%)\n",
      "\n",
      "参数量增加: 37,785,600 (2.07倍)\n"
     ]
    }
   ],
   "source": [
    "# 创建具有4层的模型\n",
    "model_4layers = Seq2Seq(\n",
    "    src_vocab_size=len(src_word2idx),\n",
    "    trg_vocab_size=len(trg_word2idx),\n",
    "    encoder_num_layers=4,  # 编码器4层\n",
    "    decoder_num_layers=4   # 解码器4层\n",
    ")\n",
    "\n",
    "# 统计总参数量\n",
    "total_params_4layers = count_parameters(model_4layers)\n",
    "print(f\"4层模型总参数量: {total_params_4layers:,}\")\n",
    "\n",
    "# 统计每个组件的参数量\n",
    "encoder_params_4layers = count_parameters(model_4layers.encoder)\n",
    "decoder_params_4layers = count_parameters(model_4layers.decoder)\n",
    "\n",
    "print(f\"4层编码器参数量: {encoder_params_4layers:,} ({encoder_params_4layers/total_params_4layers:.2%})\")\n",
    "print(f\"4层解码器参数量: {decoder_params_4layers:,} ({decoder_params_4layers/total_params_4layers:.2%})\")\n",
    "\n",
    "# 与默认层数模型比较\n",
    "print(f\"\\n参数量增加: {total_params_4layers - total_params:,} ({total_params_4layers/total_params:.2f}倍)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3485df3",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ebfc686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义计算损失的函数，通过mask忽略特定位置\n",
    "def cross_entropy_with_padding(logits, labels, padding_mask=None):\n",
    "    # logits.shape = [batch size, sequence length, num of classes]\n",
    "    # labels.shape = [batch size, sequence length]\n",
    "    # padding_mask.shape = [batch size, sequence length] decoder_labels_mask\n",
    "    bs, seq_len, nc = logits.shape\n",
    "    loss = F.cross_entropy(logits.reshape(bs * seq_len, nc), labels.reshape(-1), reduce=False) #reduce=False表示不对batch求平均\n",
    "    if padding_mask is None:#如果没有padding_mask，就直接求平均\n",
    "        loss = loss.mean()\n",
    "    else:\n",
    "        # 如果提供了 padding_mask，则将padding填充部分的损失去除后计算有效损失的均值。首先，通过将 padding_mask reshape 成一维张量，并取 1 减去得到填充掩码。这样填充部分的掩码值变为 1，非填充部分变为 0。将损失张量与填充掩码相乘，这样填充部分的损失就会变为 0。然后，计算非填充部分的损失和（sum）以及非填充部分的掩码数量（sum）作为有效损失的均值计算。(因为上面我们设计的mask的token是0，所以这里是1-padding_mask)\n",
    "        padding_mask = 1 - padding_mask.reshape(-1) #将padding_mask reshape成一维张量，mask部分为0，非mask部分为1\n",
    "        loss = torch.mul(loss, padding_mask).sum() / padding_mask.sum()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37daa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveCheckpointsCallback:\n",
    "    def __init__(self, save_dir, save_step=5000, save_best_only=True):\n",
    "        \"\"\"\n",
    "        每隔save_epoch个epoch保存一次检查点。\n",
    "        在这个实现中我们按照epoch来保存检查点。\n",
    "        通常，使用PyTorch的训练脚本会按步骤评估模型并保存检查点。\n",
    "\n",
    "        参数:\n",
    "            save_dir (str): 保存检查点的目录\n",
    "            save_epoch (int, optional): 保存检查点的频率。默认为1。\n",
    "            save_best_only (bool, optional): 如果为True，只保存最好的模型；否则在每个epoch都保存模型。\n",
    "        \"\"\"\n",
    "        self.save_dir = save_dir\n",
    "        self.save_step = save_step\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_metrics = - np.inf\n",
    "\n",
    "        # 创建保存目录\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.mkdir(self.save_dir)\n",
    "\n",
    "    def __call__(self, step, state_dict, metric=None):\n",
    "        if step % self.save_step > 0:\n",
    "            return\n",
    "\n",
    "        if self.save_best_only:\n",
    "            assert metric is not None\n",
    "            if metric >= self.best_metrics:\n",
    "                # 保存检查点\n",
    "                torch.save(state_dict, os.path.join(self.save_dir, \"best.ckpt\"))\n",
    "                # 更新最佳指标\n",
    "                self.best_metrics = metric\n",
    "        else:\n",
    "            torch.save(state_dict, os.path.join(self.save_dir, f\"{step}.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f61208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopCallback:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        \"\"\"\n",
    "        早停回调类的初始化函数\n",
    "\n",
    "        参数:\n",
    "            patience (int, 可选): 在多少个epoch没有改善后停止训练。默认值为5。\n",
    "            min_delta (float, 可选): 被视为改善的最小变化量。如果变化小于min_delta，\n",
    "                                   则被视为没有改善。默认值为0.01。\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_metric = -np.inf  # 初始化最佳指标为负无穷\n",
    "        self.counter = 0  # 计数器，用于记录连续没有改善的次数\n",
    "\n",
    "    def __call__(self, metric):\n",
    "        if metric >= self.best_metric + self.min_delta:\n",
    "            # 更新最佳指标\n",
    "            self.best_metric = metric\n",
    "            # 重置计数器\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            # 如果没有改善，计数器加1\n",
    "            self.counter += 1\n",
    "\n",
    "    @property  # @property装饰器将方法转换为属性，这样就可以通过实例.early_stop来访问方法，而不是实例.early_stop()\n",
    "    def early_stop(self):\n",
    "        # 如果连续没有改善的次数超过耐心值，则返回True表示应该早停\n",
    "        return self.counter >= self.patience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c729f",
   "metadata": {},
   "source": [
    "# 训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32bf904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_fct):\n",
    "    \"\"\"\n",
    "    在验证/测试集上评估模型\n",
    "\n",
    "    参数:\n",
    "        model: 带有注意力机制的seq2seq模型\n",
    "        dataloader: 验证/测试数据加载器\n",
    "        loss_fct: 损失函数\n",
    "\n",
    "    返回:\n",
    "        float: 在数据集上的平均损失\n",
    "    \"\"\"\n",
    "    model.eval() # 切换到评估模式\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # 解包批次数据\n",
    "            encoder_inputs = batch[\"encoder_inputs\"]\n",
    "            encoder_inputs_mask = batch[\"encoder_inputs_mask\"]\n",
    "            decoder_inputs = batch[\"decoder_inputs\"]\n",
    "            decoder_labels = batch[\"decoder_labels\"]\n",
    "            decoder_labels_mask = batch[\"decoder_labels_mask\"]\n",
    "\n",
    "            # 前向传播\n",
    "            outputs,_ = model(\n",
    "                src=encoder_inputs,\n",
    "                src_mask=encoder_inputs_mask,\n",
    "                decoder_input=decoder_inputs\n",
    "            )\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fct(\n",
    "                outputs,\n",
    "                decoder_labels,\n",
    "                decoder_labels_mask\n",
    "            )\n",
    "\n",
    "            # 更新总损失\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader) # 计算平均损失\n",
    "\n",
    "    model.train() # 切换回训练模式\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a5b6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "def training(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epoch,\n",
    "    loss_fct,\n",
    "    optimizer,\n",
    "    save_ckpt_callback=None,\n",
    "    early_stop_callback=None,\n",
    "    eval_step=500,\n",
    "):\n",
    "    record_dict = {\"train\": [], \"val\": []}  # record_dict是字典，记录训练和验证的损失\n",
    "\n",
    "    global_step = 1\n",
    "    val_loss = 0\n",
    "    model.train()  # 切换到训练模式\n",
    "    with tqdm(total=epoch * len(train_loader)) as pbar:\n",
    "        for epoch_id in range(epoch):\n",
    "            # training\n",
    "            for batch in train_loader:\n",
    "                encoder_inputs = batch[\"encoder_inputs\"]\n",
    "                encoder_inputs_mask = batch[\"encoder_inputs_mask\"]\n",
    "                decoder_inputs = batch[\"decoder_inputs\"]\n",
    "                decoder_labels = batch[\"decoder_labels\"]\n",
    "                decoder_labels_mask = batch[\"decoder_labels_mask\"]\n",
    "\n",
    "                # 梯度清空\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向计算\n",
    "                logits, _ = model(\n",
    "                    src=encoder_inputs,\n",
    "                    src_mask=encoder_inputs_mask,\n",
    "                    decoder_input=decoder_inputs,\n",
    "                )\n",
    "                loss = loss_fct(\n",
    "                    logits, decoder_labels, decoder_labels_mask\n",
    "                )\n",
    "\n",
    "                # 梯度回传\n",
    "                loss.backward()\n",
    "\n",
    "                # 调整优化器，包括学习率的变动等\n",
    "                optimizer.step()\n",
    "\n",
    "                loss = loss.cpu().item()\n",
    "                # record\n",
    "                record_dict[\"train\"].append({\"loss\": loss, \"step\": global_step})\n",
    "\n",
    "                # evaluating\n",
    "                if global_step % eval_step == 0:\n",
    "                    val_loss = evaluate(model, val_loader, loss_fct) #evaluate是计算验证集的损失\n",
    "                    record_dict[\"val\"].append({\"loss\": val_loss, \"step\": global_step})\n",
    "\n",
    "\n",
    "                    # 2. 保存模型权重 save model checkpoint\n",
    "                    if save_ckpt_callback is not None:\n",
    "                        save_ckpt_callback(\n",
    "                            global_step, model.state_dict(), metric=-val_loss\n",
    "                        )\n",
    "\n",
    "                    # 3. 早停 Early Stop\n",
    "                    if early_stop_callback is not None:\n",
    "                        early_stop_callback(-val_loss)\n",
    "                        if early_stop_callback.early_stop:#early_stop_callback.early_stop是True，则早停\n",
    "                            print(\n",
    "                                f\"Early stop at epoch {epoch_id} / global_step {global_step}\"\n",
    "                            )\n",
    "                            return record_dict\n",
    "\n",
    "                # udate step\n",
    "                global_step += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(\n",
    "                    {\"epoch\": epoch_id,'global_step': global_step, \"loss\": loss, \"val_loss\": val_loss}\n",
    "                )  # 更新进度条\n",
    "\n",
    "    return record_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69aa9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch = 20\n",
    "batch_size = 64\n",
    "\n",
    "model = Seq2Seq(\n",
    "    src_vocab_size=len(src_word2idx),\n",
    "    trg_vocab_size=len(trg_word2idx),\n",
    "    encoder_num_layers=1,\n",
    "    decoder_num_layers=1,\n",
    ")\n",
    "\n",
    "# 为训练和验证数据创建DataLoader\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# 1. 定义损失函数 采用交叉熵损失\n",
    "loss_fct = cross_entropy_with_padding\n",
    "\n",
    "\n",
    "# 2. 定义优化器 采用 adam\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# 3. save best\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.makedirs(\"checkpoints\")\n",
    "save_ckpt_callback = SaveCheckpointsCallback(\n",
    "    f\"checkpoints\", save_step=200, save_best_only=True\n",
    ")\n",
    "# 4. early stop\n",
    "early_stop_callback = EarlyStopCallback(patience=5)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bd20983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8bc44f56fa4b8dba7e83bbfb8f7cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m record = \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_ckpt_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_ckpt_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stop_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_step\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mtraining\u001b[39m\u001b[34m(model, train_loader, val_loader, epoch, loss_fct, optimizer, save_ckpt_callback, early_stop_callback, eval_step)\u001b[39m\n\u001b[32m     29\u001b[39m optimizer.zero_grad()\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 前向计算\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m logits, _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_inputs_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m loss = loss_fct(\n\u001b[32m     38\u001b[39m     logits, decoder_labels, decoder_labels_mask\n\u001b[32m     39\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 梯度回传\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mSeq2Seq.forward\u001b[39m\u001b[34m(self, src, decoder_input, src_mask, teacher_forcing_ratio)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# 逐个时间步解码\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tgt_len):\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# 解码器前向传播,output.shape = [batch_size, 1, vocab_size]\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m#attention_scores.shape = [batch_size, src_len, 1]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     logits, hidden, attention_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43mt\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# decoder_input[:, t:t+1] shape (bs,1) hidden shape (num_layers,bs,hidden_dim) encoder_outputs shape (bs,src_len,hidden_dim) src_mask shape (bs,src_len)\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# 收集每个时间步的输出和注意力分数\u001b[39;00m\n\u001b[32m     71\u001b[39m     logits_list.append(logits)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, decoder_input, hidden, encoder_outputs, attn_mask)\u001b[39m\n\u001b[32m     47\u001b[39m seq_output, hidden = \u001b[38;5;28mself\u001b[39m.gru(embeds, hidden) \u001b[38;5;66;03m#这里可以把hidden去掉对比一下最终的bleu指标\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# seq_output.shape = [batch size, 1, hidden_dim]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# logits.shape = [batch size, 1, vocab size]，attention_score = [batch size, sequence length, 1]\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits, hidden, attention_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "record = training(\n",
    "    model,\n",
    "    train_dl,\n",
    "    test_dl,\n",
    "    epoch,\n",
    "    loss_fct,\n",
    "    optimizer,\n",
    "    save_ckpt_callback=save_ckpt_callback,\n",
    "    early_stop_callback=early_stop_callback,\n",
    "    eval_step=200\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: disparad !\n",
      "Reference: fire !\n",
      "Candidate: certain ! ! it ! !\n",
      "BLEU: 0.1667\n",
      "--------------------------------------------------\n",
      "Source: esperen .\n",
      "Reference: wait .\n",
      "Candidate: wait in every , wait . i wait . .\n",
      "BLEU: 0.2000\n",
      "--------------------------------------------------\n",
      "Source: continua .\n",
      "Reference: go on .\n",
      "Candidate: go on on it on . go on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on . it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on . it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on . it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on . it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on it on . it on it on it on it on it on it on it on it on\n",
      "BLEU: 0.0059\n",
      "--------------------------------------------------\n",
      "Source: ¿ entendiste ?\n",
      "Reference: got it ?\n",
      "Candidate: did you you ? do you you you ?\n",
      "BLEU: 0.1111\n",
      "--------------------------------------------------\n",
      "Source: yo lo se .\n",
      "Reference: i know .\n",
      "Candidate: i as i i know i know about it it , i i know it it , i i know it , i i know it , i i know it , i i know it , i i know it , i i know it , i i know it , i i know it , i know it it , i i know it , i i know it , i know it it , i i know it , i know it it , i i know it , i know it it , i i know it , i know it it , i i know it , i know it it , i i know it it , i know it it , i i know it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it , i i know it it , i know it it\n",
      "BLEU: 0.0039\n",
      "--------------------------------------------------\n",
      "Source: sali .\n",
      "Reference: i left .\n",
      "Candidate: i get out out out out out out out . i go out of it out out of it out out of it out out of it out out of it out on . i i go out of it out on . i go out of it out on . i i left out . i go out of it out on . i i go out of it out on . i i go out of it out on . i i go out of it out on . i i go out of it out on . i i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i\n",
      "BLEU: 0.0059\n",
      "--------------------------------------------------\n",
      "Source: pruebalo .\n",
      "Reference: try it .\n",
      "Candidate: i do it have it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it\n",
      "BLEU: 0.0039\n",
      "--------------------------------------------------\n",
      "Source: pirate .\n",
      "Reference: beat it .\n",
      "Candidate: it s it s it s it s it s it s it . it s it s it . it s it . it s it . it s it . it s it . it s it . it s it . it s it . it . it s it . it . it . it . . it . . it . . it . . it . . it . . it . . it . . it . .\n",
      "BLEU: 0.0235\n",
      "--------------------------------------------------\n",
      "Source: sueltalo .\n",
      "Reference: drop it !\n",
      "Candidate: i was it was it . stop it . stop it . stop it . it . stop it . it . stop it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it . it .\n",
      "BLEU: 0.0020\n",
      "--------------------------------------------------\n",
      "Source: sali .\n",
      "Reference: get out .\n",
      "Candidate: i get out out out out out out out . i go out of it out out of it out out of it out out of it out out of it out on . i i go out of it out on . i go out of it out on . i i left out . i go out of it out on . i i go out of it out on . i i go out of it out on . i i go out of it out on . i i go out of it out on . i i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out of it out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i go out . i\n",
      "BLEU: 0.0059\n",
      "--------------------------------------------------\n",
      "Source: largate !\n",
      "Reference: go away .\n",
      "Candidate: go away ! ! go ! go ! ! go ! go ! get out ! ! go ! ! go ! go ! ! go ! get ! ! go ! ! go ! ! go ! ! go ! get it ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go ! ! go\n",
      "BLEU: 0.0039\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.421169952198137e-05"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2Seq(len(src_word2idx), len(trg_word2idx))\n",
    "model.load_state_dict(torch.load(f\"./checkpoints/best.ckpt\", map_location=\"cpu\"))\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, model, src_tokenizer, trg_tokenizer):\n",
    "        self.model = model\n",
    "        self.model.eval() # 切换到验证模式\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        sentence = preprocess_sentence(sentence) # 预处理句子，标点符号处理等\n",
    "        encoder_input, attn_mask = self.src_tokenizer.encode(\n",
    "            [sentence.split()],\n",
    "            padding_first=True,\n",
    "            add_bos=True,\n",
    "            add_eos=True,\n",
    "            return_mask=True,\n",
    "            ) # 对输入进行编码，并返回encode_piadding_mask\n",
    "        encoder_input = torch.Tensor(encoder_input).to(dtype=torch.int64) # 转换成tensor\n",
    "\n",
    "        preds, scores = model.infer(src=encoder_input, src_mask=attn_mask) #预测\n",
    "\n",
    "        trg_sentence = self.trg_tokenizer.decode(preds.numpy(), split=True, remove_eos=False)[0] #通过tokenizer转换成文字\n",
    "        # print(trg_sentence)\n",
    "        return \" \".join(trg_sentence[:-1])\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def evaluate_bleu_on_test_set(test_data, translator):\n",
    "    \"\"\"\n",
    "    在测试集上计算平均 BLEU 分数。\n",
    "    :param test_data: 测试集数据，格式为 [(src_sentence, [ref_translation1, ref_translation2, ...]), ...]\n",
    "    :param translator: 翻译器对象（Translator 类的实例）\n",
    "    :return: 平均 BLEU 分数\n",
    "    \"\"\"\n",
    "    total_bleu = 0.0\n",
    "    num_samples = len(test_data)\n",
    "    i=0\n",
    "    for src_sentence, ref_translations in test_data:\n",
    "        # 使用翻译器生成翻译结果\n",
    "        candidate_translation = translator(src_sentence)\n",
    "        # print(candidate_translation)\n",
    "        # 计算 BLEU 分数\n",
    "        bleu_score = sentence_bleu([ref_translations.split()], candidate_translation.split(),weights=(1, 0, 0, 0))\n",
    "        total_bleu += bleu_score\n",
    "\n",
    "        # 打印当前句子的 BLEU 分数（可选）\n",
    "        # print(f\"Source: {src_sentence}\")\n",
    "        # print(f\"Reference: {ref_translations}\")\n",
    "        # print(f\"Candidate: {candidate_translation}\")\n",
    "        # print(f\"BLEU: {bleu_score:.4f}\")\n",
    "        # print(\"-\" * 50)\n",
    "        # i+=1\n",
    "        # if i>10:\n",
    "        #   break\n",
    "    # 计算平均 BLEU 分数\n",
    "    avg_bleu = total_bleu / num_samples\n",
    "    return avg_bleu\n",
    "translator = Translator(model.cpu(), src_tokenizer, trg_tokenizer)\n",
    "evaluate_bleu_on_test_set(test_dataset, translator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
