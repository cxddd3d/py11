{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T07:03:19.604070Z",
     "start_time": "2025-05-20T07:02:38.328340Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbd521fd6214bee9c68e97337e0925a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HDS\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adae379a5d349a9898f9ba2f2f5c32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALBEF(\n",
      "  (image_encoder): ImageEncoder(\n",
      "    (backbone): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (text_encoder): TextEncoder(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (proj): Linear(in_features=768, out_features=256, bias=True)\n",
      "  )\n",
      "  (itm_head): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (mlm_head): Linear(in_features=768, out_features=30522, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch  # 导入PyTorch库\n",
    "import torch.nn as nn  # 导入PyTorch神经网络模块\n",
    "from transformers import BertModel, BertTokenizer, BertForMaskedLM  # 导入Hugging Face的BERT模型和分词器\n",
    "from torchvision.models import resnet50  # 导入ResNet50预训练模型\n",
    "import random  # 导入随机模块，用于MLM任务的掩码操作\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    \"\"\"图像编码器（使用 ResNet50）\"\"\"\n",
    "    def __init__(self, embed_dim=256):  # 初始化函数，设置嵌入维度默认为256\n",
    "        super(ImageEncoder, self).__init__()  # 调用父类初始化\n",
    "        self.backbone = resnet50(pretrained=True)  # 加载预训练的ResNet50模型作为骨干网络\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, embed_dim)  # 替换最后的全连接层，输出指定维度\n",
    "\n",
    "    def forward(self, images):  # 前向传播函数\n",
    "        return self.backbone(images)  # 通过ResNet50处理图像并返回特征\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    \"\"\"文本编码器（使用 BERT）\"\"\"\n",
    "    def __init__(self, embed_dim=256):  # 初始化函数，设置嵌入维度默认为256\n",
    "        super(TextEncoder, self).__init__()  # 调用父类初始化\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')  # 加载预训练的BERT模型\n",
    "        self.proj = nn.Linear(self.bert.config.hidden_size, embed_dim)  # 投影层，将BERT输出映射到指定维度\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):  # 前向传播函数\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)  # 通过BERT处理文本\n",
    "        last_hidden_state = outputs.last_hidden_state  # 获取最后一层的隐藏状态\n",
    "        cls_token = last_hidden_state[:, 0, :]  # 取 [CLS] 对应的向量作为文本表示\n",
    "        return self.proj(cls_token), last_hidden_state  # 返回投影后的CLS向量和完整的隐藏状态\n",
    "\n",
    "\n",
    "class ALBEF(nn.Module):\n",
    "    \"\"\"简化版 ALBEF 模型\"\"\"\n",
    "    def __init__(self, embed_dim=256):  # 初始化函数，设置嵌入维度默认为256\n",
    "        super(ALBEF, self).__init__()  # 调用父类初始化\n",
    "        self.image_encoder = ImageEncoder(embed_dim)  # 初始化图像编码器\n",
    "        self.text_encoder = TextEncoder(embed_dim)  # 初始化文本编码器\n",
    "        self.temperature = nn.Parameter(torch.ones([]) * 0.07)  # 温度参数，用于调整相似度计算的尺度\n",
    "        \n",
    "        # 图像-文本匹配（ITM）任务的分类器\n",
    "        self.itm_head = nn.Linear(self.text_encoder.bert.config.hidden_size, 2)  # 二分类：匹配/不匹配\n",
    "        \n",
    "        # 掩码语言模型（MLM）任务\n",
    "        self.mlm_head = nn.Linear(self.text_encoder.bert.config.hidden_size, self.text_encoder.bert.config.vocab_size)\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask, task=\"contrastive\"):  # 前向传播函数，增加任务类型参数\n",
    "        \"\"\"\n",
    "        支持三种任务：\n",
    "        - contrastive: 图像-文本对比学习\n",
    "        - itm: 图像-文本匹配\n",
    "        - mlm: 掩码语言模型\n",
    "        \"\"\"\n",
    "        if task == \"contrastive\":  # 图像-文本对比学习\n",
    "            return self.contrastive_forward(images, input_ids, attention_mask)\n",
    "        elif task == \"itm\":  # 图像-文本匹配\n",
    "            return self.itm_forward(images, input_ids, attention_mask)\n",
    "        elif task == \"mlm\":  # 掩码语言模型\n",
    "            return self.mlm_forward(images, input_ids, attention_mask)\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的任务类型: {task}\")\n",
    "\n",
    "    def contrastive_forward(self, images, input_ids, attention_mask):\n",
    "        # 编码图像和文本\n",
    "        image_features = self.image_encoder(images)  # 获取图像特征 (batch_size, embed_dim)\n",
    "        text_features, _ = self.text_encoder(input_ids, attention_mask)  # 获取文本特征 (batch_size, embed_dim)\n",
    "\n",
    "        # 归一化特征\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)  # L2归一化图像特征\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)  # L2归一化文本特征\n",
    "\n",
    "        # 计算对比损失\n",
    "        logits = (image_features @ text_features.t()) / self.temperature  # 计算余弦相似度并除以温度参数\n",
    "        labels = torch.arange(logits.size(0), device=logits.device)  # 创建标签（对角线匹配）\n",
    "        loss_i = nn.CrossEntropyLoss()(logits, labels)  # 计算图像到文本的损失\n",
    "        loss_t = nn.CrossEntropyLoss()(logits.t(), labels)  # 计算文本到图像的损失\n",
    "        loss = (loss_i + loss_t) / 2  # 取两个方向损失的平均值\n",
    "\n",
    "        return loss  # 返回总损失\n",
    "    \n",
    "    def itm_forward(self, images, input_ids, attention_mask, labels=None):\n",
    "        \"\"\"图像-文本匹配（ITM）任务的前向传播\"\"\"\n",
    "        # 编码图像\n",
    "        image_features = self.image_encoder(images)  # (batch_size, embed_dim)\n",
    "        \n",
    "        # 编码文本，获取完整的隐藏状态\n",
    "        _, text_hidden = self.text_encoder(input_ids, attention_mask)  # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        # 使用[CLS]标记的隐藏状态进行分类\n",
    "        cls_hidden = text_hidden[:, 0, :]  # (batch_size, hidden_size)\n",
    "        \n",
    "        # 图像特征与文本特征融合（简单拼接或相加）\n",
    "        # 这里我们简单地将图像特征与CLS隐藏状态相加\n",
    "        fused_features = cls_hidden + image_features  # (batch_size, hidden_size)\n",
    "        \n",
    "        # 通过ITM头部预测匹配/不匹配\n",
    "        itm_logits = self.itm_head(fused_features)  # (batch_size, 2)\n",
    "        \n",
    "        # 如果提供了标签，计算损失\n",
    "        if labels is not None:\n",
    "            itm_loss = nn.CrossEntropyLoss()(itm_logits, labels)\n",
    "            return itm_loss\n",
    "        else:\n",
    "            return itm_logits\n",
    "    \n",
    "    def mlm_forward(self, images, input_ids, attention_mask, masked_input_ids=None, mlm_labels=None):\n",
    "        \"\"\"掩码语言模型（MLM）任务的前向传播\"\"\"\n",
    "        # 编码图像\n",
    "        image_features = self.image_encoder(images)  # (batch_size, embed_dim)\n",
    "        \n",
    "        # 如果没有提供掩码输入，则创建掩码\n",
    "        if masked_input_ids is None and mlm_labels is None:\n",
    "            masked_input_ids, mlm_labels = self.mask_tokens(input_ids)\n",
    "        \n",
    "        # 编码文本，获取完整的隐藏状态\n",
    "        _, text_hidden = self.text_encoder(masked_input_ids, attention_mask)  # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        # 将图像特征与每个文本token的特征融合\n",
    "        # 这里我们简单地将图像特征扩展并加到文本特征上，相当于把图像特征加到每个文本token上,实际albef这里用的是融合特征，而非简单拼接或相加\n",
    "        #详见课件的说明：https://github.com/salesforce/ALBEF/blob/main/modeling_albef.py#L107-L110\n",
    "        image_features_expanded = image_features.unsqueeze(1).expand(-1, text_hidden.size(1), -1)\n",
    "        fused_features = text_hidden + image_features_expanded  # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        # 通过MLM头部预测掩码token\n",
    "        mlm_logits = self.mlm_head(fused_features)  # (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        # 如果提供了标签，计算损失\n",
    "        if mlm_labels is not None:\n",
    "            mlm_loss = nn.CrossEntropyLoss()(mlm_logits.view(-1, mlm_logits.size(-1)), mlm_labels.view(-1))\n",
    "            return mlm_loss\n",
    "        else:\n",
    "            return mlm_logits\n",
    "    \n",
    "    def mask_tokens(self, input_ids, mlm_probability=0.15):\n",
    "        \"\"\"创建用于MLM任务的掩码输入和标签\"\"\"\n",
    "        device = input_ids.device\n",
    "        labels = input_ids.clone()\n",
    "        \n",
    "        # 创建掩码概率矩阵\n",
    "        probability_matrix = torch.full(labels.shape, mlm_probability, device=device)\n",
    "        \n",
    "        # 特殊token不应该被掩码\n",
    "        special_tokens_mask = torch.zeros_like(input_ids, dtype=torch.bool, device=device)\n",
    "        for special_id in [0, 101, 102]:  # [PAD], [CLS], [SEP]的ID\n",
    "            special_tokens_mask = special_tokens_mask | (input_ids == special_id)\n",
    "        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
    "        \n",
    "        # 创建掩码，bernoulli功能是以给定概率生成掩码\n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "        labels[~masked_indices] = -100  # 只计算被掩码token的损失，-100是无效token的标签\n",
    "        \n",
    "        # 80%的情况下用[MASK]替换\n",
    "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8, device=device)).bool() & masked_indices\n",
    "        input_ids[indices_replaced] = 103  # [MASK]的ID\n",
    "        \n",
    "        # 10%的情况下用随机token替换\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5, device=device)).bool() & masked_indices & ~indices_replaced\n",
    "        random_words = torch.randint(0, self.text_encoder.bert.config.vocab_size, labels.shape, device=device)\n",
    "        input_ids[indices_random] = random_words[indices_random]\n",
    "        \n",
    "        # 剩下10%保持不变\n",
    "        \n",
    "        return input_ids, labels\n",
    "\n",
    "\n",
    "# 初始化模型\n",
    "model = ALBEF()  # 创建ALBEF模型实例\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)  # 输出模型的结构信息"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
