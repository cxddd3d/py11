{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGV2VjXF4pNs"
   },
   "source": [
    "# 查看FashionMNIST原始数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:55.758693Z",
     "start_time": "2025-07-02T12:01:55.139275Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# 加载预训练的VGG11模型\n",
    "vgg11 = models.vgg11(pretrained=True)\n",
    "\n",
    "# 打印模型结构\n",
    "print(vgg11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:55.769346Z",
     "start_time": "2025-07-02T12:01:55.760858Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "vgg11模型的总参数量: 132,863,336\n",
      "无法显示图像，请检查torchviz是否正确安装\n",
      "VGG11模型的详细参数信息:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-3         [-1, 64, 112, 112]               0\n",
      "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-5        [-1, 128, 112, 112]               0\n",
      "         MaxPool2d-6          [-1, 128, 56, 56]               0\n",
      "            Conv2d-7          [-1, 256, 56, 56]         295,168\n",
      "              ReLU-8          [-1, 256, 56, 56]               0\n",
      "            Conv2d-9          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-10          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-11          [-1, 256, 28, 28]               0\n",
      "           Conv2d-12          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-13          [-1, 512, 28, 28]               0\n",
      "           Conv2d-14          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-15          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-16          [-1, 512, 14, 14]               0\n",
      "           Conv2d-17          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-18          [-1, 512, 14, 14]               0\n",
      "           Conv2d-19          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-20          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-21            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-22            [-1, 512, 7, 7]               0\n",
      "           Linear-23                 [-1, 4096]     102,764,544\n",
      "             ReLU-24                 [-1, 4096]               0\n",
      "          Dropout-25                 [-1, 4096]               0\n",
      "           Linear-26                 [-1, 4096]      16,781,312\n",
      "             ReLU-27                 [-1, 4096]               0\n",
      "          Dropout-28                 [-1, 4096]               0\n",
      "           Linear-29                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 132,863,336\n",
      "Trainable params: 132,863,336\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 125.37\n",
      "Params size (MB): 506.83\n",
      "Estimated Total Size (MB): 632.78\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "# 加载预训练的VGG11模型\n",
    "vgg11 = models.vgg11(pretrained=True)\n",
    "\n",
    "# 打印模型结构\n",
    "print(vgg11)\n",
    "total_params = sum(p.numel() for p in vgg11.parameters())\n",
    "print(f\"vgg11模型的总参数量: {total_params:,}\")\n",
    "\n",
    "# 导入可视化模型结构所需的库\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "\n",
    "# 创建一个示例输入\n",
    "x = Variable(torch.randn(1, 3, 224, 224))\n",
    "\n",
    "# 获取模型输出\n",
    "y = vgg11(x)\n",
    "\n",
    "# 使用make_dot生成计算图\n",
    "dot = make_dot(y, params=dict(vgg11.named_parameters()))\n",
    "\n",
    "# 保存计算图为图片\n",
    "dot.format = 'png'\n",
    "dot.render(\"vgg11_structure\", cleanup=True)\n",
    "\n",
    "# 显示模型结构图\n",
    "try:\n",
    "    img = Image.open(\"vgg11_structure.png\")\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    plt.imshow(np.array(img))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"VGG11模型结构图\")\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"无法显示图像，请检查torchviz是否正确安装\")\n",
    "\n",
    "# 使用torchsummary打印模型的详细参数信息\n",
    "print(\"VGG11模型的详细参数信息:\")\n",
    "summary(vgg11, (3, 224, 224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.269256Z",
     "start_time": "2025-07-02T12:01:55.770793Z"
    },
    "id": "3djTfPq64pNt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from wangdao_deeplearning_train import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from wangdao_deeplearning_train import evaluate_classification_model as evaluate_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odpnkEt99pJ6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vk4EQTiM4pNt"
   },
   "source": [
    "# 加载数据并处理为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.299096Z",
     "start_time": "2025-07-02T12:01:56.270264Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvguuJLl4pNt",
    "outputId": "057311c0-4c17-4881-8bc8-1509721f63b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完整数据集大小: 50000\n",
      "训练集大小: 45000\n",
      "验证集大小: 5000\n"
     ]
    }
   ],
   "source": [
    "# 加载CIFAR-10数据集\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 定义CIFAR-10数据集类\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取标签文件，read_csv默认读取第一行作为列名\n",
    "        self.labels_df = pd.read_csv(labels_file)\n",
    "        self.img_names = self.labels_df.iloc[:, 0].values.astype(str)  # 第一列是图片名称，确保为字符串类型\n",
    "\n",
    "        # 类别名称字典，使用字典可以提高查找速度\n",
    "        self.class_names_dict = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3,\n",
    "                                 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "        # 将文本标签转换为数字ID\n",
    "        self.labels = [self.class_names_dict[label] for label in self.labels_df.iloc[:, 1].values]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx] + '.png') #图片路径\n",
    "        image = Image.open(img_path) #打开图片\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image)\n",
    "\n",
    "        return image_tensor, label\n",
    "\n",
    "# 定义数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4917, 0.4823, 0.4467), (0.2024, 0.1995, 0.2010))\n",
    "])\n",
    "\n",
    "# 加载CIFAR-10数据集\n",
    "# img_dir = r\"competitions/cifar-10/train\"\n",
    "# labels_file = r\"./trainLabels.csv\"\n",
    "img_dir = r\"D:\\cifar-10\\train\\train\"\n",
    "labels_file = r\"D:\\cifar-10\\trainLabels.csv\"\n",
    "full_dataset = CIFAR10Dataset(img_dir=img_dir, labels_file=labels_file, transform=transform)\n",
    "\n",
    "# 定义类别名称\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = 45000\n",
    "val_size = 5000\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "# 查看数据集基本信息\n",
    "print(f\"完整数据集大小: {len(full_dataset)}\")\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"验证集大小: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.304611Z",
     "start_time": "2025-07-02T12:01:56.300100Z"
    },
    "id": "1akKUts84pNu"
   },
   "outputs": [],
   "source": [
    "def cal_mean_std(ds):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for img, _ in ds:\n",
    "        mean += img.mean(dim=(1, 2)) #dim=(1, 2)表示在通道维度上求平均\n",
    "        std += img.std(dim=(1, 2))  #dim=(1, 2)表示在通道维度上求标准差\n",
    "    mean /= len(ds)\n",
    "    std /= len(ds)\n",
    "    return mean, std\n",
    "# cal_mean_std(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrTSD6iw4pNu"
   },
   "source": [
    "# 把数据集划分为训练集45000和验证集5000，并给DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.310166Z",
     "start_time": "2025-07-02T12:01:56.304611Z"
    },
    "id": "qK_zQ__r4pNu"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUyAkERd4pNu"
   },
   "source": [
    "# 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.317622Z",
     "start_time": "2025-07-02T12:01:56.311171Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j17TXWWx4pNu",
    "outputId": "c84a8838-7e38-4021-f998-278b2fbbc450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100])\n"
     ]
    }
   ],
   "source": [
    "#理解每个接口的方法，单独写例子\n",
    "import torch.nn as nn\n",
    "m=nn.BatchNorm1d(100)\n",
    "x=torch.randn(20,100)\n",
    "print(m(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFvbdkKd4pNu"
   },
   "source": [
    "# 复现VGG11简单版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.324703Z",
     "start_time": "2025-07-02T12:01:56.318627Z"
    },
    "id": "UOfee2qW4pNu"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VG11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 第一组卷积层 - 使用Sequential组织\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 第二组卷积层 - 使用Sequential组织\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 第三组卷积层 - 使用Sequential组织\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 全连接层 - 使用Sequential组织\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "        # 初始化权重\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"使用 xavier 均匀分布来初始化卷积层和全连接层的权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播使用Sequential定义的块\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "\n",
    "        # 展平\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # 分类器\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.706516Z",
     "start_time": "2025-07-02T12:01:56.327710Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ll8FXqD4pNv",
    "outputId": "8a7d4e48-a347-44cf-998d-768b3dcd1746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次图像形状: torch.Size([64, 3, 32, 32])\n",
      "批次标签形状: torch.Size([64])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = VG11()\n",
    "\n",
    "# 从train_loader获取第一个批次的数据\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 查看批次数据的形状\n",
    "print(\"批次图像形状:\", images.shape)\n",
    "print(\"批次标签形状:\", labels.shape)\n",
    "\n",
    "\n",
    "print('-'*100)\n",
    "# 进行前向传播\n",
    "with torch.no_grad():  # 不需要计算梯度\n",
    "    outputs = model(images)\n",
    "\n",
    "\n",
    "print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.714127Z",
     "start_time": "2025-07-02T12:01:56.708633Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8zEsAla4pNv",
    "outputId": "419f1a1b-0cdb-43b6-9eaa-e7c5e96f7a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要求梯度的参数总量: 12979850\n",
      "模型总参数量: 12979850\n",
      "\n",
      "各层参数量明细:\n",
      "conv_block1.0.weight: 3456 参数\n",
      "conv_block1.0.bias: 128 参数\n",
      "conv_block1.1.weight: 128 参数\n",
      "conv_block1.1.bias: 128 参数\n",
      "conv_block1.3.weight: 147456 参数\n",
      "conv_block1.3.bias: 128 参数\n",
      "conv_block1.4.weight: 128 参数\n",
      "conv_block1.4.bias: 128 参数\n",
      "conv_block2.0.weight: 294912 参数\n",
      "conv_block2.0.bias: 256 参数\n",
      "conv_block2.1.weight: 256 参数\n",
      "conv_block2.1.bias: 256 参数\n",
      "conv_block2.3.weight: 589824 参数\n",
      "conv_block2.3.bias: 256 参数\n",
      "conv_block2.4.weight: 256 参数\n",
      "conv_block2.4.bias: 256 参数\n",
      "conv_block3.0.weight: 1179648 参数\n",
      "conv_block3.0.bias: 512 参数\n",
      "conv_block3.1.weight: 512 参数\n",
      "conv_block3.1.bias: 512 参数\n",
      "conv_block3.3.weight: 2359296 参数\n",
      "conv_block3.3.bias: 512 参数\n",
      "conv_block3.4.weight: 512 参数\n",
      "conv_block3.4.bias: 512 参数\n",
      "classifier.0.weight: 8388608 参数\n",
      "classifier.0.bias: 1024 参数\n",
      "classifier.2.weight: 10240 参数\n",
      "classifier.2.bias: 10 参数\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数量\n",
    "# 统计需要求梯度的参数总量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"需要求梯度的参数总量: {total_params}\")\n",
    "\n",
    "# 统计所有参数总量\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {all_params}\")\n",
    "\n",
    "# 查看每层参数量明细\n",
    "print(\"\\n各层参数量明细:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} 参数\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.722184Z",
     "start_time": "2025-07-02T12:01:56.715134Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XQuUiCe4pNv",
    "outputId": "6392904b-f824-429a-ba2b-6f20859a7285"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294912"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*3*3*256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B2dFDE14pNv"
   },
   "source": [
    "# 各层参数量明细:\n",
    "conv1.weight: 288 参数 3*3*1*32\n",
    "conv1.bias: 32 参数\n",
    "conv2.weight: 9216 参数 3*3*32*32\n",
    "conv2.bias: 32 参数  \n",
    "conv3.weight: 18432 参数 3*3*32*64\n",
    "conv3.bias: 64 参数\n",
    "conv4.weight: 36864 参数  3*3*64*64\n",
    "conv4.bias: 64 参数\n",
    "conv5.weight: 73728 参数\n",
    "conv5.bias: 128 参数\n",
    "conv6.weight: 147456 参数\n",
    "conv6.bias: 128 参数\n",
    "fc1.weight: 294912 参数 128*3*3*256\n",
    "fc1.bias: 256 参数\n",
    "fc2.weight: 2560 参数\n",
    "fc2.bias: 10 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.787079Z",
     "start_time": "2025-07-02T12:01:56.723195Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "al9xZTJQ4pNv",
    "outputId": "84542063-d5a6-4ac5-da39-562f651421f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block1.0.weight',\n",
       "              tensor([[[[-0.0605,  0.0214,  0.0429],\n",
       "                        [ 0.0228, -0.0636, -0.0540],\n",
       "                        [-0.0274,  0.0268, -0.0448]],\n",
       "              \n",
       "                       [[-0.0566,  0.0261,  0.0537],\n",
       "                        [ 0.0463, -0.0602,  0.0124],\n",
       "                        [-0.0449,  0.0372, -0.0432]],\n",
       "              \n",
       "                       [[ 0.0572, -0.0177, -0.0183],\n",
       "                        [-0.0698, -0.0454, -0.0399],\n",
       "                        [ 0.0685,  0.0574,  0.0076]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0674, -0.0330, -0.0394],\n",
       "                        [ 0.0682, -0.0346, -0.0393],\n",
       "                        [-0.0394, -0.0520,  0.0351]],\n",
       "              \n",
       "                       [[-0.0377,  0.0141, -0.0487],\n",
       "                        [ 0.0110,  0.0274,  0.0201],\n",
       "                        [-0.0706, -0.0462, -0.0289]],\n",
       "              \n",
       "                       [[-0.0512, -0.0658,  0.0377],\n",
       "                        [-0.0084, -0.0390,  0.0050],\n",
       "                        [-0.0505, -0.0109,  0.0362]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0604,  0.0576,  0.0048],\n",
       "                        [-0.0674,  0.0329,  0.0471],\n",
       "                        [-0.0229, -0.0522,  0.0446]],\n",
       "              \n",
       "                       [[-0.0402, -0.0547, -0.0397],\n",
       "                        [ 0.0268, -0.0032,  0.0123],\n",
       "                        [ 0.0446, -0.0093,  0.0635]],\n",
       "              \n",
       "                       [[-0.0045,  0.0335,  0.0654],\n",
       "                        [ 0.0707, -0.0427, -0.0600],\n",
       "                        [-0.0209, -0.0431,  0.0416]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0662,  0.0677, -0.0334],\n",
       "                        [ 0.0713,  0.0634, -0.0503],\n",
       "                        [-0.0282, -0.0318, -0.0131]],\n",
       "              \n",
       "                       [[ 0.0390, -0.0670, -0.0184],\n",
       "                        [-0.0468,  0.0008, -0.0214],\n",
       "                        [ 0.0020,  0.0021,  0.0643]],\n",
       "              \n",
       "                       [[ 0.0152, -0.0548, -0.0670],\n",
       "                        [-0.0260,  0.0035, -0.0099],\n",
       "                        [ 0.0710,  0.0675, -0.0445]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0197, -0.0313, -0.0061],\n",
       "                        [ 0.0190, -0.0007, -0.0251],\n",
       "                        [ 0.0274, -0.0390,  0.0209]],\n",
       "              \n",
       "                       [[ 0.0096, -0.0200,  0.0461],\n",
       "                        [ 0.0611, -0.0099,  0.0689],\n",
       "                        [ 0.0460,  0.0360, -0.0449]],\n",
       "              \n",
       "                       [[ 0.0029,  0.0433, -0.0035],\n",
       "                        [-0.0644, -0.0681,  0.0456],\n",
       "                        [ 0.0206, -0.0086,  0.0703]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0517,  0.0446, -0.0472],\n",
       "                        [ 0.0675, -0.0414, -0.0276],\n",
       "                        [-0.0632, -0.0285,  0.0429]],\n",
       "              \n",
       "                       [[-0.0276,  0.0705, -0.0042],\n",
       "                        [ 0.0647,  0.0056, -0.0691],\n",
       "                        [-0.0320,  0.0046,  0.0097]],\n",
       "              \n",
       "                       [[ 0.0318,  0.0648,  0.0500],\n",
       "                        [-0.0152, -0.0326,  0.0251],\n",
       "                        [ 0.0024,  0.0494, -0.0404]]]])),\n",
       "             ('conv_block1.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block1.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('conv_block1.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block1.1.running_mean',\n",
       "              tensor([-9.9267e-04, -1.0140e-03,  1.6786e-05,  5.1103e-04, -9.8734e-04,\n",
       "                      -1.0365e-03, -1.3528e-04, -5.0125e-04, -4.0018e-04,  1.9588e-04,\n",
       "                      -1.1787e-03, -3.4351e-04, -4.4885e-04,  6.7735e-04,  6.0142e-04,\n",
       "                       2.0896e-03, -1.4659e-03, -2.5514e-04, -2.9630e-04, -3.6756e-04,\n",
       "                      -3.0934e-04,  6.2634e-04, -1.1068e-03, -1.9927e-03, -4.6272e-04,\n",
       "                       2.2173e-04,  1.1366e-03,  2.5670e-04, -1.2421e-03, -1.4229e-03,\n",
       "                      -4.3935e-04,  4.9148e-04,  1.4244e-03, -7.2855e-04, -2.3125e-04,\n",
       "                      -5.6300e-04, -5.8867e-04, -3.3392e-04, -7.0414e-04,  9.0261e-04,\n",
       "                      -8.9261e-04, -1.2331e-04, -1.4078e-03, -7.8582e-05, -1.5829e-04,\n",
       "                      -5.9405e-04, -1.0858e-03,  6.5980e-04, -5.2190e-04, -2.3363e-04,\n",
       "                      -1.2896e-03, -6.1356e-04, -2.8306e-04, -2.2758e-03,  1.0131e-03,\n",
       "                      -3.2653e-04, -3.7932e-04,  5.2145e-04, -2.6490e-04,  2.1525e-05,\n",
       "                       6.8459e-04, -5.7596e-04, -8.2227e-04, -2.3577e-03,  5.4348e-04,\n",
       "                      -1.2226e-03,  9.8371e-04, -9.7231e-04,  1.0597e-03, -1.1021e-03,\n",
       "                       9.5481e-04, -1.0751e-03,  3.5531e-04,  5.2551e-05, -1.1579e-04,\n",
       "                       9.1193e-04,  3.5589e-04, -2.7175e-04, -6.6046e-06, -4.0610e-04,\n",
       "                      -7.9956e-04, -6.3510e-04, -3.1508e-05, -8.4809e-04,  2.4981e-04,\n",
       "                      -3.7954e-04,  2.0020e-04,  6.4994e-04,  6.0294e-04,  4.0231e-05,\n",
       "                       9.9173e-04, -4.1506e-04,  8.5083e-04, -1.5389e-04,  1.3187e-03,\n",
       "                       1.3437e-03,  1.8422e-03,  8.4912e-04, -6.6941e-04, -1.0326e-03,\n",
       "                      -8.3973e-04,  1.1303e-03, -7.4907e-04, -4.8685e-04, -1.0949e-03,\n",
       "                      -3.7003e-05,  5.6759e-04, -9.7091e-06,  1.9953e-04, -7.5996e-04,\n",
       "                      -2.8671e-04,  9.4633e-04,  2.6282e-04, -9.3981e-04,  2.2822e-04,\n",
       "                       4.0533e-04, -1.4316e-04, -5.5674e-04,  9.0475e-04, -3.9615e-04,\n",
       "                      -3.5792e-04,  1.2493e-03, -6.7009e-04, -9.8644e-04,  3.6063e-04,\n",
       "                       2.3781e-04,  2.0590e-04,  5.3352e-04])),\n",
       "             ('conv_block1.1.running_var',\n",
       "              tensor([0.9039, 0.9158, 0.9009, 0.9057, 0.9033, 0.9021, 0.9022, 0.9012, 0.9008,\n",
       "                      0.9010, 0.9133, 0.9019, 0.9098, 0.9053, 0.9039, 0.9215, 0.9120, 0.9027,\n",
       "                      0.9048, 0.9009, 0.9054, 0.9019, 0.9181, 0.9304, 0.9105, 0.9029, 0.9082,\n",
       "                      0.9059, 0.9110, 0.9081, 0.9027, 0.9102, 0.9169, 0.9020, 0.9021, 0.9120,\n",
       "                      0.9033, 0.9017, 0.9077, 0.9046, 0.9081, 0.9043, 0.9149, 0.9038, 0.9005,\n",
       "                      0.9032, 0.9217, 0.9043, 0.9059, 0.9016, 0.9127, 0.9108, 0.9017, 0.9363,\n",
       "                      0.9031, 0.9020, 0.9042, 0.9014, 0.9037, 0.9005, 0.9037, 0.9016, 0.9033,\n",
       "                      0.9246, 0.9021, 0.9056, 0.9052, 0.9130, 0.9119, 0.9064, 0.9084, 0.9185,\n",
       "                      0.9005, 0.9032, 0.9004, 0.9070, 0.9008, 0.9053, 0.9017, 0.9029, 0.9027,\n",
       "                      0.9024, 0.9022, 0.9061, 0.9035, 0.9061, 0.9038, 0.9021, 0.9045, 0.9026,\n",
       "                      0.9055, 0.9099, 0.9159, 0.9016, 0.9168, 0.9058, 0.9222, 0.9145, 0.9027,\n",
       "                      0.9065, 0.9027, 0.9156, 0.9039, 0.9075, 0.9052, 0.9017, 0.9027, 0.9007,\n",
       "                      0.9068, 0.9041, 0.9011, 0.9156, 0.9010, 0.9098, 0.9012, 0.9033, 0.9038,\n",
       "                      0.9083, 0.9022, 0.9038, 0.9033, 0.9106, 0.9036, 0.9038, 0.9023, 0.9022,\n",
       "                      0.9051, 0.9048])),\n",
       "             ('conv_block1.1.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block1.3.weight',\n",
       "              tensor([[[[ 0.0249,  0.0035, -0.0067],\n",
       "                        [-0.0079,  0.0059, -0.0095],\n",
       "                        [ 0.0359,  0.0017,  0.0119]],\n",
       "              \n",
       "                       [[-0.0435, -0.0038,  0.0491],\n",
       "                        [-0.0337,  0.0040,  0.0279],\n",
       "                        [ 0.0178, -0.0234, -0.0014]],\n",
       "              \n",
       "                       [[-0.0335,  0.0429,  0.0469],\n",
       "                        [-0.0004,  0.0072,  0.0355],\n",
       "                        [-0.0048,  0.0138, -0.0093]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0108,  0.0338,  0.0295],\n",
       "                        [-0.0118, -0.0184, -0.0474],\n",
       "                        [-0.0083,  0.0466, -0.0501]],\n",
       "              \n",
       "                       [[ 0.0397, -0.0078,  0.0464],\n",
       "                        [-0.0427,  0.0342,  0.0396],\n",
       "                        [ 0.0463, -0.0488, -0.0194]],\n",
       "              \n",
       "                       [[-0.0341, -0.0021, -0.0157],\n",
       "                        [ 0.0081, -0.0303,  0.0344],\n",
       "                        [ 0.0320,  0.0221,  0.0269]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0486,  0.0446, -0.0225],\n",
       "                        [-0.0316,  0.0039,  0.0100],\n",
       "                        [ 0.0107,  0.0270, -0.0470]],\n",
       "              \n",
       "                       [[ 0.0458,  0.0139,  0.0037],\n",
       "                        [-0.0407, -0.0325,  0.0215],\n",
       "                        [ 0.0039,  0.0292,  0.0317]],\n",
       "              \n",
       "                       [[ 0.0005,  0.0119, -0.0318],\n",
       "                        [-0.0507,  0.0319,  0.0472],\n",
       "                        [ 0.0277, -0.0248,  0.0349]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0038, -0.0087,  0.0292],\n",
       "                        [-0.0323,  0.0008,  0.0175],\n",
       "                        [ 0.0248, -0.0045, -0.0291]],\n",
       "              \n",
       "                       [[ 0.0452, -0.0404,  0.0035],\n",
       "                        [ 0.0299,  0.0296, -0.0074],\n",
       "                        [ 0.0122,  0.0419,  0.0148]],\n",
       "              \n",
       "                       [[ 0.0326,  0.0092,  0.0325],\n",
       "                        [-0.0127, -0.0039,  0.0413],\n",
       "                        [-0.0435,  0.0290,  0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0210,  0.0464,  0.0091],\n",
       "                        [ 0.0120, -0.0019, -0.0134],\n",
       "                        [ 0.0045, -0.0054,  0.0375]],\n",
       "              \n",
       "                       [[-0.0330, -0.0085, -0.0424],\n",
       "                        [-0.0272, -0.0462, -0.0260],\n",
       "                        [ 0.0048, -0.0240, -0.0014]],\n",
       "              \n",
       "                       [[ 0.0385, -0.0204, -0.0444],\n",
       "                        [ 0.0252,  0.0242, -0.0102],\n",
       "                        [ 0.0161,  0.0388,  0.0201]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0335, -0.0385, -0.0488],\n",
       "                        [-0.0159,  0.0189,  0.0296],\n",
       "                        [-0.0086,  0.0256,  0.0110]],\n",
       "              \n",
       "                       [[-0.0205,  0.0060, -0.0161],\n",
       "                        [ 0.0481,  0.0143,  0.0483],\n",
       "                        [ 0.0033, -0.0152, -0.0404]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0174,  0.0021],\n",
       "                        [ 0.0296, -0.0373,  0.0509],\n",
       "                        [-0.0220, -0.0341, -0.0223]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0052, -0.0433, -0.0436],\n",
       "                        [ 0.0407, -0.0173, -0.0445],\n",
       "                        [ 0.0114, -0.0367, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0412, -0.0054, -0.0245],\n",
       "                        [ 0.0508,  0.0056, -0.0222],\n",
       "                        [ 0.0006,  0.0171,  0.0321]],\n",
       "              \n",
       "                       [[-0.0295, -0.0230,  0.0387],\n",
       "                        [-0.0237,  0.0329, -0.0106],\n",
       "                        [ 0.0315,  0.0046, -0.0271]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0132, -0.0050,  0.0465],\n",
       "                        [-0.0268, -0.0427,  0.0353],\n",
       "                        [ 0.0244, -0.0245,  0.0075]],\n",
       "              \n",
       "                       [[-0.0228, -0.0331, -0.0339],\n",
       "                        [-0.0016,  0.0480,  0.0452],\n",
       "                        [-0.0362,  0.0393, -0.0280]],\n",
       "              \n",
       "                       [[-0.0107,  0.0414, -0.0476],\n",
       "                        [ 0.0507, -0.0382,  0.0367],\n",
       "                        [-0.0370,  0.0259,  0.0498]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0504, -0.0070,  0.0033],\n",
       "                        [ 0.0038, -0.0044,  0.0299],\n",
       "                        [ 0.0095, -0.0487, -0.0434]],\n",
       "              \n",
       "                       [[-0.0127, -0.0409,  0.0013],\n",
       "                        [-0.0272,  0.0225, -0.0058],\n",
       "                        [-0.0379,  0.0268,  0.0087]],\n",
       "              \n",
       "                       [[ 0.0164,  0.0003,  0.0214],\n",
       "                        [-0.0304, -0.0384,  0.0013],\n",
       "                        [ 0.0099, -0.0021,  0.0427]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0323, -0.0237,  0.0476],\n",
       "                        [ 0.0338, -0.0102,  0.0247],\n",
       "                        [ 0.0286,  0.0280,  0.0023]],\n",
       "              \n",
       "                       [[-0.0327,  0.0436, -0.0340],\n",
       "                        [-0.0287,  0.0230,  0.0070],\n",
       "                        [ 0.0235,  0.0160, -0.0014]],\n",
       "              \n",
       "                       [[ 0.0504, -0.0441, -0.0018],\n",
       "                        [ 0.0465, -0.0432, -0.0080],\n",
       "                        [ 0.0364, -0.0393,  0.0209]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0097,  0.0184, -0.0238],\n",
       "                        [-0.0236,  0.0447,  0.0306],\n",
       "                        [-0.0237,  0.0240,  0.0296]],\n",
       "              \n",
       "                       [[-0.0036,  0.0098, -0.0336],\n",
       "                        [ 0.0297,  0.0278,  0.0371],\n",
       "                        [-0.0237, -0.0044,  0.0399]],\n",
       "              \n",
       "                       [[-0.0407,  0.0466,  0.0463],\n",
       "                        [-0.0187,  0.0100, -0.0414],\n",
       "                        [ 0.0034, -0.0035,  0.0086]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0386, -0.0061, -0.0187],\n",
       "                        [ 0.0401, -0.0007, -0.0230],\n",
       "                        [ 0.0073, -0.0096, -0.0045]],\n",
       "              \n",
       "                       [[ 0.0147,  0.0029, -0.0195],\n",
       "                        [ 0.0222, -0.0027, -0.0289],\n",
       "                        [-0.0492, -0.0117, -0.0387]],\n",
       "              \n",
       "                       [[ 0.0132, -0.0132, -0.0322],\n",
       "                        [-0.0479, -0.0091,  0.0459],\n",
       "                        [-0.0377,  0.0158,  0.0396]]]])),\n",
       "             ('conv_block1.3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block1.4.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('conv_block1.4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block1.4.running_mean',\n",
       "              tensor([-1.1978e-02,  2.1868e-02,  1.6762e-02,  5.0822e-02, -2.0822e-02,\n",
       "                      -4.7542e-04,  6.1654e-03, -1.1279e-02, -5.1502e-02, -2.1204e-02,\n",
       "                      -1.5702e-02,  2.1160e-02, -3.5471e-02,  2.5814e-02,  4.7461e-03,\n",
       "                       2.4552e-02,  1.2158e-01, -8.7066e-02,  2.8721e-02,  7.9941e-02,\n",
       "                       5.2538e-02,  1.4440e-02, -7.1403e-02,  5.8173e-06, -2.6287e-02,\n",
       "                       3.0420e-02, -3.3225e-02,  1.8413e-02,  1.6586e-02,  1.3040e-02,\n",
       "                       3.2663e-02,  2.5855e-02,  1.1965e-02,  5.5477e-02, -6.1191e-02,\n",
       "                      -5.3833e-02,  2.6915e-02,  2.8336e-02, -1.2357e-02,  1.0970e-02,\n",
       "                       1.0403e-02, -2.3683e-02, -1.9913e-02,  2.8111e-03,  1.9001e-03,\n",
       "                      -5.9194e-02, -3.8742e-02,  1.8462e-02, -2.7052e-03, -8.1102e-02,\n",
       "                       2.9682e-02, -5.0976e-03,  1.5578e-02,  8.7918e-03, -7.2401e-03,\n",
       "                      -2.6505e-02, -6.9971e-03, -6.3507e-02, -3.5099e-03, -4.7464e-02,\n",
       "                       1.1214e-02, -6.2404e-02,  1.4857e-02,  3.6546e-02,  2.0646e-02,\n",
       "                      -8.7495e-02,  2.0488e-02,  1.6988e-02,  8.8844e-03,  2.5246e-02,\n",
       "                       3.1855e-02, -1.6808e-02, -2.4300e-02, -3.9982e-02, -3.9052e-02,\n",
       "                       1.7355e-02,  2.1459e-03,  4.5056e-02,  9.6781e-02, -9.4976e-03,\n",
       "                      -3.2983e-02,  5.9789e-03, -1.3354e-02, -1.1731e-02,  6.8975e-04,\n",
       "                      -7.5741e-03,  9.4501e-03,  3.5965e-02,  2.8745e-02, -2.4597e-02,\n",
       "                      -6.7293e-02, -5.1726e-03, -1.1640e-02, -3.0895e-02, -1.8326e-02,\n",
       "                      -7.4605e-02,  3.0427e-03, -2.1944e-02, -2.4214e-02, -3.3402e-02,\n",
       "                       2.9727e-02,  4.8125e-02,  5.2746e-03,  5.0562e-02, -1.7751e-02,\n",
       "                      -4.0949e-02,  3.8014e-02,  1.5912e-02,  1.1045e-02,  1.1690e-01,\n",
       "                      -3.5145e-02,  3.9595e-02,  1.4620e-02,  1.0544e-01,  1.8612e-02,\n",
       "                       6.2452e-04,  4.0217e-03, -1.9586e-02, -7.7563e-03,  2.0283e-02,\n",
       "                      -5.6797e-02,  6.3110e-02,  4.7986e-02,  8.8227e-03,  4.0567e-02,\n",
       "                      -6.4061e-02,  4.1117e-02,  4.6973e-02])),\n",
       "             ('conv_block1.4.running_var',\n",
       "              tensor([0.9123, 0.9218, 0.9298, 0.9324, 0.9146, 0.9176, 0.9213, 0.9232, 0.9357,\n",
       "                      0.9147, 0.9173, 0.9532, 0.9265, 0.9555, 0.9242, 0.9247, 0.9777, 0.9284,\n",
       "                      0.9274, 0.9291, 0.9412, 0.9201, 0.9370, 0.9216, 0.9228, 0.9391, 1.0637,\n",
       "                      0.9524, 0.9375, 0.9136, 0.9283, 0.9301, 0.9161, 0.9321, 0.9573, 0.9378,\n",
       "                      0.9213, 0.9188, 0.9285, 0.9348, 0.9369, 0.9252, 0.9120, 0.9154, 0.9151,\n",
       "                      0.9243, 0.9337, 0.9186, 0.9178, 0.9302, 0.9234, 0.9165, 0.9220, 0.9255,\n",
       "                      0.9296, 0.9656, 0.9285, 0.9401, 0.9274, 0.9275, 0.9353, 0.9245, 0.9170,\n",
       "                      0.9284, 0.9207, 0.9332, 0.9414, 0.9288, 0.9222, 0.9256, 0.9430, 0.9370,\n",
       "                      0.9135, 0.9146, 0.9599, 0.9163, 0.9333, 0.9377, 0.9566, 0.9546, 0.9345,\n",
       "                      0.9219, 0.9726, 0.9233, 0.9503, 0.9265, 0.9148, 0.9411, 0.9215, 0.9142,\n",
       "                      0.9224, 0.9110, 0.9156, 0.9159, 0.9223, 0.9378, 0.9208, 0.9411, 0.9144,\n",
       "                      0.9277, 0.9395, 0.9236, 0.9143, 0.9171, 0.9261, 0.9244, 0.9265, 0.9860,\n",
       "                      0.9187, 0.9428, 0.9179, 0.9302, 0.9134, 0.9380, 0.9524, 0.9226, 0.9195,\n",
       "                      0.9143, 0.9288, 0.9309, 0.9332, 0.9476, 0.9222, 0.9645, 0.9835, 0.9373,\n",
       "                      0.9234, 0.9570])),\n",
       "             ('conv_block1.4.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block2.0.weight',\n",
       "              tensor([[[[ 2.6336e-02,  2.0966e-02,  5.2236e-03],\n",
       "                        [-1.7277e-03, -4.0463e-02, -3.6218e-02],\n",
       "                        [-1.1560e-02,  1.8608e-02,  2.2825e-02]],\n",
       "              \n",
       "                       [[ 4.0681e-02, -8.9398e-03, -1.7991e-02],\n",
       "                        [ 1.7943e-02,  1.2321e-02, -3.4199e-02],\n",
       "                        [-3.6053e-03, -2.5595e-02, -3.2691e-02]],\n",
       "              \n",
       "                       [[ 1.9861e-02,  2.2141e-02, -2.7313e-03],\n",
       "                        [ 3.4144e-02, -2.8150e-02,  1.2388e-02],\n",
       "                        [-3.1814e-02, -8.8326e-03,  1.0168e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.9866e-02, -2.3796e-02, -6.7945e-03],\n",
       "                        [-3.7408e-02,  1.5871e-02,  4.1208e-02],\n",
       "                        [ 3.6972e-02,  1.3462e-02,  2.7350e-02]],\n",
       "              \n",
       "                       [[-1.8876e-03, -2.7974e-03,  1.8924e-02],\n",
       "                        [-1.1579e-02, -2.8716e-02, -2.9107e-02],\n",
       "                        [-4.9282e-03, -1.9395e-02, -1.4642e-04]],\n",
       "              \n",
       "                       [[-1.3812e-03,  1.9543e-02, -1.7910e-02],\n",
       "                        [-3.8863e-02, -3.6318e-03, -1.0786e-02],\n",
       "                        [ 2.3441e-02, -2.7211e-02, -1.8894e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0417e-02,  2.9947e-02, -2.1882e-02],\n",
       "                        [ 1.1913e-02,  1.8559e-04, -2.0434e-02],\n",
       "                        [ 3.2779e-02,  3.9024e-02, -3.6701e-02]],\n",
       "              \n",
       "                       [[ 6.9627e-03,  3.9758e-02,  1.5308e-02],\n",
       "                        [ 2.1076e-03,  8.6210e-03, -1.8720e-02],\n",
       "                        [ 1.0972e-02,  2.3626e-02, -3.9293e-03]],\n",
       "              \n",
       "                       [[-3.0173e-02, -2.1988e-02, -2.9862e-02],\n",
       "                        [-3.4336e-02,  4.8786e-03,  2.5936e-02],\n",
       "                        [ 3.4167e-02,  3.9604e-02,  3.5049e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2577e-02, -2.4253e-02,  2.0514e-02],\n",
       "                        [ 2.4146e-03, -4.6752e-06,  1.0473e-02],\n",
       "                        [ 1.0991e-02, -7.2868e-03, -1.5662e-02]],\n",
       "              \n",
       "                       [[ 2.2892e-02,  1.0722e-02, -6.9141e-03],\n",
       "                        [-3.0081e-02, -3.3988e-02,  3.1658e-02],\n",
       "                        [ 7.0825e-04,  1.7736e-02,  2.5321e-02]],\n",
       "              \n",
       "                       [[ 2.8814e-02,  1.6745e-02,  2.1376e-02],\n",
       "                        [ 1.6813e-02,  2.9790e-02, -1.7674e-02],\n",
       "                        [ 4.9474e-03, -7.1716e-03,  3.1105e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5449e-02,  2.1100e-02,  4.0313e-03],\n",
       "                        [-8.6300e-03, -4.0438e-02,  2.6169e-02],\n",
       "                        [-1.5015e-02,  1.8568e-02,  3.3120e-02]],\n",
       "              \n",
       "                       [[ 1.0290e-02, -2.7117e-02, -2.8622e-02],\n",
       "                        [-3.1210e-02, -1.6939e-02, -2.8758e-02],\n",
       "                        [-3.0592e-02,  1.4303e-02, -1.3177e-02]],\n",
       "              \n",
       "                       [[-2.3816e-02,  2.4851e-02, -3.4593e-02],\n",
       "                        [ 1.1979e-03,  6.1365e-04, -3.8420e-02],\n",
       "                        [ 3.8980e-02,  4.5246e-03,  4.0482e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.6800e-03, -1.3621e-02, -1.0385e-02],\n",
       "                        [-2.5346e-02, -3.6505e-02, -3.8886e-02],\n",
       "                        [-3.4651e-03,  3.5359e-02, -3.7280e-02]],\n",
       "              \n",
       "                       [[-3.5582e-02, -1.2980e-02, -8.2153e-03],\n",
       "                        [ 3.6813e-02,  3.4467e-02,  1.0395e-02],\n",
       "                        [ 3.5872e-02,  3.4373e-02, -9.4738e-03]],\n",
       "              \n",
       "                       [[ 3.9916e-02,  7.2018e-03, -3.9174e-03],\n",
       "                        [ 3.3420e-02,  1.3893e-02, -6.0669e-03],\n",
       "                        [-3.2706e-02, -1.9858e-04, -3.8347e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-6.0670e-03,  1.9703e-02, -8.8211e-03],\n",
       "                        [ 2.5226e-02,  1.7170e-02,  1.1939e-02],\n",
       "                        [ 4.0097e-02,  1.2618e-02,  3.4521e-02]],\n",
       "              \n",
       "                       [[-3.6941e-02,  7.3244e-03,  2.4476e-02],\n",
       "                        [ 2.4043e-02,  2.0129e-03,  2.4385e-02],\n",
       "                        [ 3.8508e-02,  3.4579e-02, -1.1900e-02]],\n",
       "              \n",
       "                       [[-2.8824e-02,  1.7796e-02,  2.5542e-02],\n",
       "                        [-9.7515e-03, -3.8837e-02,  9.8116e-03],\n",
       "                        [ 1.9970e-02, -7.2630e-03,  3.8485e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.2186e-03, -1.0695e-02,  1.7546e-02],\n",
       "                        [ 1.9154e-02, -2.5417e-02,  3.0423e-02],\n",
       "                        [-1.6681e-02,  3.7554e-02, -2.4961e-02]],\n",
       "              \n",
       "                       [[ 2.8538e-02,  1.7743e-02,  1.2870e-02],\n",
       "                        [-1.3676e-02, -9.7454e-03,  1.7075e-02],\n",
       "                        [ 1.5279e-02,  3.1594e-02, -1.3369e-02]],\n",
       "              \n",
       "                       [[-2.8648e-03, -1.8526e-02,  3.0706e-02],\n",
       "                        [-3.1024e-02,  3.2432e-02,  2.5134e-02],\n",
       "                        [-3.9798e-02, -3.3210e-02,  4.5740e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6773e-04,  2.0522e-02,  1.6911e-02],\n",
       "                        [-1.0233e-02, -3.4064e-02, -3.1045e-02],\n",
       "                        [ 1.9120e-02, -1.9671e-02, -1.1605e-02]],\n",
       "              \n",
       "                       [[-1.0753e-02,  1.1857e-02, -6.0952e-03],\n",
       "                        [ 3.2353e-02,  2.2997e-02,  1.3841e-02],\n",
       "                        [ 3.6545e-02,  2.9420e-02,  1.8006e-02]],\n",
       "              \n",
       "                       [[ 8.5461e-03,  2.5151e-02, -2.2098e-03],\n",
       "                        [-2.3381e-02, -2.3727e-02, -1.6773e-02],\n",
       "                        [-1.9491e-03, -7.2985e-03,  3.3485e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.6958e-02, -2.9920e-02, -2.2330e-02],\n",
       "                        [-1.6556e-02, -3.7556e-04, -1.3808e-03],\n",
       "                        [ 1.6922e-02,  2.5847e-02, -3.4614e-02]],\n",
       "              \n",
       "                       [[ 1.7980e-02, -3.2370e-02, -1.5099e-02],\n",
       "                        [-3.9105e-02, -5.1821e-03, -1.3938e-02],\n",
       "                        [-4.0455e-02, -1.2539e-02, -3.7853e-02]],\n",
       "              \n",
       "                       [[ 2.3371e-02,  2.2116e-02, -3.3513e-02],\n",
       "                        [ 2.1773e-02,  3.3538e-02, -2.8556e-02],\n",
       "                        [ 1.6525e-02,  1.2378e-02, -2.1939e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8149e-02,  2.9558e-02,  3.1037e-02],\n",
       "                        [-1.7026e-03,  2.5711e-02,  1.5293e-02],\n",
       "                        [-1.5268e-02,  3.7884e-02,  3.0268e-02]],\n",
       "              \n",
       "                       [[ 4.0535e-02, -2.7491e-02, -4.3482e-03],\n",
       "                        [ 3.9342e-02,  8.6069e-03, -7.4786e-04],\n",
       "                        [ 1.4746e-03, -3.5465e-02,  7.6716e-03]],\n",
       "              \n",
       "                       [[-1.5039e-03,  1.6672e-02, -3.0106e-02],\n",
       "                        [-1.4698e-02, -4.0257e-02,  3.5442e-02],\n",
       "                        [-3.3497e-02,  1.6673e-02, -1.6442e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.9255e-02,  3.9171e-02, -1.7024e-02],\n",
       "                        [-2.8932e-02,  1.4896e-02, -1.6364e-02],\n",
       "                        [ 4.1379e-02, -2.8033e-02,  1.3553e-02]],\n",
       "              \n",
       "                       [[-3.3893e-02, -6.2159e-03,  1.0130e-02],\n",
       "                        [-1.7143e-02, -1.1473e-02,  1.7878e-02],\n",
       "                        [ 1.1903e-02, -6.8962e-03, -1.6107e-02]],\n",
       "              \n",
       "                       [[ 2.9466e-02, -3.7619e-02,  3.8952e-03],\n",
       "                        [-7.2248e-03,  3.9736e-02, -1.6480e-02],\n",
       "                        [ 3.5668e-02, -2.5826e-02,  1.1340e-02]]]])),\n",
       "             ('conv_block2.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block2.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('conv_block2.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block2.1.running_mean',\n",
       "              tensor([ 1.6880e-02,  2.4092e-02, -4.2960e-02,  4.1344e-02,  2.7896e-02,\n",
       "                       9.5386e-02, -6.8829e-02, -4.9417e-03,  2.2881e-02, -8.4788e-03,\n",
       "                       1.8115e-02,  1.7078e-03, -3.6772e-02, -3.5946e-02,  1.1219e-02,\n",
       "                       2.3094e-02, -7.6143e-03, -1.6744e-02,  6.2631e-02, -8.6552e-02,\n",
       "                       4.1843e-02, -8.0717e-02,  2.6334e-02,  4.8987e-02,  1.0054e-02,\n",
       "                       2.3084e-02, -1.6140e-02, -6.8868e-02, -8.7896e-03,  1.5323e-02,\n",
       "                       4.4359e-02,  2.4775e-02, -1.6452e-02, -2.1268e-02, -4.4880e-02,\n",
       "                       1.1825e-02, -8.4307e-03, -4.2318e-02, -5.4304e-02,  3.0152e-03,\n",
       "                      -2.1555e-02,  2.6612e-02, -6.6029e-02, -1.1544e-02,  4.9420e-02,\n",
       "                      -2.0394e-02,  3.3750e-03, -3.5700e-02, -5.6313e-02,  9.6531e-02,\n",
       "                       2.6826e-02,  2.4184e-03,  4.7452e-02, -1.1103e-01, -1.9225e-02,\n",
       "                      -3.9265e-02,  3.9436e-02,  8.4709e-02,  1.0265e-02,  5.2328e-02,\n",
       "                       2.3531e-02,  8.6431e-02, -4.6388e-02,  2.6755e-02, -2.1859e-02,\n",
       "                       4.6270e-02,  8.1146e-03, -3.4123e-02,  2.6075e-02, -2.5730e-02,\n",
       "                      -9.8554e-02, -6.5584e-02, -9.0922e-04, -2.3513e-02, -5.6797e-02,\n",
       "                       6.9501e-02,  1.2370e-02, -6.7343e-02,  2.3599e-02,  2.1213e-02,\n",
       "                      -4.6001e-02, -8.6116e-03, -3.1975e-02,  1.8795e-02,  6.7334e-02,\n",
       "                       5.6917e-02, -1.3535e-02,  7.5861e-02,  5.5323e-02, -2.4085e-02,\n",
       "                      -4.7098e-02,  7.7224e-02,  1.2487e-02,  9.1231e-02,  2.3158e-02,\n",
       "                      -2.2928e-02, -2.4249e-02,  1.8284e-02,  3.6576e-02,  2.2525e-02,\n",
       "                      -1.9321e-02,  4.7321e-02, -2.9891e-02,  5.9154e-02, -2.0976e-02,\n",
       "                      -3.4693e-02,  4.2767e-03, -4.3643e-02, -5.8641e-03, -8.1942e-02,\n",
       "                       4.7130e-03,  4.2694e-02,  2.1486e-02, -2.3038e-02,  1.9558e-03,\n",
       "                       1.2561e-02,  3.0885e-02, -2.4632e-03,  1.8389e-03, -1.1936e-02,\n",
       "                       7.1533e-02,  3.2304e-02, -1.2206e-02, -4.1650e-02,  3.6720e-02,\n",
       "                       2.8351e-02,  3.0331e-02, -2.3294e-02, -1.6191e-02,  5.4944e-02,\n",
       "                      -3.0219e-02, -3.5810e-02, -6.6560e-02,  1.9023e-02, -5.9564e-02,\n",
       "                      -7.6704e-02,  1.4407e-03,  8.1750e-03, -5.6066e-02,  2.7282e-02,\n",
       "                       3.9909e-03, -2.0932e-02,  5.5847e-02,  1.0769e-02,  5.4749e-02,\n",
       "                       5.9017e-02,  5.1248e-03, -2.3385e-02,  6.3531e-02,  5.5189e-04,\n",
       "                      -8.2462e-02, -2.0029e-02, -1.3335e-01,  7.1542e-03,  2.3959e-02,\n",
       "                      -2.4963e-02,  9.4174e-03, -9.8027e-02, -3.3855e-02,  5.9418e-02,\n",
       "                       9.2132e-02, -1.5396e-02, -1.2735e-01,  7.7381e-02, -1.5396e-03,\n",
       "                       3.2731e-02,  1.0448e-03, -5.3886e-02, -2.6026e-02,  9.5715e-03,\n",
       "                      -2.5101e-02, -7.3524e-02, -1.5390e-03, -9.9413e-03, -2.0732e-02,\n",
       "                       8.7844e-05, -3.6338e-02, -8.6842e-02,  2.0165e-02, -2.9443e-02,\n",
       "                      -2.8272e-02, -1.9938e-02,  2.0176e-02,  3.9870e-03, -6.5634e-02,\n",
       "                      -5.7104e-02, -2.1458e-02, -9.2651e-02, -7.7906e-04, -2.5575e-03,\n",
       "                       3.2318e-02, -1.0601e-01, -5.6078e-02, -1.0910e-02,  3.6648e-02,\n",
       "                      -1.7395e-02, -1.9823e-02, -4.9092e-03, -4.0422e-02,  9.3513e-02,\n",
       "                      -5.4908e-02, -3.6980e-02,  3.3476e-02, -1.4771e-02, -1.1324e-03,\n",
       "                       4.0126e-03, -1.4412e-02, -3.7065e-03,  1.2602e-02,  4.2884e-02,\n",
       "                       5.4384e-02,  2.6538e-02, -3.5517e-02,  1.2045e-02,  4.8546e-02,\n",
       "                       1.4680e-02,  5.2444e-02,  5.3574e-02,  6.2217e-03,  4.9219e-02,\n",
       "                       9.0768e-02, -4.3476e-02, -9.8560e-03,  7.8089e-03, -2.4749e-02,\n",
       "                       1.0229e-02,  4.9530e-02, -1.1291e-02,  1.7447e-02,  1.1772e-02,\n",
       "                       7.7115e-02,  4.3041e-02,  1.2874e-02,  5.7416e-02,  1.9917e-03,\n",
       "                       1.2332e-02, -2.4216e-02, -1.0970e-02,  3.1096e-02, -6.0598e-03,\n",
       "                      -6.9317e-02,  5.8327e-02, -3.8753e-02,  5.2121e-02, -4.2171e-02,\n",
       "                       4.3670e-03, -2.7853e-02,  3.7149e-02, -1.5282e-02,  4.4669e-02,\n",
       "                      -2.3232e-02,  4.5131e-02, -4.4779e-02,  4.9101e-02, -5.6987e-02,\n",
       "                      -2.8630e-02])),\n",
       "             ('conv_block2.1.running_var',\n",
       "              tensor([0.9355, 0.9279, 0.9369, 0.9296, 0.9407, 0.9447, 0.9273, 0.9194, 0.9355,\n",
       "                      0.9262, 0.9257, 0.9346, 0.9421, 0.9399, 0.9435, 0.9279, 0.9168, 0.9370,\n",
       "                      0.9299, 0.9494, 0.9401, 0.9343, 0.9264, 0.9338, 0.9228, 0.9719, 0.9203,\n",
       "                      0.9480, 0.9234, 0.9197, 0.9293, 0.9260, 0.9316, 0.9225, 0.9299, 0.9266,\n",
       "                      0.9257, 0.9227, 0.9307, 0.9404, 0.9445, 0.9390, 0.9256, 0.9317, 0.9225,\n",
       "                      0.9358, 0.9279, 0.9275, 0.9312, 0.9349, 0.9248, 0.9370, 0.9233, 0.9399,\n",
       "                      0.9383, 0.9367, 0.9270, 0.9343, 0.9211, 0.9302, 0.9289, 0.9328, 0.9325,\n",
       "                      0.9251, 0.9250, 0.9355, 0.9259, 0.9332, 0.9309, 0.9262, 0.9369, 0.9265,\n",
       "                      0.9304, 0.9386, 0.9267, 0.9332, 0.9366, 0.9294, 0.9287, 0.9428, 0.9403,\n",
       "                      0.9321, 0.9342, 0.9328, 0.9296, 0.9262, 0.9230, 0.9492, 0.9294, 0.9242,\n",
       "                      0.9407, 0.9444, 0.9239, 0.9293, 0.9247, 0.9328, 0.9353, 0.9282, 0.9261,\n",
       "                      0.9230, 0.9194, 0.9339, 0.9164, 0.9386, 0.9327, 0.9275, 0.9363, 0.9424,\n",
       "                      0.9189, 0.9437, 0.9208, 0.9407, 0.9251, 0.9416, 0.9320, 0.9214, 0.9168,\n",
       "                      0.9269, 0.9406, 0.9289, 0.9292, 0.9451, 0.9251, 0.9287, 0.9280, 0.9279,\n",
       "                      0.9290, 0.9514, 0.9345, 0.9357, 0.9238, 0.9220, 0.9309, 0.9317, 0.9219,\n",
       "                      0.9356, 0.9310, 0.9188, 0.9384, 0.9365, 0.9206, 0.9302, 0.9217, 0.9429,\n",
       "                      0.9273, 0.9522, 0.9330, 0.9560, 0.9428, 0.9223, 0.9250, 0.9292, 0.9646,\n",
       "                      0.9300, 0.9229, 0.9335, 0.9325, 0.9387, 0.9351, 0.9511, 0.9445, 0.9346,\n",
       "                      0.9481, 0.9391, 0.9218, 0.9368, 0.9247, 0.9529, 0.9326, 0.9211, 0.9347,\n",
       "                      0.9343, 0.9173, 0.9202, 0.9345, 0.9287, 0.9220, 0.9437, 0.9297, 0.9241,\n",
       "                      0.9283, 0.9263, 0.9326, 0.9266, 0.9343, 0.9670, 0.9517, 0.9402, 0.9250,\n",
       "                      0.9395, 0.9296, 0.9577, 0.9317, 0.9371, 0.9365, 0.9435, 0.9359, 0.9217,\n",
       "                      0.9279, 0.9299, 0.9305, 0.9223, 0.9165, 0.9189, 0.9332, 0.9515, 0.9384,\n",
       "                      0.9327, 0.9617, 0.9379, 0.9263, 0.9250, 0.9367, 0.9317, 0.9246, 0.9490,\n",
       "                      0.9284, 0.9218, 0.9216, 0.9244, 0.9284, 0.9248, 0.9277, 0.9304, 0.9210,\n",
       "                      0.9292, 0.9378, 0.9275, 0.9180, 0.9241, 0.9345, 0.9294, 0.9331, 0.9356,\n",
       "                      0.9343, 0.9360, 0.9218, 0.9227, 0.9460, 0.9361, 0.9375, 0.9415, 0.9143,\n",
       "                      0.9308, 0.9294, 0.9467, 0.9519, 0.9425, 0.9350, 0.9309, 0.9270, 0.9262,\n",
       "                      0.9226, 0.9341, 0.9347, 0.9346])),\n",
       "             ('conv_block2.1.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block2.3.weight',\n",
       "              tensor([[[[-0.0066,  0.0355, -0.0083],\n",
       "                        [ 0.0010,  0.0268, -0.0226],\n",
       "                        [ 0.0271,  0.0040, -0.0171]],\n",
       "              \n",
       "                       [[ 0.0122,  0.0327,  0.0342],\n",
       "                        [-0.0191, -0.0115, -0.0024],\n",
       "                        [ 0.0336, -0.0269, -0.0276]],\n",
       "              \n",
       "                       [[-0.0024, -0.0225,  0.0041],\n",
       "                        [-0.0134,  0.0019, -0.0296],\n",
       "                        [ 0.0009, -0.0222, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0016,  0.0230],\n",
       "                        [ 0.0319,  0.0323,  0.0157],\n",
       "                        [ 0.0181, -0.0158, -0.0025]],\n",
       "              \n",
       "                       [[ 0.0345,  0.0177, -0.0276],\n",
       "                        [-0.0283, -0.0264,  0.0198],\n",
       "                        [ 0.0311, -0.0203,  0.0056]],\n",
       "              \n",
       "                       [[ 0.0193, -0.0029,  0.0215],\n",
       "                        [ 0.0105,  0.0141,  0.0243],\n",
       "                        [ 0.0089,  0.0123,  0.0350]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0089,  0.0306,  0.0046],\n",
       "                        [ 0.0314,  0.0063, -0.0261],\n",
       "                        [ 0.0009,  0.0018, -0.0269]],\n",
       "              \n",
       "                       [[-0.0256, -0.0173, -0.0083],\n",
       "                        [-0.0093,  0.0176,  0.0173],\n",
       "                        [-0.0171,  0.0087,  0.0268]],\n",
       "              \n",
       "                       [[ 0.0286, -0.0199, -0.0281],\n",
       "                        [-0.0292,  0.0069,  0.0310],\n",
       "                        [-0.0105,  0.0124, -0.0307]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0190,  0.0070,  0.0015],\n",
       "                        [ 0.0304, -0.0015, -0.0147],\n",
       "                        [ 0.0289, -0.0202, -0.0311]],\n",
       "              \n",
       "                       [[-0.0342, -0.0331, -0.0210],\n",
       "                        [ 0.0288,  0.0040,  0.0287],\n",
       "                        [ 0.0194, -0.0350,  0.0159]],\n",
       "              \n",
       "                       [[ 0.0145,  0.0313, -0.0035],\n",
       "                        [ 0.0281, -0.0102, -0.0076],\n",
       "                        [ 0.0183, -0.0120, -0.0180]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0237,  0.0361,  0.0025],\n",
       "                        [-0.0131,  0.0357,  0.0284],\n",
       "                        [ 0.0341, -0.0084,  0.0056]],\n",
       "              \n",
       "                       [[-0.0062,  0.0326,  0.0320],\n",
       "                        [ 0.0312, -0.0217,  0.0182],\n",
       "                        [ 0.0360,  0.0177,  0.0229]],\n",
       "              \n",
       "                       [[-0.0013, -0.0282,  0.0224],\n",
       "                        [ 0.0138,  0.0211,  0.0199],\n",
       "                        [ 0.0138,  0.0122, -0.0218]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0046,  0.0168, -0.0350],\n",
       "                        [-0.0328, -0.0258,  0.0072],\n",
       "                        [-0.0079,  0.0190, -0.0061]],\n",
       "              \n",
       "                       [[ 0.0297,  0.0250, -0.0360],\n",
       "                        [ 0.0130, -0.0265,  0.0114],\n",
       "                        [ 0.0144,  0.0001,  0.0345]],\n",
       "              \n",
       "                       [[-0.0062, -0.0101,  0.0290],\n",
       "                        [ 0.0062,  0.0226, -0.0098],\n",
       "                        [ 0.0261, -0.0110, -0.0328]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0036, -0.0316,  0.0269],\n",
       "                        [-0.0241,  0.0333, -0.0215],\n",
       "                        [ 0.0147,  0.0267,  0.0133]],\n",
       "              \n",
       "                       [[ 0.0270,  0.0100,  0.0238],\n",
       "                        [ 0.0354, -0.0067,  0.0287],\n",
       "                        [-0.0047, -0.0178, -0.0204]],\n",
       "              \n",
       "                       [[-0.0188,  0.0242, -0.0274],\n",
       "                        [-0.0181, -0.0188,  0.0312],\n",
       "                        [ 0.0046, -0.0240, -0.0107]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0181, -0.0334,  0.0037],\n",
       "                        [ 0.0337, -0.0083, -0.0192],\n",
       "                        [ 0.0035, -0.0017,  0.0301]],\n",
       "              \n",
       "                       [[-0.0012,  0.0009, -0.0175],\n",
       "                        [ 0.0011, -0.0030,  0.0322],\n",
       "                        [ 0.0042, -0.0044,  0.0251]],\n",
       "              \n",
       "                       [[-0.0215,  0.0151,  0.0128],\n",
       "                        [ 0.0186, -0.0186,  0.0103],\n",
       "                        [ 0.0268, -0.0350, -0.0317]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0332,  0.0173, -0.0249],\n",
       "                        [ 0.0234, -0.0305, -0.0291],\n",
       "                        [-0.0277,  0.0164,  0.0274]],\n",
       "              \n",
       "                       [[ 0.0174, -0.0126,  0.0259],\n",
       "                        [ 0.0325,  0.0145, -0.0190],\n",
       "                        [-0.0128,  0.0051,  0.0192]],\n",
       "              \n",
       "                       [[-0.0271,  0.0357,  0.0140],\n",
       "                        [-0.0027, -0.0151, -0.0145],\n",
       "                        [ 0.0128, -0.0069,  0.0314]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0293,  0.0056,  0.0361],\n",
       "                        [-0.0138, -0.0117,  0.0063],\n",
       "                        [ 0.0159, -0.0140, -0.0132]],\n",
       "              \n",
       "                       [[-0.0276, -0.0054, -0.0077],\n",
       "                        [-0.0245, -0.0099, -0.0322],\n",
       "                        [-0.0217, -0.0353,  0.0009]],\n",
       "              \n",
       "                       [[-0.0084, -0.0167, -0.0340],\n",
       "                        [ 0.0214,  0.0262, -0.0224],\n",
       "                        [-0.0347, -0.0213,  0.0160]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0197, -0.0069, -0.0230],\n",
       "                        [ 0.0150, -0.0308,  0.0047],\n",
       "                        [ 0.0033, -0.0161, -0.0153]],\n",
       "              \n",
       "                       [[-0.0191,  0.0056, -0.0185],\n",
       "                        [-0.0053, -0.0234, -0.0034],\n",
       "                        [-0.0101,  0.0051,  0.0027]],\n",
       "              \n",
       "                       [[ 0.0329, -0.0123,  0.0152],\n",
       "                        [-0.0141,  0.0353,  0.0229],\n",
       "                        [-0.0238, -0.0022, -0.0163]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0112,  0.0308,  0.0195],\n",
       "                        [ 0.0231,  0.0123, -0.0165],\n",
       "                        [ 0.0294,  0.0259,  0.0252]],\n",
       "              \n",
       "                       [[-0.0117, -0.0322, -0.0252],\n",
       "                        [-0.0279,  0.0267, -0.0152],\n",
       "                        [ 0.0323, -0.0156,  0.0085]],\n",
       "              \n",
       "                       [[-0.0210, -0.0295, -0.0351],\n",
       "                        [ 0.0126,  0.0228, -0.0012],\n",
       "                        [ 0.0074,  0.0073, -0.0147]]]])),\n",
       "             ('conv_block2.3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block2.4.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('conv_block2.4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block2.4.running_mean',\n",
       "              tensor([-0.0136, -0.0253,  0.0197,  0.0684, -0.0176, -0.0051, -0.0106,  0.0141,\n",
       "                       0.0503,  0.0303, -0.0075, -0.0087, -0.0151,  0.0134,  0.0474,  0.0313,\n",
       "                       0.0252,  0.0070, -0.0175,  0.0211,  0.0963, -0.0403,  0.0194, -0.0706,\n",
       "                      -0.0436, -0.0255, -0.0245,  0.0030,  0.0027,  0.0061,  0.0165, -0.0327,\n",
       "                      -0.0041,  0.0383, -0.0097, -0.0068, -0.0462,  0.0191, -0.0129,  0.0144,\n",
       "                      -0.0146,  0.0089, -0.0023, -0.0031,  0.0110, -0.0332, -0.0218, -0.0296,\n",
       "                       0.0698, -0.0576,  0.0841,  0.0613, -0.0055,  0.0152, -0.0064, -0.0117,\n",
       "                      -0.0498, -0.0171,  0.0600, -0.0370,  0.0461, -0.0124,  0.0315,  0.0228,\n",
       "                      -0.0787, -0.0409,  0.0278,  0.0874, -0.1046,  0.0021, -0.0744,  0.0090,\n",
       "                      -0.0107, -0.0045,  0.0395, -0.0356, -0.0068, -0.0387,  0.0119,  0.0089,\n",
       "                      -0.0061,  0.0305,  0.0137,  0.0263,  0.0188, -0.0254, -0.0124,  0.0418,\n",
       "                      -0.0117,  0.0672,  0.0216, -0.0074, -0.0690, -0.0357,  0.0266, -0.0144,\n",
       "                      -0.0082, -0.0025, -0.0117, -0.0360,  0.0125,  0.0297,  0.0077, -0.0448,\n",
       "                       0.0171, -0.0093, -0.0397, -0.0183, -0.0533,  0.0707, -0.0640,  0.0180,\n",
       "                      -0.0212, -0.0038, -0.0588, -0.0647, -0.0297, -0.0088, -0.0133, -0.0277,\n",
       "                      -0.0364,  0.0422, -0.0521, -0.0274, -0.0050,  0.0212,  0.0025, -0.0346,\n",
       "                      -0.0169,  0.0019, -0.0172,  0.0503,  0.0022, -0.0506, -0.0100,  0.0401,\n",
       "                      -0.0746,  0.0169, -0.0207,  0.0803,  0.0760,  0.0150, -0.0171,  0.0149,\n",
       "                      -0.0860,  0.0237, -0.0302, -0.0578, -0.0081, -0.0005, -0.0591, -0.0043,\n",
       "                       0.0170, -0.0138,  0.0053, -0.0257, -0.0304, -0.0287, -0.0640,  0.0288,\n",
       "                      -0.0507,  0.0544,  0.0367, -0.0604,  0.0068, -0.0469,  0.0568,  0.0408,\n",
       "                       0.0065, -0.0618,  0.0507,  0.0283, -0.0388,  0.0041, -0.0597,  0.0011,\n",
       "                      -0.0620, -0.0036, -0.0749, -0.0499, -0.0642,  0.0200,  0.0737,  0.0221,\n",
       "                       0.0413, -0.0102, -0.0076,  0.0354,  0.0205,  0.0420, -0.0268,  0.0204,\n",
       "                      -0.0027, -0.1074,  0.0732, -0.0178, -0.0499, -0.0388, -0.0229,  0.0295,\n",
       "                       0.0155,  0.0189, -0.0123,  0.0582,  0.0765,  0.0023, -0.0129, -0.0140,\n",
       "                      -0.0405,  0.0154,  0.0508, -0.0072, -0.0022, -0.0550, -0.0010,  0.0406,\n",
       "                      -0.0466, -0.0095,  0.0223, -0.0096,  0.0429,  0.0380, -0.0650, -0.0212,\n",
       "                       0.0004,  0.0229, -0.0283, -0.0381,  0.0157,  0.0010, -0.0033, -0.0026,\n",
       "                       0.0331,  0.0031, -0.0166,  0.0038,  0.0242, -0.0038, -0.0478,  0.0541,\n",
       "                      -0.0525, -0.1125,  0.0532,  0.0028, -0.0139,  0.0478, -0.0672, -0.0653,\n",
       "                       0.0417,  0.0038,  0.0626,  0.0183,  0.0305,  0.1031, -0.0138, -0.0327])),\n",
       "             ('conv_block2.4.running_var',\n",
       "              tensor([0.9293, 0.9338, 0.9262, 0.9299, 0.9284, 0.9258, 0.9303, 0.9313, 0.9368,\n",
       "                      0.9295, 0.9218, 0.9313, 0.9278, 0.9312, 0.9380, 0.9340, 0.9385, 0.9454,\n",
       "                      0.9274, 0.9203, 0.9369, 0.9430, 0.9228, 0.9283, 0.9341, 0.9292, 0.9307,\n",
       "                      0.9288, 0.9246, 0.9359, 0.9437, 0.9365, 0.9295, 0.9299, 0.9282, 0.9304,\n",
       "                      0.9363, 0.9361, 0.9246, 0.9345, 0.9467, 0.9308, 0.9358, 0.9354, 0.9270,\n",
       "                      0.9282, 0.9431, 0.9294, 0.9346, 0.9324, 0.9373, 0.9442, 0.9309, 0.9283,\n",
       "                      0.9269, 0.9362, 0.9285, 0.9464, 0.9383, 0.9391, 0.9352, 0.9303, 0.9261,\n",
       "                      0.9246, 0.9368, 0.9354, 0.9350, 0.9278, 0.9647, 0.9264, 0.9270, 0.9240,\n",
       "                      0.9298, 0.9405, 0.9286, 0.9334, 0.9314, 0.9266, 0.9338, 0.9309, 0.9243,\n",
       "                      0.9356, 0.9498, 0.9359, 0.9548, 0.9271, 0.9256, 0.9324, 0.9254, 0.9282,\n",
       "                      0.9268, 0.9378, 0.9350, 0.9390, 0.9284, 0.9285, 0.9435, 0.9362, 0.9353,\n",
       "                      0.9243, 0.9272, 0.9499, 0.9319, 0.9361, 0.9344, 0.9246, 0.9353, 0.9346,\n",
       "                      0.9259, 0.9358, 0.9308, 0.9381, 0.9256, 0.9338, 0.9328, 0.9390, 0.9329,\n",
       "                      0.9421, 0.9287, 0.9230, 0.9257, 0.9271, 0.9240, 0.9301, 0.9291, 0.9256,\n",
       "                      0.9258, 0.9307, 0.9514, 0.9298, 0.9408, 0.9372, 0.9257, 0.9366, 0.9413,\n",
       "                      0.9267, 0.9466, 0.9312, 0.9270, 0.9304, 0.9778, 0.9287, 0.9279, 0.9310,\n",
       "                      0.9301, 0.9321, 0.9347, 0.9397, 0.9304, 0.9311, 0.9279, 0.9252, 0.9304,\n",
       "                      0.9241, 0.9319, 0.9277, 0.9187, 0.9256, 0.9245, 0.9272, 0.9354, 0.9309,\n",
       "                      0.9368, 0.9299, 0.9297, 0.9318, 0.9334, 0.9287, 0.9306, 0.9527, 0.9203,\n",
       "                      0.9586, 0.9361, 0.9380, 0.9239, 0.9263, 0.9292, 0.9245, 0.9727, 0.9348,\n",
       "                      0.9318, 0.9337, 0.9284, 0.9498, 0.9327, 0.9276, 0.9415, 0.9305, 0.9311,\n",
       "                      0.9296, 0.9398, 0.9297, 0.9312, 0.9321, 0.9316, 0.9298, 0.9386, 0.9307,\n",
       "                      0.9329, 0.9332, 0.9240, 0.9244, 0.9298, 0.9231, 0.9358, 0.9259, 0.9271,\n",
       "                      0.9311, 0.9261, 0.9283, 0.9354, 0.9334, 0.9325, 0.9311, 0.9250, 0.9287,\n",
       "                      0.9351, 0.9255, 0.9280, 0.9346, 0.9215, 0.9295, 0.9352, 0.9313, 0.9418,\n",
       "                      0.9272, 0.9320, 0.9389, 0.9301, 0.9297, 0.9343, 0.9301, 0.9288, 0.9258,\n",
       "                      0.9319, 0.9302, 0.9290, 0.9238, 0.9275, 0.9630, 0.9225, 0.9329, 0.9323,\n",
       "                      0.9285, 0.9333, 0.9331, 0.9321, 0.9310, 0.9382, 0.9300, 0.9329, 0.9332,\n",
       "                      0.9283, 0.9334, 0.9348, 0.9422])),\n",
       "             ('conv_block2.4.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block3.0.weight',\n",
       "              tensor([[[[-3.7561e-03, -9.3452e-03,  4.1063e-03],\n",
       "                        [ 2.6722e-02, -2.6803e-02, -2.2853e-02],\n",
       "                        [ 2.4806e-02,  7.2053e-04,  1.6061e-02]],\n",
       "              \n",
       "                       [[-2.1831e-02, -1.9689e-02,  2.3978e-03],\n",
       "                        [ 4.5653e-03, -1.4942e-02, -1.4825e-02],\n",
       "                        [ 2.3599e-02, -1.9337e-02,  2.7426e-02]],\n",
       "              \n",
       "                       [[-2.4814e-02, -1.2566e-02, -2.1365e-02],\n",
       "                        [ 3.9763e-04, -8.8494e-03,  1.0903e-02],\n",
       "                        [-5.0254e-03,  1.5562e-02,  8.8220e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.3557e-03,  2.4241e-02, -2.6354e-02],\n",
       "                        [ 1.1341e-02, -1.6165e-02, -2.0363e-02],\n",
       "                        [ 1.6838e-02,  1.7259e-02, -1.2539e-02]],\n",
       "              \n",
       "                       [[ 1.9946e-02,  1.1240e-03, -2.5051e-02],\n",
       "                        [-2.4939e-03,  1.3616e-03, -2.7086e-02],\n",
       "                        [-1.8486e-02, -2.5179e-03,  2.4681e-02]],\n",
       "              \n",
       "                       [[-1.8109e-02,  2.8584e-02, -2.2650e-03],\n",
       "                        [-5.8677e-03, -1.5877e-02, -1.1574e-02],\n",
       "                        [-9.5419e-03,  1.3241e-02, -6.5414e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3562e-02, -1.5715e-03, -5.2166e-03],\n",
       "                        [-2.4984e-02, -1.6190e-02,  1.1760e-02],\n",
       "                        [-2.1424e-02,  2.0946e-02, -8.9805e-03]],\n",
       "              \n",
       "                       [[-1.1841e-02, -1.0559e-02,  1.6374e-02],\n",
       "                        [ 1.6843e-03,  1.0615e-02, -1.9951e-02],\n",
       "                        [ 1.3880e-02, -1.6333e-02,  2.3567e-02]],\n",
       "              \n",
       "                       [[-1.5380e-03, -2.0129e-03,  2.0899e-02],\n",
       "                        [-1.0570e-02,  1.2534e-02,  4.0716e-04],\n",
       "                        [ 1.6661e-02, -1.9149e-02,  2.6100e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.8383e-02, -2.4418e-02,  1.6911e-02],\n",
       "                        [-2.2160e-02,  2.6587e-02, -1.4126e-02],\n",
       "                        [ 2.5588e-02,  2.8693e-02, -2.0298e-03]],\n",
       "              \n",
       "                       [[-8.9688e-03, -7.1451e-04, -5.8128e-05],\n",
       "                        [ 2.3059e-02, -2.0553e-02,  1.0530e-02],\n",
       "                        [ 2.6560e-02,  1.5975e-02, -2.7697e-03]],\n",
       "              \n",
       "                       [[-6.2334e-03, -8.6343e-03,  9.3042e-03],\n",
       "                        [-1.5089e-02, -2.8355e-02,  2.0637e-02],\n",
       "                        [-2.0921e-02, -5.0585e-03,  1.5994e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8966e-02, -1.1173e-02, -7.9839e-03],\n",
       "                        [-1.9029e-02,  9.9184e-03, -1.1863e-02],\n",
       "                        [ 6.6091e-03, -3.9415e-03, -4.4392e-03]],\n",
       "              \n",
       "                       [[-8.1391e-03,  2.0337e-02,  2.8115e-02],\n",
       "                        [ 2.0227e-02,  1.7648e-02, -3.4004e-03],\n",
       "                        [ 1.5845e-02, -2.8451e-02,  1.1010e-02]],\n",
       "              \n",
       "                       [[ 2.3984e-02,  1.9249e-02, -2.1208e-04],\n",
       "                        [ 2.8071e-02, -1.9487e-02,  2.7776e-03],\n",
       "                        [ 2.4307e-02, -1.0551e-02, -6.4349e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0878e-02, -2.6319e-02, -2.3782e-02],\n",
       "                        [-2.8817e-02, -2.2621e-02, -2.3782e-02],\n",
       "                        [ 2.9386e-02, -2.7876e-02, -1.1028e-02]],\n",
       "              \n",
       "                       [[ 1.5579e-02,  9.2978e-03,  1.6094e-02],\n",
       "                        [ 4.2167e-03, -1.6183e-02, -1.8227e-02],\n",
       "                        [ 1.7407e-02,  7.0180e-03, -1.5019e-02]],\n",
       "              \n",
       "                       [[ 2.7103e-03, -1.7920e-02,  1.1412e-02],\n",
       "                        [-2.5104e-02,  2.7275e-02, -8.7828e-04],\n",
       "                        [-1.2711e-02,  1.4394e-02, -1.0741e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.2106e-02,  9.5402e-03,  2.3409e-02],\n",
       "                        [ 1.9970e-02, -1.0469e-02,  1.6868e-02],\n",
       "                        [ 8.0703e-03,  1.9612e-02,  1.1165e-02]],\n",
       "              \n",
       "                       [[ 2.5763e-02,  2.6195e-03,  4.2171e-03],\n",
       "                        [ 8.7625e-03,  1.2893e-02, -2.7738e-02],\n",
       "                        [-1.2182e-02,  1.3122e-02, -5.7709e-03]],\n",
       "              \n",
       "                       [[-2.0998e-02, -1.8978e-02, -1.5146e-02],\n",
       "                        [ 5.2175e-03, -2.8918e-02, -2.3139e-02],\n",
       "                        [-1.7493e-02,  4.1456e-03,  2.8571e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.5357e-02, -1.8746e-02,  1.3039e-02],\n",
       "                        [-1.1562e-02, -7.4286e-04,  1.6810e-02],\n",
       "                        [-1.7501e-02, -1.3512e-02,  1.2023e-02]],\n",
       "              \n",
       "                       [[ 1.3479e-02,  1.9706e-02,  2.9405e-03],\n",
       "                        [ 2.6721e-02,  4.8281e-03, -1.9764e-03],\n",
       "                        [-1.1439e-02, -1.2210e-02, -2.0545e-02]],\n",
       "              \n",
       "                       [[ 1.5445e-02, -1.1388e-02,  9.9367e-03],\n",
       "                        [ 1.8199e-02, -8.1579e-03, -1.3190e-02],\n",
       "                        [-1.5324e-02,  6.0683e-03, -1.4993e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1983e-03, -2.8501e-02,  7.2434e-03],\n",
       "                        [-2.4011e-02,  1.0066e-02, -1.6804e-03],\n",
       "                        [ 8.3762e-03,  1.3817e-02, -1.1086e-02]],\n",
       "              \n",
       "                       [[-1.4884e-02, -2.0937e-02,  2.8626e-03],\n",
       "                        [-1.5899e-03, -6.2759e-03,  2.8447e-02],\n",
       "                        [-2.0151e-02,  4.3624e-03,  1.7088e-02]],\n",
       "              \n",
       "                       [[-6.3591e-03, -1.0221e-02,  3.8361e-03],\n",
       "                        [ 4.7676e-03,  5.0335e-03, -1.7902e-02],\n",
       "                        [ 1.2236e-04, -1.1794e-02,  7.0604e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.7217e-04, -5.3144e-03,  2.4296e-02],\n",
       "                        [-4.9810e-03, -1.7488e-02, -1.1723e-02],\n",
       "                        [ 1.7695e-03,  2.6688e-02, -3.6749e-03]],\n",
       "              \n",
       "                       [[ 1.2394e-02, -4.3959e-03, -2.8418e-02],\n",
       "                        [-1.1515e-02,  2.1002e-02, -2.8996e-03],\n",
       "                        [-1.0720e-02, -1.4121e-03, -2.8501e-02]],\n",
       "              \n",
       "                       [[-1.4649e-02, -1.6968e-02,  1.7228e-02],\n",
       "                        [ 1.7258e-02, -4.0975e-03,  4.5985e-03],\n",
       "                        [-8.5723e-03,  2.3705e-02,  6.8362e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6672e-02, -2.6314e-02,  1.7838e-02],\n",
       "                        [-1.3717e-02,  2.5126e-03,  2.8001e-02],\n",
       "                        [-1.1327e-02, -4.0384e-03, -1.1303e-02]],\n",
       "              \n",
       "                       [[-1.6664e-02, -1.5283e-02, -3.4676e-03],\n",
       "                        [ 1.8518e-03, -9.7692e-03, -1.1817e-02],\n",
       "                        [-2.9153e-02, -2.1681e-02, -2.8474e-02]],\n",
       "              \n",
       "                       [[-1.6770e-02, -2.6642e-02, -7.4755e-03],\n",
       "                        [ 7.0861e-04,  1.1783e-02, -2.5170e-02],\n",
       "                        [-4.5598e-03,  2.6743e-02, -2.8793e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8664e-03, -2.3528e-02, -2.8028e-02],\n",
       "                        [ 2.0714e-02,  4.1569e-03,  2.6323e-02],\n",
       "                        [ 1.6266e-02, -2.3928e-02, -2.6085e-02]],\n",
       "              \n",
       "                       [[ 8.7670e-03,  1.2252e-02, -2.1036e-02],\n",
       "                        [-1.0621e-02,  2.2374e-02,  2.1035e-02],\n",
       "                        [ 1.7641e-02, -6.1855e-03, -2.6112e-02]],\n",
       "              \n",
       "                       [[ 1.2216e-02,  3.9195e-03,  1.3033e-02],\n",
       "                        [-8.2480e-03, -7.2145e-03,  1.1478e-02],\n",
       "                        [ 7.1156e-03,  1.4873e-02,  2.1405e-02]]]])),\n",
       "             ('conv_block3.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block3.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('conv_block3.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block3.1.running_mean',\n",
       "              tensor([ 6.0154e-02, -6.5550e-02,  3.6607e-02,  3.8252e-02, -4.5880e-02,\n",
       "                      -2.3174e-03, -8.0678e-03,  4.0649e-02,  1.3214e-02, -8.3070e-02,\n",
       "                      -6.2964e-02,  1.4137e-02, -4.0025e-02,  9.1985e-02,  1.7575e-02,\n",
       "                       1.1517e-02,  2.0259e-02, -4.5860e-02,  5.7312e-03,  5.0787e-03,\n",
       "                       9.2709e-02,  5.2231e-03, -2.8879e-02, -9.9116e-02, -5.8688e-02,\n",
       "                       1.6652e-02, -1.0410e-02,  8.1798e-04,  7.4473e-03, -1.7744e-02,\n",
       "                      -1.1042e-02, -4.7249e-02, -1.6613e-02, -2.7834e-02, -7.0562e-02,\n",
       "                      -1.6424e-02, -3.8059e-02, -1.6953e-02,  1.5391e-03,  2.9800e-02,\n",
       "                      -2.1431e-02,  9.2055e-02, -3.2728e-02, -3.6509e-02,  3.3794e-02,\n",
       "                       4.4485e-02,  5.3499e-02,  2.0464e-02, -1.7851e-02,  8.6834e-03,\n",
       "                      -5.8182e-02,  4.1286e-02,  2.4970e-04,  5.2151e-02,  5.9732e-02,\n",
       "                       4.3794e-02,  6.4208e-02, -1.5474e-02,  1.1792e-01, -5.3799e-02,\n",
       "                       4.5426e-02,  3.0331e-02,  2.1915e-02,  6.0788e-02,  2.1310e-02,\n",
       "                      -1.8724e-02, -5.7355e-02, -5.2524e-03, -5.9095e-02,  8.3691e-03,\n",
       "                      -4.8615e-02,  4.2800e-02, -6.8601e-03, -9.2086e-02, -1.3764e-02,\n",
       "                      -7.6166e-02, -1.2012e-02,  5.7872e-02,  3.1187e-02,  3.6608e-03,\n",
       "                      -6.3842e-02, -4.9785e-02,  1.5562e-02, -4.7327e-02, -7.1461e-02,\n",
       "                      -5.2933e-02, -3.3125e-02,  5.0864e-03, -2.4696e-03, -2.4277e-02,\n",
       "                       2.1847e-02, -5.7199e-02,  1.2195e-01, -2.0066e-02, -9.8692e-03,\n",
       "                      -8.7013e-04,  2.1631e-03, -5.7598e-02, -8.9709e-03, -5.3993e-02,\n",
       "                       9.4266e-02,  4.5375e-02,  3.3718e-02, -1.5878e-02, -7.8460e-02,\n",
       "                       1.5236e-02, -5.4097e-02,  8.4552e-02, -6.0249e-02, -5.5932e-02,\n",
       "                       2.0821e-02, -5.4055e-02,  3.5754e-02, -2.4238e-02,  9.7687e-03,\n",
       "                      -3.4502e-02, -8.9198e-03,  2.4639e-02,  2.4081e-02,  4.6278e-02,\n",
       "                      -4.2990e-02,  1.5717e-02, -9.6284e-02, -3.8109e-02,  1.0299e-03,\n",
       "                       1.4289e-02, -1.0821e-01, -6.7830e-02, -1.0637e-02, -2.8602e-02,\n",
       "                      -3.6518e-02,  4.8489e-02,  4.1504e-02,  6.8609e-02,  1.3037e-01,\n",
       "                      -2.4710e-02,  5.4337e-02,  1.1582e-03, -5.6614e-02,  2.4308e-02,\n",
       "                       2.0860e-03, -3.1141e-02,  3.1538e-05,  7.5159e-04,  2.5499e-02,\n",
       "                       1.4647e-02, -6.4163e-03,  5.5338e-02,  5.1747e-02, -4.9919e-02,\n",
       "                       8.7476e-03,  4.1817e-02,  3.6063e-02,  5.3711e-02, -7.5299e-02,\n",
       "                       4.0882e-02, -5.1284e-02, -1.8303e-02, -5.4548e-02, -3.3790e-02,\n",
       "                      -3.8830e-02, -1.5030e-02, -1.6965e-02, -3.1404e-02, -3.1161e-02,\n",
       "                      -8.1166e-02, -2.4758e-02,  1.1177e-01,  8.8903e-02,  7.7434e-03,\n",
       "                      -7.5186e-02, -4.8434e-02, -1.4115e-01,  1.3380e-02, -6.0405e-02,\n",
       "                      -4.3744e-02, -9.8538e-02,  4.9747e-03,  1.2941e-02, -5.2870e-02,\n",
       "                       6.4332e-02, -9.5237e-02, -4.4330e-02,  1.0291e-01,  1.8426e-02,\n",
       "                       5.2690e-02,  5.8444e-02, -1.0659e-03, -2.5688e-02, -3.5319e-02,\n",
       "                      -8.8030e-02, -1.2280e-02, -2.7861e-02,  3.2790e-02,  1.8014e-02,\n",
       "                      -8.1057e-02,  1.8153e-02, -7.4836e-02, -5.3918e-02, -3.2949e-02,\n",
       "                      -8.4360e-02,  4.8611e-02, -5.7892e-03, -2.6436e-02,  3.9655e-02,\n",
       "                       1.6525e-03,  5.9846e-02,  4.2851e-02, -7.3460e-02, -6.8897e-02,\n",
       "                      -2.8564e-02, -7.9406e-02, -8.5521e-03,  5.4193e-02,  6.6272e-03,\n",
       "                       1.3237e-01,  3.7284e-02,  1.0275e-01, -6.4866e-02, -5.6067e-02,\n",
       "                      -5.1486e-02,  2.6754e-02, -6.2331e-02,  2.1897e-02, -7.7958e-02,\n",
       "                       2.4083e-02,  1.5637e-03,  8.7677e-03, -2.9389e-02, -6.1979e-03,\n",
       "                       5.4836e-02,  4.6342e-02, -3.9392e-02,  4.4530e-02,  4.5521e-03,\n",
       "                      -1.0989e-01,  1.0242e-01, -5.3666e-02,  3.8758e-02, -3.4263e-02,\n",
       "                      -7.5552e-02,  4.4673e-02,  4.9932e-03,  1.6047e-02,  1.0866e-02,\n",
       "                       3.5756e-03, -1.8473e-02, -1.1620e-02, -3.0323e-02,  6.5040e-02,\n",
       "                      -7.6469e-02, -1.6639e-02, -6.7387e-02, -6.9180e-02, -2.1877e-03,\n",
       "                       1.3653e-02, -8.0687e-02, -4.3173e-02, -3.4206e-02,  2.0628e-02,\n",
       "                       8.8381e-02, -4.4930e-02,  1.2616e-02, -3.1655e-02, -2.8134e-02,\n",
       "                      -7.5822e-02,  2.4681e-02, -3.8854e-02, -3.4178e-02,  1.5667e-02,\n",
       "                      -2.4623e-02, -1.6284e-02,  3.0871e-02,  4.1176e-02,  3.8802e-03,\n",
       "                       1.0430e-01,  1.5247e-02, -6.6870e-02,  5.2919e-02, -1.5377e-02,\n",
       "                      -9.1274e-02,  1.1297e-02, -8.7422e-02,  4.6522e-02, -5.0238e-02,\n",
       "                      -2.6780e-02, -1.1937e-02,  1.5677e-02,  6.6715e-02, -3.5820e-02,\n",
       "                       4.2979e-02, -3.7686e-02, -5.3561e-02,  1.3259e-02, -5.2178e-02,\n",
       "                       3.7430e-02, -1.7369e-02, -2.4874e-03, -1.1554e-02, -2.6923e-02,\n",
       "                       2.8916e-02,  2.3472e-02, -4.1229e-02,  1.9077e-02,  1.5129e-01,\n",
       "                       1.9047e-02, -7.8898e-02, -6.3587e-02,  1.2495e-02, -8.5662e-02,\n",
       "                      -6.1429e-03, -3.6131e-02,  1.3792e-02,  1.5445e-02,  4.5322e-02,\n",
       "                      -5.1133e-02, -3.1404e-02,  2.1155e-02,  1.0330e-02, -7.4563e-02,\n",
       "                      -5.3628e-02,  4.0495e-02, -6.3879e-02,  1.8444e-02, -3.9716e-02,\n",
       "                       3.5740e-02, -1.1411e-02,  1.3213e-02,  1.3543e-01, -1.2438e-02,\n",
       "                       5.8660e-02, -1.1367e-01,  2.7355e-02, -4.4389e-02, -2.4932e-02,\n",
       "                       2.5520e-02, -3.4407e-02,  4.9679e-04, -2.2895e-02,  8.7855e-02,\n",
       "                      -2.1393e-02,  1.2906e-02,  1.9696e-02,  4.1740e-02,  1.1497e-02,\n",
       "                      -2.6430e-02, -2.6478e-02,  3.3405e-02, -9.3900e-02, -3.7020e-04,\n",
       "                       3.4858e-02,  6.3552e-04,  2.5315e-02,  1.0691e-01, -3.5211e-02,\n",
       "                      -8.0438e-03,  5.8794e-03,  4.5113e-02,  4.9435e-02,  2.1057e-02,\n",
       "                       1.7089e-02,  1.0659e-02,  1.2249e-01, -7.4722e-02,  8.8073e-02,\n",
       "                       1.1458e-01,  6.4030e-02, -5.0565e-03, -5.3329e-02,  7.9061e-02,\n",
       "                       5.4423e-03,  4.1977e-02,  7.1531e-02, -2.0139e-02, -1.1014e-02,\n",
       "                       1.2221e-02, -9.0418e-04, -1.8684e-02,  8.5996e-02,  7.8620e-02,\n",
       "                      -3.9714e-02,  6.6539e-02, -1.5890e-03,  1.0207e-01, -3.5688e-02,\n",
       "                       2.7713e-02, -5.5955e-03,  1.2640e-02,  4.8043e-03, -6.0360e-02,\n",
       "                      -1.0240e-01,  1.5960e-02, -6.5380e-03, -5.1762e-02,  8.2388e-02,\n",
       "                      -5.6092e-03, -1.0381e-01, -1.0033e-01, -3.5831e-02, -5.2148e-02,\n",
       "                      -4.4464e-03,  7.0923e-02, -9.0165e-03, -6.7396e-02,  1.0776e-01,\n",
       "                       5.1244e-02,  1.0376e-02,  5.6393e-04, -5.3677e-02,  6.2511e-02,\n",
       "                      -1.0632e-02, -5.9334e-03,  3.4147e-02,  1.9506e-02,  1.6335e-02,\n",
       "                       7.2899e-03, -8.7387e-02,  5.4809e-02, -6.3237e-03,  2.2546e-02,\n",
       "                      -1.3972e-01, -2.3627e-02,  4.4019e-03, -4.7491e-02, -1.5671e-02,\n",
       "                       2.1331e-02, -1.3340e-02, -4.9717e-02, -5.5703e-02,  1.7071e-02,\n",
       "                       4.5392e-02, -1.6409e-02, -3.7753e-02, -2.8589e-02, -1.2487e-02,\n",
       "                      -4.0659e-02, -3.6802e-02,  6.5180e-02, -1.6992e-02, -2.9766e-02,\n",
       "                      -1.1403e-02, -1.0588e-02,  2.7094e-02, -2.6681e-02, -1.1835e-02,\n",
       "                       2.9245e-02, -4.0267e-03, -4.8826e-02, -6.8789e-02, -7.6195e-03,\n",
       "                       1.3826e-02,  4.9897e-02, -1.2953e-01, -1.9999e-02,  7.6610e-02,\n",
       "                      -1.4860e-02,  2.7865e-02,  1.4037e-02, -4.3991e-02, -3.8017e-02,\n",
       "                       5.9425e-03, -7.9806e-02,  4.4311e-02,  4.0857e-02,  4.7585e-02,\n",
       "                      -1.0988e-01,  5.5319e-02,  6.5071e-02,  3.9680e-02,  2.5475e-03,\n",
       "                      -4.2171e-02, -5.2696e-02, -4.2151e-02,  4.9522e-02, -2.1915e-02,\n",
       "                      -1.9463e-02, -1.9447e-02, -5.4550e-02, -8.0984e-02, -2.2003e-02,\n",
       "                       6.2838e-02,  1.3809e-01, -2.2306e-02, -5.2269e-02,  4.3763e-02,\n",
       "                      -2.7703e-02,  5.7533e-02,  1.1229e-01, -4.9928e-02, -5.5067e-02,\n",
       "                       3.3240e-03,  9.6391e-03, -7.2059e-02, -3.4158e-02,  2.1432e-02,\n",
       "                      -2.7506e-02, -4.0796e-02,  1.7014e-02,  1.1617e-02,  2.4709e-03,\n",
       "                      -9.6258e-03, -4.3769e-02,  1.4589e-02, -7.7993e-02,  2.8752e-02,\n",
       "                       7.7428e-03,  5.2973e-02, -3.1115e-02, -1.3859e-02,  1.1447e-01,\n",
       "                      -7.5906e-02, -9.1313e-03])),\n",
       "             ('conv_block3.1.running_var',\n",
       "              tensor([0.9324, 0.9459, 0.9364, 0.9254, 0.9381, 0.9316, 0.9371, 0.9329, 0.9271,\n",
       "                      0.9251, 0.9355, 0.9296, 0.9385, 0.9438, 0.9402, 0.9297, 0.9295, 0.9286,\n",
       "                      0.9327, 0.9372, 0.9366, 0.9296, 0.9289, 0.9384, 0.9270, 0.9323, 0.9368,\n",
       "                      0.9379, 0.9277, 0.9296, 0.9335, 0.9710, 0.9304, 0.9326, 0.9528, 0.9314,\n",
       "                      0.9323, 0.9330, 0.9381, 0.9292, 0.9406, 0.9405, 0.9278, 0.9291, 0.9293,\n",
       "                      0.9336, 0.9349, 0.9344, 0.9407, 0.9216, 0.9302, 0.9423, 0.9494, 0.9313,\n",
       "                      0.9326, 0.9348, 0.9406, 0.9244, 0.9593, 0.9253, 0.9404, 0.9339, 0.9432,\n",
       "                      0.9391, 0.9300, 0.9246, 0.9343, 0.9294, 0.9331, 0.9369, 0.9317, 0.9271,\n",
       "                      0.9263, 0.9502, 0.9275, 0.9441, 0.9399, 0.9437, 0.9391, 0.9254, 0.9276,\n",
       "                      0.9271, 0.9371, 0.9327, 0.9312, 0.9427, 0.9357, 0.9330, 0.9334, 0.9322,\n",
       "                      0.9343, 0.9302, 0.9453, 0.9497, 0.9268, 0.9376, 0.9301, 0.9425, 0.9416,\n",
       "                      0.9306, 0.9644, 0.9314, 0.9352, 0.9339, 0.9502, 0.9296, 0.9400, 0.9421,\n",
       "                      0.9491, 0.9298, 0.9351, 0.9275, 0.9306, 0.9336, 0.9351, 0.9385, 0.9257,\n",
       "                      0.9331, 0.9381, 0.9321, 0.9421, 0.9337, 0.9556, 0.9348, 0.9391, 0.9376,\n",
       "                      0.9449, 0.9309, 0.9320, 0.9379, 0.9489, 0.9316, 0.9323, 0.9386, 0.9429,\n",
       "                      0.9291, 0.9473, 0.9420, 0.9445, 0.9430, 0.9328, 0.9373, 0.9261, 0.9340,\n",
       "                      0.9300, 0.9328, 0.9256, 0.9329, 0.9681, 0.9272, 0.9369, 0.9462, 0.9354,\n",
       "                      0.9311, 0.9507, 0.9430, 0.9569, 0.9323, 0.9324, 0.9304, 0.9344, 0.9297,\n",
       "                      0.9327, 0.9367, 0.9348, 0.9361, 0.9330, 0.9414, 0.9501, 0.9263, 0.9278,\n",
       "                      0.9328, 0.9518, 0.9339, 0.9404, 0.9322, 0.9493, 0.9289, 0.9266, 0.9412,\n",
       "                      0.9444, 0.9488, 0.9238, 0.9372, 0.9527, 0.9359, 0.9303, 0.9360, 0.9423,\n",
       "                      0.9260, 0.9544, 0.9285, 0.9348, 0.9301, 0.9505, 0.9472, 0.9397, 0.9382,\n",
       "                      0.9412, 0.9360, 0.9317, 0.9311, 0.9329, 0.9321, 0.9251, 0.9268, 0.9305,\n",
       "                      0.9236, 0.9533, 0.9364, 0.9278, 0.9255, 0.9342, 0.9310, 0.9527, 0.9460,\n",
       "                      0.9252, 0.9358, 0.9517, 0.9432, 0.9298, 0.9333, 0.9471, 0.9332, 0.9309,\n",
       "                      0.9277, 0.9354, 0.9437, 0.9269, 0.9281, 0.9331, 0.9402, 0.9323, 0.9303,\n",
       "                      0.9254, 0.9453, 0.9346, 0.9382, 0.9496, 0.9361, 0.9460, 0.9276, 0.9388,\n",
       "                      0.9367, 0.9481, 0.9275, 0.9361, 0.9352, 0.9259, 0.9322, 0.9312, 0.9288,\n",
       "                      0.9358, 0.9293, 0.9335, 0.9380, 0.9373, 0.9309, 0.9258, 0.9379, 0.9387,\n",
       "                      0.9488, 0.9287, 0.9342, 0.9475, 0.9355, 0.9317, 0.9374, 0.9329, 0.9398,\n",
       "                      0.9354, 0.9337, 0.9247, 0.9402, 0.9277, 0.9431, 0.9303, 0.9310, 0.9334,\n",
       "                      0.9323, 0.9506, 0.9347, 0.9386, 0.9332, 0.9418, 0.9272, 0.9496, 0.9317,\n",
       "                      0.9456, 0.9367, 0.9332, 0.9348, 0.9348, 0.9367, 0.9337, 0.9341, 0.9284,\n",
       "                      0.9382, 0.9333, 0.9296, 0.9327, 0.9315, 0.9416, 0.9307, 0.9529, 0.9324,\n",
       "                      0.9389, 0.9350, 0.9416, 0.9452, 0.9369, 0.9350, 0.9319, 0.9372, 0.9472,\n",
       "                      0.9303, 0.9314, 0.9364, 0.9383, 0.9596, 0.9299, 0.9314, 0.9620, 0.9319,\n",
       "                      0.9277, 0.9353, 0.9366, 0.9350, 0.9373, 0.9323, 0.9488, 0.9451, 0.9283,\n",
       "                      0.9379, 0.9275, 0.9442, 0.9525, 0.9299, 0.9284, 0.9681, 0.9318, 0.9333,\n",
       "                      0.9311, 0.9311, 0.9473, 0.9313, 0.9261, 0.9434, 0.9460, 0.9280, 0.9313,\n",
       "                      0.9239, 0.9239, 0.9463, 0.9467, 0.9352, 0.9243, 0.9330, 0.9306, 0.9292,\n",
       "                      0.9393, 0.9418, 0.9459, 0.9389, 0.9327, 0.9386, 0.9609, 0.9337, 0.9404,\n",
       "                      0.9349, 0.9277, 0.9433, 0.9391, 0.9421, 0.9359, 0.9402, 0.9312, 0.9462,\n",
       "                      0.9299, 0.9514, 0.9465, 0.9391, 0.9493, 0.9509, 0.9257, 0.9442, 0.9270,\n",
       "                      0.9309, 0.9258, 0.9363, 0.9481, 0.9290, 0.9291, 0.9318, 0.9369, 0.9475,\n",
       "                      0.9472, 0.9343, 0.9359, 0.9341, 0.9390, 0.9338, 0.9374, 0.9287, 0.9589,\n",
       "                      0.9325, 0.9378, 0.9416, 0.9375, 0.9362, 0.9336, 0.9270, 0.9351, 0.9307,\n",
       "                      0.9227, 0.9257, 0.9661, 0.9580, 0.9339, 0.9299, 0.9596, 0.9307, 0.9484,\n",
       "                      0.9402, 0.9303, 0.9288, 0.9293, 0.9296, 0.9217, 0.9239, 0.9263, 0.9339,\n",
       "                      0.9323, 0.9477, 0.9311, 0.9406, 0.9534, 0.9346, 0.9293, 0.9318, 0.9313,\n",
       "                      0.9228, 0.9464, 0.9315, 0.9309, 0.9293, 0.9395, 0.9327, 0.9386, 0.9457,\n",
       "                      0.9278, 0.9338, 0.9434, 0.9391, 0.9311, 0.9240, 0.9360, 0.9351, 0.9406,\n",
       "                      0.9269, 0.9265, 0.9455, 0.9377, 0.9350, 0.9407, 0.9598, 0.9303, 0.9334,\n",
       "                      0.9384, 0.9251, 0.9291, 0.9301, 0.9342, 0.9311, 0.9365, 0.9220, 0.9351,\n",
       "                      0.9352, 0.9549, 0.9288, 0.9388, 0.9669, 0.9287, 0.9364, 0.9347, 0.9387,\n",
       "                      0.9404, 0.9511, 0.9466, 0.9360, 0.9277, 0.9321, 0.9343, 0.9407, 0.9316,\n",
       "                      0.9355, 0.9340, 0.9373, 0.9290, 0.9322, 0.9367, 0.9429, 0.9309, 0.9434,\n",
       "                      0.9310, 0.9283, 0.9350, 0.9428, 0.9338, 0.9273, 0.9534, 0.9367])),\n",
       "             ('conv_block3.1.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block3.3.weight',\n",
       "              tensor([[[[ 0.0135, -0.0144, -0.0048],\n",
       "                        [ 0.0241,  0.0073, -0.0035],\n",
       "                        [-0.0121,  0.0233,  0.0146]],\n",
       "              \n",
       "                       [[ 0.0113,  0.0080,  0.0094],\n",
       "                        [-0.0132, -0.0018, -0.0195],\n",
       "                        [ 0.0203, -0.0149, -0.0229]],\n",
       "              \n",
       "                       [[-0.0190,  0.0113, -0.0205],\n",
       "                        [-0.0054,  0.0049,  0.0227],\n",
       "                        [ 0.0191,  0.0057,  0.0139]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0168,  0.0192,  0.0080],\n",
       "                        [-0.0194,  0.0052,  0.0033],\n",
       "                        [ 0.0081, -0.0180, -0.0128]],\n",
       "              \n",
       "                       [[-0.0037,  0.0020, -0.0194],\n",
       "                        [ 0.0184,  0.0156, -0.0148],\n",
       "                        [ 0.0094,  0.0067,  0.0195]],\n",
       "              \n",
       "                       [[-0.0081, -0.0153, -0.0165],\n",
       "                        [ 0.0165,  0.0199,  0.0181],\n",
       "                        [ 0.0077, -0.0005, -0.0103]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0187, -0.0230, -0.0152],\n",
       "                        [-0.0026,  0.0017,  0.0136],\n",
       "                        [-0.0037, -0.0212,  0.0151]],\n",
       "              \n",
       "                       [[ 0.0085, -0.0097, -0.0083],\n",
       "                        [ 0.0098,  0.0055,  0.0166],\n",
       "                        [-0.0099,  0.0226,  0.0214]],\n",
       "              \n",
       "                       [[ 0.0099, -0.0004, -0.0149],\n",
       "                        [ 0.0058,  0.0215, -0.0104],\n",
       "                        [-0.0217, -0.0002, -0.0228]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0153, -0.0108,  0.0246],\n",
       "                        [ 0.0137, -0.0125,  0.0084],\n",
       "                        [ 0.0046,  0.0096,  0.0019]],\n",
       "              \n",
       "                       [[ 0.0180, -0.0210, -0.0191],\n",
       "                        [ 0.0060, -0.0017,  0.0156],\n",
       "                        [ 0.0165, -0.0204, -0.0248]],\n",
       "              \n",
       "                       [[ 0.0140, -0.0193, -0.0078],\n",
       "                        [-0.0228,  0.0111, -0.0097],\n",
       "                        [-0.0149,  0.0080,  0.0164]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0106,  0.0214,  0.0070],\n",
       "                        [-0.0057,  0.0118, -0.0203],\n",
       "                        [-0.0140,  0.0056,  0.0166]],\n",
       "              \n",
       "                       [[ 0.0191, -0.0045, -0.0200],\n",
       "                        [-0.0050,  0.0154, -0.0121],\n",
       "                        [ 0.0179,  0.0003, -0.0114]],\n",
       "              \n",
       "                       [[ 0.0181, -0.0154,  0.0199],\n",
       "                        [ 0.0042, -0.0157,  0.0251],\n",
       "                        [-0.0225, -0.0017, -0.0127]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0078, -0.0215, -0.0242],\n",
       "                        [ 0.0170,  0.0215, -0.0056],\n",
       "                        [ 0.0182, -0.0123,  0.0081]],\n",
       "              \n",
       "                       [[ 0.0045, -0.0229,  0.0132],\n",
       "                        [-0.0193, -0.0022,  0.0104],\n",
       "                        [-0.0152,  0.0047,  0.0103]],\n",
       "              \n",
       "                       [[-0.0089, -0.0100,  0.0150],\n",
       "                        [ 0.0160, -0.0090, -0.0188],\n",
       "                        [-0.0018, -0.0199,  0.0199]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0184,  0.0090, -0.0193],\n",
       "                        [ 0.0226, -0.0037,  0.0150],\n",
       "                        [-0.0076,  0.0147,  0.0185]],\n",
       "              \n",
       "                       [[ 0.0063, -0.0166, -0.0113],\n",
       "                        [ 0.0075,  0.0218, -0.0167],\n",
       "                        [ 0.0078,  0.0066, -0.0254]],\n",
       "              \n",
       "                       [[ 0.0148, -0.0102, -0.0102],\n",
       "                        [ 0.0063,  0.0135,  0.0041],\n",
       "                        [-0.0064,  0.0110, -0.0142]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0220,  0.0029,  0.0200],\n",
       "                        [-0.0234,  0.0158,  0.0215],\n",
       "                        [ 0.0112, -0.0072,  0.0121]],\n",
       "              \n",
       "                       [[ 0.0132,  0.0233, -0.0066],\n",
       "                        [ 0.0046, -0.0193, -0.0093],\n",
       "                        [ 0.0005,  0.0047,  0.0141]],\n",
       "              \n",
       "                       [[-0.0167,  0.0021, -0.0106],\n",
       "                        [ 0.0098,  0.0251, -0.0141],\n",
       "                        [ 0.0103,  0.0211, -0.0115]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0206,  0.0107, -0.0023],\n",
       "                        [-0.0040, -0.0018, -0.0022],\n",
       "                        [ 0.0153,  0.0050, -0.0109]],\n",
       "              \n",
       "                       [[ 0.0236, -0.0089, -0.0093],\n",
       "                        [-0.0153,  0.0030, -0.0088],\n",
       "                        [-0.0121,  0.0030, -0.0138]],\n",
       "              \n",
       "                       [[ 0.0150, -0.0098,  0.0207],\n",
       "                        [-0.0173, -0.0175,  0.0069],\n",
       "                        [ 0.0076, -0.0069, -0.0120]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0195, -0.0253, -0.0059],\n",
       "                        [-0.0070,  0.0130,  0.0099],\n",
       "                        [-0.0145,  0.0144, -0.0158]],\n",
       "              \n",
       "                       [[ 0.0023, -0.0107,  0.0027],\n",
       "                        [-0.0027,  0.0044, -0.0086],\n",
       "                        [-0.0249, -0.0159, -0.0121]],\n",
       "              \n",
       "                       [[-0.0101, -0.0249,  0.0193],\n",
       "                        [ 0.0166, -0.0183, -0.0216],\n",
       "                        [ 0.0085, -0.0012, -0.0160]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0031,  0.0053,  0.0079],\n",
       "                        [-0.0154, -0.0030, -0.0043],\n",
       "                        [ 0.0146,  0.0002, -0.0229]],\n",
       "              \n",
       "                       [[-0.0065, -0.0239, -0.0019],\n",
       "                        [ 0.0077,  0.0198,  0.0146],\n",
       "                        [-0.0145,  0.0165, -0.0179]],\n",
       "              \n",
       "                       [[ 0.0229, -0.0254, -0.0077],\n",
       "                        [ 0.0201, -0.0132, -0.0120],\n",
       "                        [-0.0029,  0.0207,  0.0064]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0116,  0.0245, -0.0203],\n",
       "                        [-0.0019,  0.0141,  0.0060],\n",
       "                        [-0.0127,  0.0185,  0.0153]],\n",
       "              \n",
       "                       [[ 0.0090, -0.0112, -0.0055],\n",
       "                        [ 0.0124, -0.0211, -0.0018],\n",
       "                        [-0.0128, -0.0074,  0.0109]],\n",
       "              \n",
       "                       [[ 0.0177,  0.0180,  0.0058],\n",
       "                        [ 0.0014,  0.0070, -0.0095],\n",
       "                        [ 0.0192, -0.0012,  0.0143]]]])),\n",
       "             ('conv_block3.3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block3.4.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('conv_block3.4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block3.4.running_mean',\n",
       "              tensor([ 4.0969e-02, -1.0265e-02,  3.4720e-02,  1.4283e-02, -7.1431e-02,\n",
       "                       4.5517e-02, -3.8814e-02, -1.9074e-03,  6.3905e-03,  4.5584e-02,\n",
       "                       8.6441e-03, -3.0866e-02,  4.4859e-02,  6.7327e-02,  3.1912e-02,\n",
       "                      -1.4648e-03,  3.7340e-02, -3.7106e-02, -2.1887e-03,  4.0719e-03,\n",
       "                       6.3680e-03, -4.4740e-02, -8.1272e-03,  1.7607e-02, -7.3974e-02,\n",
       "                       1.2410e-02, -4.0106e-03, -1.1508e-02, -1.6548e-02,  2.9535e-03,\n",
       "                      -2.8643e-02,  3.6131e-02,  2.0181e-02,  8.6971e-03,  2.0082e-02,\n",
       "                       4.6686e-02,  5.4912e-02, -6.9948e-02, -1.2783e-02, -5.2717e-02,\n",
       "                       7.4278e-02, -4.6165e-02, -5.5791e-02, -9.5560e-03, -2.0881e-02,\n",
       "                       5.4220e-02,  1.1534e-02,  6.0157e-02, -1.0917e-02, -1.2612e-02,\n",
       "                       7.2560e-02, -2.4871e-02,  3.4326e-02, -6.9549e-02, -1.4660e-02,\n",
       "                      -1.6677e-02, -1.9263e-02,  9.4813e-02,  2.5448e-02,  3.5288e-02,\n",
       "                       4.6913e-02, -4.6999e-02, -9.7425e-03,  2.0102e-02, -6.3079e-02,\n",
       "                       1.4516e-02, -2.8309e-02,  2.4229e-02, -4.4666e-02,  5.2289e-03,\n",
       "                      -2.1489e-02,  8.0114e-03,  1.1523e-02,  7.8955e-03,  3.3963e-02,\n",
       "                       4.8687e-02, -3.3874e-02,  2.5314e-02,  2.2410e-02,  4.2289e-02,\n",
       "                       5.9225e-03,  3.7506e-02, -6.0638e-02,  9.3644e-03, -1.4205e-02,\n",
       "                       5.4864e-02,  1.4837e-02,  3.4257e-02, -8.7363e-03,  5.8893e-03,\n",
       "                      -2.4863e-03,  5.8081e-03,  1.9952e-02, -9.3351e-03, -2.6533e-02,\n",
       "                      -3.3534e-03,  1.0731e-02, -1.0025e-02, -8.9168e-03,  3.1261e-02,\n",
       "                       1.1148e-03,  2.9163e-02,  7.3266e-03,  5.6120e-03, -1.2941e-02,\n",
       "                       2.3985e-02,  2.9192e-02,  3.1326e-02,  1.4230e-02, -1.2691e-02,\n",
       "                      -1.0355e-02, -1.8300e-02,  1.2015e-02,  5.1825e-02,  8.9146e-03,\n",
       "                       4.8001e-02,  8.5299e-03,  8.1458e-02,  1.4364e-02,  1.4766e-02,\n",
       "                       3.0237e-03,  1.0632e-02,  1.4321e-02, -2.4867e-02,  7.8115e-04,\n",
       "                      -7.2019e-02, -6.7626e-02, -6.8954e-03, -1.1161e-01, -2.4434e-02,\n",
       "                      -3.7867e-02,  5.6833e-03, -2.7876e-02,  3.0159e-02,  8.4583e-03,\n",
       "                       1.0010e-02,  2.3214e-03,  2.8495e-02,  3.3396e-02,  2.5142e-02,\n",
       "                      -8.1355e-04, -3.6641e-02, -4.3027e-02,  3.3758e-02, -1.5031e-02,\n",
       "                       3.1789e-02, -1.3795e-02, -2.7905e-02, -1.2140e-02,  3.0192e-02,\n",
       "                       3.4659e-02,  3.6222e-02,  2.1118e-02, -9.3342e-03, -6.7853e-03,\n",
       "                       1.0802e-02, -3.3607e-03,  1.8651e-02, -1.6166e-02,  6.0579e-02,\n",
       "                      -3.9010e-03,  2.9254e-02,  2.6564e-02, -3.1725e-02, -3.0515e-02,\n",
       "                       1.2369e-02, -4.0615e-02,  3.3632e-02,  7.7057e-03,  4.5658e-02,\n",
       "                       2.2927e-02,  3.2243e-02,  4.9349e-02, -2.7279e-02,  3.6399e-02,\n",
       "                      -1.9470e-02,  6.4876e-02,  1.4073e-03,  1.5955e-02,  1.9358e-02,\n",
       "                      -1.8729e-02,  7.7247e-02, -7.4144e-04,  4.6143e-02, -7.3286e-02,\n",
       "                      -1.2140e-02, -3.8698e-02, -4.0890e-02,  3.2619e-03, -2.2669e-02,\n",
       "                      -1.4972e-02, -1.3032e-02,  3.9688e-03, -4.7444e-02,  1.2634e-02,\n",
       "                       2.7971e-02, -8.0032e-02,  2.5396e-02, -2.0481e-02,  3.4488e-02,\n",
       "                       3.3957e-02, -2.2343e-02,  5.8806e-02,  3.1933e-02,  8.8315e-03,\n",
       "                      -1.2739e-01, -2.6233e-02,  2.4871e-02, -3.0283e-02, -4.1642e-02,\n",
       "                       1.7438e-02,  1.3561e-02,  1.5835e-02, -4.2794e-02,  9.7865e-03,\n",
       "                      -5.0489e-02,  4.8624e-02,  6.3589e-02, -5.9436e-02, -3.5532e-02,\n",
       "                       5.5800e-02,  8.5159e-02,  2.0093e-02,  1.9779e-02, -3.3293e-03,\n",
       "                       4.7951e-02, -1.8917e-02, -4.6096e-02, -4.5372e-02, -6.2824e-02,\n",
       "                      -3.1954e-02,  5.5402e-03,  1.3028e-02, -2.9742e-02,  3.4752e-02,\n",
       "                       1.2536e-02,  2.6495e-02,  3.8174e-02, -1.4257e-02, -2.6313e-02,\n",
       "                      -1.7165e-03,  1.9736e-02, -1.6775e-02, -3.6442e-02, -2.5423e-02,\n",
       "                       6.8865e-03, -7.1032e-02, -3.7226e-02,  6.1170e-02,  3.1763e-02,\n",
       "                      -6.3278e-03,  1.1782e-02, -7.1094e-03,  5.7055e-02,  2.4529e-02,\n",
       "                      -8.4566e-02, -7.8380e-03, -3.0095e-02, -4.8367e-02, -7.9124e-03,\n",
       "                       1.0878e-02, -2.4661e-02,  4.0633e-02, -2.8134e-04,  2.7261e-03,\n",
       "                      -3.6263e-02, -1.4181e-02,  1.7136e-02,  4.8369e-02, -9.2727e-03,\n",
       "                       3.6478e-03,  1.7677e-02,  2.3284e-02,  4.1221e-02, -6.7179e-02,\n",
       "                      -1.2447e-02, -1.7171e-02,  2.0645e-02, -1.1937e-02,  2.0448e-02,\n",
       "                       7.3553e-02,  5.6736e-03,  1.7101e-02, -6.8099e-02, -2.8992e-02,\n",
       "                       2.6046e-02,  4.4568e-02, -5.4118e-02,  5.8639e-02,  8.2474e-03,\n",
       "                      -3.2903e-02, -2.9107e-02, -3.6888e-02,  9.8346e-04, -6.9235e-02,\n",
       "                       3.4701e-02,  4.4596e-02,  3.1123e-02, -2.1888e-02, -1.5830e-02,\n",
       "                       1.3364e-03,  1.2358e-02, -1.6016e-02, -8.7920e-02, -1.3771e-02,\n",
       "                       3.8863e-02,  5.4086e-02, -3.3582e-02, -3.0759e-03,  1.5397e-02,\n",
       "                      -4.5062e-02, -5.3262e-04,  5.5008e-03,  1.6167e-02, -4.7665e-03,\n",
       "                      -7.3519e-03,  1.0305e-02,  9.0160e-03,  2.7777e-03, -2.2498e-02,\n",
       "                       1.5505e-03,  1.0036e-01, -2.7916e-02,  1.9494e-02,  2.8484e-02,\n",
       "                       4.3200e-02, -3.5176e-02, -2.3420e-02, -2.4121e-02,  7.0739e-03,\n",
       "                       2.3491e-02, -1.0017e-03, -3.3092e-02, -4.5462e-02, -5.9494e-05,\n",
       "                       2.5988e-03, -6.2265e-02, -8.8472e-03,  3.0858e-02,  1.2734e-02,\n",
       "                      -6.2167e-02, -6.4280e-03,  2.0624e-02,  4.5189e-02, -1.4855e-02,\n",
       "                      -2.7384e-02,  1.0977e-02,  5.5518e-04, -4.6347e-02, -1.0003e-02,\n",
       "                       1.8372e-02,  3.7459e-03, -5.0499e-02, -8.6446e-03,  1.2013e-02,\n",
       "                      -4.1205e-02, -1.9036e-02, -4.7543e-02, -4.0763e-02,  2.8023e-03,\n",
       "                      -1.5593e-03, -2.6641e-02, -7.9147e-03,  3.5857e-02, -2.0494e-02,\n",
       "                      -1.7453e-02, -3.7775e-02, -1.4541e-02,  4.7034e-02,  2.1442e-02,\n",
       "                      -3.5084e-02, -6.2790e-02,  3.5455e-02,  1.0568e-02, -1.5199e-02,\n",
       "                       3.0507e-02,  1.7711e-02,  9.5641e-03,  4.7661e-02, -7.8941e-03,\n",
       "                       1.4488e-02,  1.9878e-02, -2.2783e-02, -3.4557e-03, -2.3033e-02,\n",
       "                      -1.3504e-02,  5.4811e-02,  6.3014e-02, -1.8682e-02, -4.6414e-03,\n",
       "                       2.2256e-02, -1.2911e-02, -2.9815e-02, -2.0291e-02,  2.2959e-02,\n",
       "                       8.9825e-03,  1.4579e-02, -9.8733e-03,  1.9408e-02,  3.2957e-02,\n",
       "                      -4.7074e-02,  1.1795e-01, -2.9174e-02, -3.6606e-02,  5.7172e-02,\n",
       "                       4.1697e-02,  6.5676e-04, -3.6069e-02, -7.8170e-02, -5.6264e-02,\n",
       "                      -1.9710e-02,  1.5048e-02,  5.8537e-02, -6.7313e-02,  1.7757e-02,\n",
       "                      -3.0801e-02, -1.3249e-03,  8.6951e-03, -6.3915e-02, -2.2443e-02,\n",
       "                      -1.4820e-02,  8.0374e-02,  4.9171e-03, -3.6564e-03,  1.2244e-03,\n",
       "                       1.0471e-02,  1.3476e-02, -1.8299e-02,  1.9122e-02,  1.7718e-02,\n",
       "                       1.6899e-02, -3.3899e-02, -2.4375e-02, -6.6402e-03, -1.7634e-02,\n",
       "                      -2.2439e-02, -4.7366e-02, -4.4191e-02, -3.5731e-02, -1.3968e-02,\n",
       "                      -1.3031e-02, -1.3659e-02, -1.0707e-02, -4.2347e-02,  3.4186e-02,\n",
       "                      -2.3141e-02, -4.4972e-02,  1.4067e-02, -3.5293e-02,  1.5649e-02,\n",
       "                      -3.2323e-03,  6.3922e-02,  3.3067e-03,  3.1648e-02,  1.2067e-02,\n",
       "                      -1.2099e-02, -5.5715e-02,  1.8411e-02,  1.9058e-03,  5.7627e-02,\n",
       "                      -3.2830e-02, -6.1543e-02, -2.7153e-02,  4.7463e-02, -6.0514e-02,\n",
       "                      -1.8426e-02, -1.1478e-02,  4.0198e-02, -2.5654e-02, -2.5561e-02,\n",
       "                       3.8557e-03, -4.8012e-04,  1.4035e-02,  3.0774e-02, -5.1342e-03,\n",
       "                      -7.5601e-02,  4.8854e-02,  6.8919e-03,  4.3454e-02,  8.8455e-03,\n",
       "                       6.6771e-02,  6.5137e-03,  1.8278e-02, -1.9473e-02, -2.7564e-03,\n",
       "                      -1.0314e-02,  3.8207e-02, -4.6797e-02, -6.8215e-02, -2.9269e-02,\n",
       "                       2.4262e-02,  4.0924e-03,  1.2639e-02,  2.0342e-02, -3.4947e-02,\n",
       "                       3.5469e-02, -3.0319e-02,  8.1248e-02,  2.3083e-02,  9.9874e-05,\n",
       "                       1.2387e-04, -4.3060e-02,  2.9483e-03,  5.9711e-02, -8.0772e-03,\n",
       "                      -4.1558e-04,  4.3379e-02,  3.9973e-02, -3.4977e-02,  2.9493e-02,\n",
       "                       2.4702e-02, -4.7559e-02])),\n",
       "             ('conv_block3.4.running_var',\n",
       "              tensor([0.9301, 0.9287, 0.9301, 0.9309, 0.9361, 0.9286, 0.9310, 0.9387, 0.9270,\n",
       "                      0.9336, 0.9280, 0.9425, 0.9287, 0.9374, 0.9311, 0.9286, 0.9230, 0.9310,\n",
       "                      0.9354, 0.9302, 0.9279, 0.9290, 0.9299, 0.9310, 0.9621, 0.9278, 0.9315,\n",
       "                      0.9313, 0.9293, 0.9354, 0.9276, 0.9294, 0.9305, 0.9344, 0.9219, 0.9404,\n",
       "                      0.9392, 0.9406, 0.9315, 0.9456, 0.9308, 0.9257, 0.9430, 0.9273, 0.9242,\n",
       "                      0.9308, 0.9352, 0.9422, 0.9234, 0.9272, 0.9437, 0.9231, 0.9265, 0.9416,\n",
       "                      0.9341, 0.9260, 0.9326, 0.9357, 0.9333, 0.9281, 0.9279, 0.9305, 0.9262,\n",
       "                      0.9330, 0.9328, 0.9448, 0.9282, 0.9297, 0.9288, 0.9261, 0.9273, 0.9249,\n",
       "                      0.9295, 0.9243, 0.9303, 0.9508, 0.9269, 0.9418, 0.9279, 0.9295, 0.9345,\n",
       "                      0.9250, 0.9305, 0.9330, 0.9310, 0.9385, 0.9297, 0.9350, 0.9262, 0.9292,\n",
       "                      0.9311, 0.9257, 0.9275, 0.9365, 0.9454, 0.9283, 0.9290, 0.9238, 0.9313,\n",
       "                      0.9248, 0.9303, 0.9346, 0.9308, 0.9297, 0.9273, 0.9253, 0.9293, 0.9260,\n",
       "                      0.9311, 0.9320, 0.9397, 0.9284, 0.9307, 0.9269, 0.9286, 0.9361, 0.9287,\n",
       "                      0.9349, 0.9395, 0.9299, 0.9266, 0.9265, 0.9241, 0.9290, 0.9320, 0.9378,\n",
       "                      0.9399, 0.9287, 0.9396, 0.9305, 0.9302, 0.9318, 0.9275, 0.9351, 0.9271,\n",
       "                      0.9275, 0.9299, 0.9425, 0.9272, 0.9322, 0.9359, 0.9318, 0.9290, 0.9287,\n",
       "                      0.9355, 0.9384, 0.9335, 0.9271, 0.9283, 0.9294, 0.9319, 0.9285, 0.9423,\n",
       "                      0.9407, 0.9276, 0.9331, 0.9282, 0.9290, 0.9320, 0.9282, 0.9340, 0.9349,\n",
       "                      0.9312, 0.9289, 0.9371, 0.9306, 0.9357, 0.9306, 0.9318, 0.9295, 0.9356,\n",
       "                      0.9309, 0.9286, 0.9267, 0.9272, 0.9291, 0.9373, 0.9312, 0.9337, 0.9276,\n",
       "                      0.9351, 0.9331, 0.9298, 0.9321, 0.9306, 0.9242, 0.9425, 0.9382, 0.9287,\n",
       "                      0.9297, 0.9264, 0.9321, 0.9364, 0.9303, 0.9277, 0.9398, 0.9441, 0.9287,\n",
       "                      0.9359, 0.9377, 0.9298, 0.9331, 0.9313, 0.9322, 0.9300, 0.9483, 0.9279,\n",
       "                      0.9294, 0.9263, 0.9324, 0.9377, 0.9288, 0.9279, 0.9294, 0.9335, 0.9302,\n",
       "                      0.9280, 0.9278, 0.9378, 0.9314, 0.9283, 0.9370, 0.9257, 0.9271, 0.9269,\n",
       "                      0.9295, 0.9279, 0.9309, 0.9362, 0.9344, 0.9316, 0.9289, 0.9264, 0.9257,\n",
       "                      0.9296, 0.9295, 0.9324, 0.9285, 0.9297, 0.9277, 0.9339, 0.9278, 0.9275,\n",
       "                      0.9268, 0.9338, 0.9264, 0.9323, 0.9273, 0.9419, 0.9268, 0.9264, 0.9235,\n",
       "                      0.9321, 0.9256, 0.9280, 0.9336, 0.9261, 0.9291, 0.9267, 0.9317, 0.9316,\n",
       "                      0.9365, 0.9371, 0.9265, 0.9327, 0.9281, 0.9325, 0.9262, 0.9315, 0.9395,\n",
       "                      0.9281, 0.9348, 0.9273, 0.9300, 0.9269, 0.9302, 0.9305, 0.9409, 0.9244,\n",
       "                      0.9255, 0.9307, 0.9319, 0.9282, 0.9396, 0.9269, 0.9305, 0.9261, 0.9280,\n",
       "                      0.9343, 0.9365, 0.9255, 0.9339, 0.9330, 0.9363, 0.9377, 0.9272, 0.9438,\n",
       "                      0.9293, 0.9312, 0.9380, 0.9262, 0.9338, 0.9331, 0.9370, 0.9281, 0.9244,\n",
       "                      0.9391, 0.9408, 0.9243, 0.9314, 0.9334, 0.9289, 0.9385, 0.9284, 0.9318,\n",
       "                      0.9265, 0.9270, 0.9320, 0.9301, 0.9311, 0.9393, 0.9327, 0.9276, 0.9276,\n",
       "                      0.9395, 0.9323, 0.9313, 0.9388, 0.9312, 0.9274, 0.9223, 0.9312, 0.9244,\n",
       "                      0.9322, 0.9286, 0.9239, 0.9290, 0.9319, 0.9268, 0.9339, 0.9331, 0.9290,\n",
       "                      0.9348, 0.9390, 0.9225, 0.9273, 0.9266, 0.9346, 0.9406, 0.9273, 0.9315,\n",
       "                      0.9302, 0.9279, 0.9262, 0.9332, 0.9369, 0.9344, 0.9294, 0.9359, 0.9339,\n",
       "                      0.9267, 0.9470, 0.9344, 0.9289, 0.9360, 0.9377, 0.9314, 0.9244, 0.9343,\n",
       "                      0.9278, 0.9336, 0.9300, 0.9263, 0.9264, 0.9329, 0.9309, 0.9298, 0.9323,\n",
       "                      0.9374, 0.9277, 0.9367, 0.9294, 0.9301, 0.9260, 0.9269, 0.9321, 0.9398,\n",
       "                      0.9485, 0.9282, 0.9305, 0.9335, 0.9350, 0.9280, 0.9343, 0.9300, 0.9255,\n",
       "                      0.9257, 0.9299, 0.9294, 0.9316, 0.9273, 0.9433, 0.9248, 0.9358, 0.9287,\n",
       "                      0.9344, 0.9326, 0.9340, 0.9320, 0.9385, 0.9303, 0.9322, 0.9340, 0.9281,\n",
       "                      0.9373, 0.9324, 0.9329, 0.9312, 0.9256, 0.9252, 0.9237, 0.9402, 0.9248,\n",
       "                      0.9301, 0.9275, 0.9322, 0.9254, 0.9261, 0.9271, 0.9360, 0.9282, 0.9387,\n",
       "                      0.9456, 0.9294, 0.9279, 0.9311, 0.9280, 0.9281, 0.9291, 0.9327, 0.9337,\n",
       "                      0.9340, 0.9311, 0.9259, 0.9309, 0.9294, 0.9270, 0.9314, 0.9318, 0.9290,\n",
       "                      0.9293, 0.9277, 0.9248, 0.9381, 0.9296, 0.9239, 0.9339, 0.9310, 0.9345,\n",
       "                      0.9288, 0.9276, 0.9397, 0.9317, 0.9293, 0.9291, 0.9350, 0.9291, 0.9319,\n",
       "                      0.9407, 0.9306, 0.9277, 0.9314, 0.9284, 0.9340, 0.9316, 0.9305, 0.9368,\n",
       "                      0.9276, 0.9278, 0.9318, 0.9256, 0.9392, 0.9327, 0.9343, 0.9313, 0.9287,\n",
       "                      0.9312, 0.9299, 0.9264, 0.9301, 0.9331, 0.9330, 0.9245, 0.9390, 0.9381,\n",
       "                      0.9272, 0.9314, 0.9285, 0.9266, 0.9302, 0.9284, 0.9331, 0.9275, 0.9333,\n",
       "                      0.9304, 0.9319, 0.9334, 0.9282, 0.9337, 0.9285, 0.9321, 0.9253])),\n",
       "             ('conv_block3.4.num_batches_tracked', tensor(1)),\n",
       "             ('classifier.0.weight',\n",
       "              tensor([[-0.0008,  0.0042, -0.0053,  ...,  0.0181,  0.0054,  0.0034],\n",
       "                      [ 0.0029,  0.0057,  0.0247,  ..., -0.0249, -0.0047, -0.0066],\n",
       "                      [-0.0100,  0.0164, -0.0140,  ..., -0.0135,  0.0166,  0.0193],\n",
       "                      ...,\n",
       "                      [ 0.0047, -0.0022, -0.0093,  ...,  0.0231, -0.0241,  0.0069],\n",
       "                      [ 0.0018,  0.0035, -0.0212,  ...,  0.0019,  0.0128, -0.0036],\n",
       "                      [-0.0003, -0.0086,  0.0048,  ..., -0.0079, -0.0228, -0.0066]])),\n",
       "             ('classifier.0.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('classifier.2.weight',\n",
       "              tensor([[-0.0248, -0.0191, -0.0523,  ..., -0.0027,  0.0226, -0.0121],\n",
       "                      [-0.0652, -0.0285,  0.0237,  ..., -0.0191, -0.0274, -0.0710],\n",
       "                      [-0.0170, -0.0308,  0.0514,  ..., -0.0257,  0.0595,  0.0277],\n",
       "                      ...,\n",
       "                      [ 0.0500, -0.0668, -0.0593,  ...,  0.0604,  0.0192,  0.0207],\n",
       "                      [ 0.0631, -0.0279,  0.0031,  ...,  0.0090, -0.0319,  0.0138],\n",
       "                      [ 0.0367, -0.0471,  0.0005,  ...,  0.0494, -0.0687, -0.0502]])),\n",
       "             ('classifier.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHD02aNt4pNv"
   },
   "source": [
    "# 设置交叉熵损失函数，SGD优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.863202Z",
     "start_time": "2025-07-02T12:01:56.789085Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1dvP3ES4pNv",
    "outputId": "5cd0740b-a761-4f5e-ca7d-85c43811cd41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "model = VG11()\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数，适用于多分类问题，里边会做softmax，还有会把0-9标签转换成one-hot编码\n",
    "\n",
    "print(\"损失函数:\", loss_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:01:56.938347Z",
     "start_time": "2025-07-02T12:01:56.864213Z"
    },
    "id": "qUeLZMIE4pNv"
   },
   "outputs": [],
   "source": [
    "model = VG11()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD优化器，学习率为0.01，动量为0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:02:09.730384Z",
     "start_time": "2025-07-02T12:01:56.939353Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "72277eaed5a144689ecd48a8dd95e497",
      "b46e4191d4a7437d99e6fef8bfde3942",
      "a6ca7f29c0b840e596ae80ab79cebd0c",
      "d9165f3cedf541e993a291d6f45c4dd7",
      "9d2d5709f3dd402ea8c2b9837bef4428",
      "dbdfd90e928e44ef86db8938304d0901",
      "34919055d5ce44f48c0dd4bce7bf01e5",
      "14a3a0852e654b02878f8d4a16effb46",
      "a9ff1bbe784546d99a37784f7b88c0fa",
      "d4160b61cbab4b5281557ab1571a757d",
      "fd64832b240b42ce8e79c14ebe983aff"
     ]
    },
    "id": "qI1L-GG94pNv",
    "outputId": "5ec52acb-13e4-45cc-80d0-2c2d8f3ea5be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n",
      "训练开始，共35200步\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2dd41327c6f438681e70c8da66eda05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m early_stopping=EarlyStopping(patience=\u001b[32m5\u001b[39m, delta=\u001b[32m0.001\u001b[39m)\n\u001b[32m      5\u001b[39m model_saver=ModelSaver(save_dir=\u001b[33m'\u001b[39m\u001b[33mmodel_weights\u001b[39m\u001b[33m'\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model, history = \u001b[43mtrain_classification_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_saver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_saver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_logger\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\python11\\day32\\chapter6-AI\\wangdao_deeplearning_train.py:210\u001b[39m, in \u001b[36mtrain_classification_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, tensorboard_logger, model_saver, early_stopping, eval_step)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# 评估\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_step % eval_step == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     val_acc, val_loss = \u001b[43mevaluate_classification_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m     record_dict[\u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m].append({\n\u001b[32m    212\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: val_loss, \u001b[33m\"\u001b[39m\u001b[33macc\u001b[39m\u001b[33m\"\u001b[39m: val_acc, \u001b[33m\"\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m\"\u001b[39m: global_step\n\u001b[32m    213\u001b[39m     })\n\u001b[32m    214\u001b[39m     model.train()  \u001b[38;5;66;03m# 切换回训练集模式\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\python11\\day32\\chapter6-AI\\wangdao_deeplearning_train.py:114\u001b[39m, in \u001b[36mevaluate_classification_model\u001b[39m\u001b[34m(model, data_loader, device, criterion)\u001b[39m\n\u001b[32m    111\u001b[39m running_loss = \u001b[32m0.0\u001b[39m  \u001b[38;5;66;03m# 总损失\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():  \u001b[38;5;66;03m# 不计算梯度\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mCIFAR10Dataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     27\u001b[39m     img_path = os.path.join(\u001b[38;5;28mself\u001b[39m.img_dir, \u001b[38;5;28mself\u001b[39m.img_names[idx] + \u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m#图片路径\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     image = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#打开图片\u001b[39;00m\n\u001b[32m     29\u001b[39m     label = \u001b[38;5;28mself\u001b[39m.labels[idx]\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\PIL\\Image.py:3505\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3502\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3505\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3506\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "model = model.to(device) #将模型移动到GPU\n",
    "early_stopping=EarlyStopping(patience=5, delta=0.001)\n",
    "model_saver=ModelSaver(save_dir='model_weights', save_best_only=True)\n",
    "\n",
    "\n",
    "model, history = train_classification_model(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=50, early_stopping=early_stopping, model_saver=model_saver, tensorboard_logger=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:02:09.732400Z",
     "start_time": "2025-07-02T12:02:09.731400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJWn5FRH4pNv",
    "outputId": "cac54270-06c6-40db-daba-741b16fc232a"
   },
   "outputs": [],
   "source": [
    "history['train'][-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:02:09.733399Z",
     "start_time": "2025-07-02T12:02:09.732400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMjJdQ2l4pNw",
    "outputId": "ed142afb-32d8-444d-adc0-9ed4ab5b5bd1"
   },
   "outputs": [],
   "source": [
    "history['val'][-1000:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcujMCRC4pNw"
   },
   "source": [
    "# 绘制损失曲线和准确率曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:02:09.735414Z",
     "start_time": "2025-07-02T12:02:09.734413Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "3xZ57j-C4pNw",
    "outputId": "923a2c40-e78a-460c-9475-8daafeb486f0"
   },
   "outputs": [],
   "source": [
    "plot_learning_curves(history, sample_step=500)  #横坐标是 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:02:09.739406Z",
     "start_time": "2025-07-02T12:02:09.739406Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yvx48aMb4pNw",
    "outputId": "641978f7-868a-4959-8af0-4c1e561950a1"
   },
   "outputs": [],
   "source": [
    "# 导入所需库\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import tqdm\n",
    "\n",
    "# 定义测试数据集类\n",
    "class CIFAR10TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化测试数据集\n",
    "\n",
    "        参数:\n",
    "            img_dir: 测试图片目录\n",
    "            transform: 图像预处理变换\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # 提取图像ID（文件名去掉扩展名）\n",
    "        img_id = int(os.path.splitext(self.img_files[idx])[0])\n",
    "\n",
    "        return image, img_id\n",
    "\n",
    "# 定义预测函数\n",
    "def predict_test_set(model, img_dir, labels_file, device, batch_size=64):\n",
    "    \"\"\"\n",
    "    预测测试集并生成提交文件\n",
    "\n",
    "    参数:\n",
    "        model: 训练好的模型\n",
    "        img_dir: 测试图片目录\n",
    "        labels_file: 提交模板文件路径\n",
    "        device: 计算设备\n",
    "        batch_size: 批处理大小\n",
    "    \"\"\"\n",
    "    # 图像预处理变换（与训练集相同）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4917, 0.4823, 0.4467), (0.2024, 0.1995, 0.2010))\n",
    "    ])\n",
    "\n",
    "    # 创建测试数据集和数据加载器\n",
    "    test_dataset = CIFAR10TestDataset(img_dir, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 设置模型为评估模式\n",
    "    model.eval()\n",
    "\n",
    "    # 读取提交模板\n",
    "    submission_df = pd.read_csv(labels_file)\n",
    "    predictions = {}\n",
    "\n",
    "    # 使用tqdm显示进度条\n",
    "    print(\"正在预测测试集...\")\n",
    "    with torch.no_grad():\n",
    "        for images, img_ids in tqdm.tqdm(test_loader, desc=\"预测进度\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1) #取最大的索引，作为预测结果\n",
    "\n",
    "            # 记录每个图像的预测结果\n",
    "            for i, img_id in enumerate(img_ids):\n",
    "                predictions[img_id.item()] = predicted[i].item() #因为一个批次有多个图像，所以需要predicted[i]\n",
    "\n",
    "    # 定义类别名称\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    # 将数值标签转换为类别名称\n",
    "    labeled_predictions = {img_id: class_names[pred] for img_id, pred in predictions.items()}\n",
    "\n",
    "    # 直接创建DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': list(labeled_predictions.keys()),\n",
    "        'label': list(labeled_predictions.values())\n",
    "    })\n",
    "    # 按id列排序\n",
    "    submission_df = submission_df.sort_values(by='id')\n",
    "\n",
    "    # 检查id列是否有重复值\n",
    "    has_duplicates = submission_df['id'].duplicated().any()\n",
    "    print(f\"id列是否有重复值: {has_duplicates}\")\n",
    "    # 保存预测结果\n",
    "    output_file = 'cifar10_submission.csv'\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"预测完成，结果已保存至 {output_file}\")\n",
    "\n",
    "# 执行测试集预测\n",
    "img_dir = r\"competitions/cifar-10/test\"\n",
    "labels_file = r\"./sampleSubmission.csv\"\n",
    "predict_test_set(model, img_dir, labels_file, device, batch_size=128)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14a3a0852e654b02878f8d4a16effb46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34919055d5ce44f48c0dd4bce7bf01e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72277eaed5a144689ecd48a8dd95e497": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b46e4191d4a7437d99e6fef8bfde3942",
       "IPY_MODEL_a6ca7f29c0b840e596ae80ab79cebd0c",
       "IPY_MODEL_d9165f3cedf541e993a291d6f45c4dd7"
      ],
      "layout": "IPY_MODEL_9d2d5709f3dd402ea8c2b9837bef4428"
     }
    },
    "9d2d5709f3dd402ea8c2b9837bef4428": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6ca7f29c0b840e596ae80ab79cebd0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14a3a0852e654b02878f8d4a16effb46",
      "max": 35200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a9ff1bbe784546d99a37784f7b88c0fa",
      "value": 10500
     }
    },
    "a9ff1bbe784546d99a37784f7b88c0fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b46e4191d4a7437d99e6fef8bfde3942": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbdfd90e928e44ef86db8938304d0901",
      "placeholder": "​",
      "style": "IPY_MODEL_34919055d5ce44f48c0dd4bce7bf01e5",
      "value": " 30%"
     }
    },
    "d4160b61cbab4b5281557ab1571a757d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9165f3cedf541e993a291d6f45c4dd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4160b61cbab4b5281557ab1571a757d",
      "placeholder": "​",
      "style": "IPY_MODEL_fd64832b240b42ce8e79c14ebe983aff",
      "value": " 10500/35200 [11:35&lt;23:51, 17.26it/s, epoch=14, loss=0.0013, acc=100.00%]"
     }
    },
    "dbdfd90e928e44ef86db8938304d0901": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd64832b240b42ce8e79c14ebe983aff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
