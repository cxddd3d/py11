{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Deformable Attention 模型结构\n",
    "## 一、模型简介\n",
    "DeformableAttention 是可变形注意力机制的 1 维单头实现，核心特点是通过学习偏移量动态调整采样位置，相比传统注意力更灵活。主要用于从输入特征（Value）中根据查询（Query）动态采样关键信息并加权融合。\n",
    "## 二、核心参数与组件\n",
    "组件\t                 作用\t                                      关键参数\n",
    "sampling_offsets\t线性层，从 Query 估计采样点偏移量  输入维度：hidden_size，输出维度：n_points * 1 * 2（单头 2D 偏移）\n",
    "attention_weights\t线性层，从 Query 估计采样点权重\t 输入维度：hidden_size，输出维度：n_points * 1（单头权重）\n",
    "## 三、Shape 变化详解（以示例输入为例）\n",
    "示例输入参数：\n",
    "batch_size=1，sequence_length=8，hidden_size=16，n_points=3\n",
    "1. 输入参数 Shape\n",
    "参数\t           形状\t                   说明\n",
    "q（Query）\t(1, 8, 16)\t(batch_size, seq_len, hidden_size)\n",
    "v（Value）\t(1, 8, 16)\t待采样的特征向量\n",
    "reference_points\t(1, 8, 2)\t初始参考点（归一化到 [0,1]）\n",
    "input_spatial_shapes\t(2,) → [8, 1]\t输入特征的空间尺寸（长度 = 8，高度 = 1）\n",
    "2. 偏移量与权重估计\n",
    "方法：esitimate_offset_and_weights 或 ground_truth_offset_and_weights\n",
    "输出 Shape：\n",
    "sampling_offsets：(1, 8, 3, 2)\n",
    "（batch_size, seq_len, n_points, 2，每个采样点的 2D 偏移量）\n",
    "weights：(1, 8, 3)\n",
    "（batch_size, seq_len, n_points，经 softmax 归一化的权重）\n",
    "3. 采样点位置计算\n",
    "参考点增维 + 偏移量归一化\n",
    "sampling_locations = reference_points[:, :, None, :] + sampling_offsets / offset_normalizer[None, None, None, :]\n",
    "reference_points 增维：(1,8,2) → (1,8,1,2)（新增采样点维度）\n",
    "offset_normalizer 增维：(2,) → (1,1,1,2)（广播适配）\n",
    "sampling_locations 形状：(1, 8, 3, 2)（归一化坐标，范围 [0,1] 附近）\n",
    "转换为绝对坐标\n",
    "sampling_locations_absolute = sampling_locations * input_spatial_shapes[None, None, None, :]\n",
    "形状不变：(1, 8, 3, 2)（映射为实际序列索引，如 0~8）\n",
    "4. 特征采样（F.grid_sample）\n",
    "Value 维度调整\n",
    "v = v.permute(0, 2, 1).unsqueeze(-1)  # (1,8,16) → (1,16,8) → (1,16,8,1)\n",
    "适配 grid_sample 输入格式：(batch, channel, height, width)（这里 height=1，width=8）\n",
    "网格采样\n",
    "sampled_values = F.grid_sample(v, sampling_locations, align_corners=True)\n",
    "输出形状：(1, 16, 8, 3)\n",
    "（batch_size, hidden_size, seq_len, n_points，每个采样点提取的特征）\n",
    "5. 加权求和输出\n",
    "维度调整\n",
    "sampled_values = sampled_values.permute(0, 2, 3, 1)  # (1,16,8,3) → (1,8,3,16)\n",
    "加权求和\n",
    "output = torch.sum(sampled_values * weights.unsqueeze(-1), dim=-2)\n",
    "weights 增维：(1,8,3) → (1,8,3,1)\n",
    "输出形状：(1, 8, 16)（batch_size, seq_len, hidden_size，与输入特征维度一致）\n",
    "## 四、输出结果 Shape\n",
    "输出\t       形状\t        说明\n",
    "output\t(1, 8, 16)\t可变形注意力加权后的特征向量\n",
    "sampling_locations_absolute\t(1, 8, 3, 2)\t采样点的绝对坐标\n",
    "deformable_score（权重）\t(1, 8, 3)\t每个采样点的注意力权重\n",
    "## 五、核心流程总结\n",
    "从 Query 估计 / 获取偏移量和权重 → 确定动态采样点\n",
    "结合参考点计算采样点坐标 → 映射到实际序列位置\n",
    "从 Value 中采样特征 → 按权重加权求和 → 输出最终特征\n",
    "通过动态调整采样位置，模型能更灵活地聚焦关键信息，适用于目标检测、序列建模等任务。"
   ],
   "id": "d80f59d992ff2995"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
