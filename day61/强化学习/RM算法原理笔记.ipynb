{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2467fe4a34348168",
   "metadata": {},
   "source": [
    "# Robbins-Monro（RM）算法原理笔记\n",
    "## 一、算法背景\n",
    "Robbins-Monro（RM）算法是随机近似理论（Stochastic Approximation, SA） 中的经典算法，用于求解未知函数方程的根。其核心价值在于：当目标函数的表达式未知（视为 “黑盒”）时，仅通过含噪声的观测数据即可迭代逼近方程的解。\n",
    "在强化学习中，RM 算法是理解时序差分（Temporal-Difference, TD）学习的重要基础，同时也是随机梯度下降（SGD）的理论原型。\n",
    "## 二、核心问题\n",
    "RM 算法旨在求解如下方程的根：\n",
    "g(w)=0\n",
    "其中：\n",
    "w∈R\n",
    " 是待求解的变量（可为标量或向量）；\n",
    "g:R→R\n",
    " 是目标函数，但其表达式未知，仅能通过观测获得含噪声的输出。\n",
    "问题转化\n",
    "许多实际问题可转化为上述根求解问题，例如：\n",
    "优化问题：最小化目标函数 \n",
    "J(w)\n",
    " 等价于求解 \n",
    "∇ \n",
    "w\n",
    "​\n",
    " J(w)=0\n",
    "（梯度为 0）；\n",
    "方程求解：将 \n",
    "g(w)=c\n",
    " 转化为 \n",
    "g(w)−c=0\n",
    "。\n",
    "## 三、算法原理\n",
    "核心思想\n",
    "当无法直接获取 \n",
    "g(w)\n",
    " 的表达式时，通过含噪声的观测值迭代更新对根的估计。观测值记为：\n",
    "g\n",
    "~\n",
    "​\n",
    " (w \n",
    "k\n",
    "​\n",
    " ,η \n",
    "k\n",
    "​\n",
    " )=g(w \n",
    "k\n",
    "​\n",
    " )+η \n",
    "k\n",
    "​\n",
    " \n",
    "其中：\n",
    "w \n",
    "k\n",
    "​\n",
    " \n",
    " 是第 \n",
    "k\n",
    " 次迭代对根的估计；\n",
    "η \n",
    "k\n",
    "​\n",
    " \n",
    " 是观测噪声（均值为 0 的随机变量）。\n",
    "RM 算法通过以下迭代公式更新估计值：\n",
    "w \n",
    "k+1\n",
    "​\n",
    " =w \n",
    "k\n",
    "​\n",
    " −a \n",
    "k\n",
    "​\n",
    " ⋅ \n",
    "g\n",
    "~\n",
    "​\n",
    " (w \n",
    "k\n",
    "​\n",
    " ,η \n",
    "k\n",
    "​\n",
    " )\n",
    "其中：\n",
    "a \n",
    "k\n",
    "​\n",
    " >0\n",
    " 是步长系数，控制迭代更新的幅度；\n",
    "负号表示沿观测值的反方向调整，逐步逼近根 \n",
    "w \n",
    "∗\n",
    " \n",
    "。\n",
    "直观解释\n",
    "当 \n",
    "w \n",
    "k\n",
    "​\n",
    " >w \n",
    "∗\n",
    " \n",
    " 时，若 \n",
    "g(w)\n",
    " 单调递增，则 \n",
    "g(w \n",
    "k\n",
    "​\n",
    " )>0\n",
    "，观测值 \n",
    "g\n",
    "~\n",
    "​\n",
    " (w \n",
    "k\n",
    "​\n",
    " ,η \n",
    "k\n",
    "​\n",
    " )≈g(w \n",
    "k\n",
    "​\n",
    " )>0\n",
    "，迭代后 \n",
    "w \n",
    "k+1\n",
    "​\n",
    " <w \n",
    "k\n",
    "​\n",
    " \n",
    "，更接近 \n",
    "w \n",
    "∗\n",
    " \n",
    "；\n",
    "当 \n",
    "w \n",
    "k\n",
    "​\n",
    " <w \n",
    "∗\n",
    " \n",
    " 时，同理 \n",
    "g(w \n",
    "k\n",
    "​\n",
    " )<0\n",
    "，迭代后 \n",
    "w \n",
    "k+1\n",
    "​\n",
    " >w \n",
    "k\n",
    "​\n",
    " \n",
    "，也更接近 \n",
    "w \n",
    "∗\n",
    " \n",
    "。\n",
    "通过持续迭代，\n",
    "w \n",
    "k\n",
    "​\n",
    " \n",
    " 逐步收敛到真实根 \n",
    "w \n",
    "∗\n",
    " \n",
    "。\n",
    "## 四、收敛性条件\n",
    "RM 算法收敛的严格条件由Robbins-Monro 定理给出，需满足以下 3 点：\n",
    "函数单调性与有界性\n",
    "g(w)\n",
    " 的梯度（导数）满足 \n",
    "0<c \n",
    "1\n",
    "​\n",
    " ≤∇ \n",
    "w\n",
    "​\n",
    " g(w)≤c \n",
    "2\n",
    "​\n",
    " \n",
    "，即：\n",
    "g(w)\n",
    " 单调递增（确保根唯一存在）；\n",
    "梯度有界（避免迭代发散）。\n",
    "步长系数条件\n",
    "步长 \n",
    "a \n",
    "k\n",
    "​\n",
    " \n",
    " 需满足：\n",
    "∑ \n",
    "k=1\n",
    "∞\n",
    "​\n",
    " a \n",
    "k\n",
    "​\n",
    " =∞且∑ \n",
    "k=1\n",
    "∞\n",
    "​\n",
    " a \n",
    "k\n",
    "2\n",
    "​\n",
    " <∞\n",
    "第一个条件确保步长不会收敛到 0 太快，保证迭代能 “到达” 根；\n",
    "第二个条件确保步长最终趋于 0，避免迭代震荡。\n",
    "典型的步长选择为 \n",
    "a \n",
    "k\n",
    "​\n",
    "= \n",
    "k\n",
    "1\n",
    "​\n",
    " \n",
    "（满足上述条件）。\n",
    "噪声条件\n",
    "观测噪声 \n",
    "η \n",
    "k\n",
    "​\n",
    " \n",
    " 满足：\n",
    "E[η \n",
    "k\n",
    "​\n",
    " ∣H \n",
    "k\n",
    "​\n",
    " ]=0且E[η \n",
    "k\n",
    "2\n",
    "​\n",
    " ∣H \n",
    "k\n",
    "​\n",
    " ]<∞\n",
    "其中 \n",
    "H \n",
    "k\n",
    "​\n",
    " \n",
    "是第 \n",
    "k\n",
    "次迭代的历史信息。即噪声均值为 0 且方差有界，避免噪声主导迭代。\n",
    "## 五、应用场景\n",
    "均值估计\n",
    "估计随机变量 \n",
    "X\n",
    " 的期望 \n",
    "E[X]\n",
    " 可转化为求解 \n",
    "g(w)=w−E[X]=0\n",
    "，此时 RM 算法退化为迭代均值估计：\n",
    "w \n",
    "k+1\n",
    "​\n",
    " =w \n",
    "k\n",
    "​\n",
    " −a \n",
    "k\n",
    "​\n",
    " (w \n",
    "k\n",
    "​\n",
    " −x \n",
    "k\n",
    "​\n",
    " )\n",
    "其中 \n",
    "x \n",
    "k\n",
    "​\n",
    " \n",
    "是 \n",
    "X\n",
    "的采样。\n",
    "强化学习中的价值估计\n",
    "时序差分（TD）学习的更新公式本质上是 RM 算法的特例，用于在无模型场景下估计状态 / 动作价值。\n",
    "黑盒优化\n",
    "当目标函数无法显式表达（如神经网络）时，通过 RM 算法可求解其极值点（梯度为 0 的点）。\n",
    "## 六、关键结论\n",
    "RM 算法是处理未知函数方程求解的强大工具，仅需含噪声的观测数据；\n",
    "步长系数的选择是收敛的关键，需平衡迭代速度与稳定性；\n",
    "作为随机梯度下降（SGD）和时序差分（TD）学习的理论基础，RM 算法为理解更复杂的迭代优化方法提供了框架。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
