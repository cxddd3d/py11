{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGV2VjXF4pNs"
   },
   "source": [
    "# 查看FashionMNIST原始数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:32.363026Z",
     "start_time": "2025-06-26T01:43:29.447990Z"
    },
    "id": "3djTfPq64pNt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from wangdao_deeplearning_train import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from wangdao_deeplearning_train import evaluate_classification_model as evaluate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ua9T8MLp3ODM",
    "outputId": "75db5670-2f39-472b-b3f0-4364236ab0d8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "输入张量的形状: torch.Size([1, 3, 6, 6])\n",
      "输出张量的形状: torch.Size([1, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个随机输入张量，模拟特征图\n",
    "# 形状为 [1, 3, 6, 6]，表示1个样本，3个通道，6x6的特征图\n",
    "input_tensor = torch.randn(1, 3, 6, 6)\n",
    "print(\"输入张量的形状:\", input_tensor.shape)\n",
    "\n",
    "# 创建 AdaptiveAvgPool2d 层，指定输出大小为 2x2\n",
    "adaptive_pool = nn.AdaptiveAvgPool2d(output_size=(2, 2))\n",
    "\n",
    "# 对输入张量进行自适应平均池化\n",
    "output_tensor = adaptive_pool(input_tensor)\n",
    "print(\"输出张量的形状:\", output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Fi46_oyAY6qD"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "token = {\"username\":\"huangdongsheng123\",\"key\":\"bc7074d3e7a23aa7233f350712ff381d\"}\n",
    "\n",
    "with open('/content/kaggle.json', 'w') as file:\n",
    "  json.dump(token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBunE0OvY6ZY",
    "outputId": "4b92efa0-bc2c-4c51-8956-717fcf488937"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"username\": \"huangdongsheng123\", \"key\": \"bc7074d3e7a23aa7233f350712ff381d\"}"
     ]
    }
   ],
   "source": [
    "!cat /content/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXgB8rdbZIDU",
    "outputId": "8cc65593-cba9-4bac-fa53-d36e4f81c7a4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- path is now set to: /content\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle config set -n path -v /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4feg3Y3_2IJC",
    "outputId": "865050d4-ee58-4c75-f17d-d741a941659c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading cifar-10.zip to /content/competitions/cifar-10\n",
      " 93% 666M/715M [00:03<00:00, 246MB/s]\n",
      "100% 715M/715M [00:03<00:00, 228MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDeB7tM12b9K",
    "outputId": "4a1d83a7-8c4e-4909-d7f3-5456c50addb3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archive:  /content/competitions/cifar-10/cifar-10.zip\n",
      "  inflating: sampleSubmission.csv    \n",
      "  inflating: test.7z                 \n",
      "  inflating: train.7z                \n",
      "  inflating: trainLabels.csv         \n"
     ]
    }
   ],
   "source": [
    "!unzip /content/competitions/cifar-10/cifar-10.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NK7iEl7I2bRK",
    "outputId": "6da18719-c894-49f3-c01f-090eba9e0c8c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting py7zr\n",
      "  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting texttable (from py7zr)\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (3.23.0)\n",
      "Collecting brotli>=1.1.0 (from py7zr)\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from py7zr) (5.9.5)\n",
      "Collecting pyzstd>=0.16.1 (from py7zr)\n",
      "  Downloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting pyppmd<1.3.0,>=1.1.0 (from py7zr)\n",
      "  Downloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
      "  Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting multivolumefile>=0.2.3 (from py7zr)\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
      "  Downloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.13.2 in /usr/local/lib/python3.11/dist-packages (from pyzstd>=0.16.1->py7zr) (4.14.0)\n",
      "Downloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m69.7/69.7 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m53.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m96.4/96.4 kB\u001B[0m \u001B[31m9.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.7/50.7 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m141.3/141.3 kB\u001B[0m \u001B[31m12.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m412.9/412.9 kB\u001B[0m \u001B[31m33.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pybcj, multivolumefile, inflate64, py7zr\n",
      "Successfully installed brotli-1.1.0 inflate64-1.0.3 multivolumefile-0.2.3 py7zr-1.0.0 pybcj-1.0.6 pyppmd-1.2.0 pyzstd-0.17.0 texttable-1.7.0\n"
     ]
    }
   ],
   "source": [
    "%pip install py7zr\n",
    "import py7zr\n",
    "a =py7zr.SevenZipFile(r'./train.7z','r')\n",
    "a.extractall(path=r'./competitions/cifar-10/')\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rI5JDfji59q-",
    "outputId": "4c4784f3-b881-4bef-9c4a-a7f5d800c0a8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "!ls competitions/cifar-10/train|wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vk4EQTiM4pNt"
   },
   "source": [
    "# 加载数据并处理为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:32.407799Z",
     "start_time": "2025-06-26T01:43:32.363026Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvguuJLl4pNt",
    "outputId": "6df63b49-de89-4c7e-c568-1621375bddf6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "完整数据集大小: 50000\n",
      "训练集大小: 45000\n",
      "验证集大小: 5000\n"
     ]
    }
   ],
   "source": [
    "# 加载CIFAR-10数据集\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 定义CIFAR-10数据集类\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取标签文件，read_csv默认读取第一行作为列名\n",
    "        self.labels_df = pd.read_csv(labels_file)\n",
    "        self.img_names = self.labels_df.iloc[:, 0].values.astype(str)  # 第一列是图片名称，确保为字符串类型\n",
    "\n",
    "        # 类别名称字典，使用字典可以提高查找速度\n",
    "        self.class_names_dict = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3,\n",
    "                                 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "        # 将文本标签转换为数字ID\n",
    "        self.labels = [self.class_names_dict[label] for label in self.labels_df.iloc[:, 1].values]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx] + '.png') #图片路径\n",
    "        image = Image.open(img_path) #打开图片\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image)\n",
    "\n",
    "        return image_tensor, label\n",
    "\n",
    "# 定义数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4917, 0.4823, 0.4467), (0.2024, 0.1995, 0.2010))\n",
    "])\n",
    "\n",
    "# colab加载CIFAR-10数据集\n",
    "img_dir = r\"competitions/cifar-10/train\"\n",
    "labels_file = r\"./trainLabels.csv\"\n",
    "\n",
    "# img_dir = r\"D:\\cifar-10\\train\\train\"\n",
    "# labels_file = r\"D:\\cifar-10\\trainLabels.csv\"\n",
    "full_dataset = CIFAR10Dataset(img_dir=img_dir, labels_file=labels_file, transform=transform)\n",
    "\n",
    "# 定义类别名称\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = 45000\n",
    "val_size = 5000\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "# 查看数据集基本信息\n",
    "print(f\"完整数据集大小: {len(full_dataset)}\")\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"验证集大小: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1akKUts84pNu"
   },
   "outputs": [],
   "source": [
    "def cal_mean_std(ds):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for img, _ in ds:\n",
    "        mean += img.mean(dim=(1, 2)) #dim=(1, 2)表示在通道维度上求平均\n",
    "        std += img.std(dim=(1, 2))  #dim=(1, 2)表示在通道维度上求标准差\n",
    "    mean /= len(ds)\n",
    "    std /= len(ds)\n",
    "    return mean, std\n",
    "# cal_mean_std(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrTSD6iw4pNu"
   },
   "source": [
    "# 把数据集划分为训练集45000和验证集5000，并给DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.144223Z",
     "start_time": "2025-06-26T01:43:33.135368Z"
    },
    "id": "qK_zQ__r4pNu"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUyAkERd4pNu"
   },
   "source": [
    "# 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j17TXWWx4pNu",
    "outputId": "a4268aa0-975f-4e2d-a4c7-01f517768cb9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([20, 100])\n"
     ]
    }
   ],
   "source": [
    "#理解每个接口的方法，单独写例子\n",
    "import torch.nn as nn\n",
    "m=nn.BatchNorm1d(100)\n",
    "x=torch.randn(20,100)\n",
    "print(m(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFvbdkKd4pNu"
   },
   "source": [
    "# 复现VGG11简单版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.152657Z",
     "start_time": "2025-06-26T01:43:33.148120Z"
    },
    "id": "UOfee2qW4pNu"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VGG11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # VGG11架构的卷积层配置\n",
    "        # 第一个卷积块 - 1个卷积层\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 第二个卷积块 - 1个卷积层\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 第三个卷积块 - 2个卷积层\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 第四个卷积块 - 2个卷积层\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 第五个卷积块 - 2个卷积层\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 全连接层 - 适配CIFAR-10的10个类别\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 10)  # 10分类\n",
    "        )\n",
    "\n",
    "        # 初始化权重\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"使用xavier均匀分布初始化权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 卷积块前向传播\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "\n",
    "        # 展平操作 - CIFAR-10经过5次下采样后为1x1\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # 分类器\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.185031Z",
     "start_time": "2025-06-26T01:43:33.152657Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ll8FXqD4pNv",
    "outputId": "2d031c42-4f26-4eaf-8570-6255e3ca2c50"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "批次图像形状: torch.Size([64, 3, 32, 32])\n",
      "批次标签形状: torch.Size([64])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = VGG11()\n",
    "\n",
    "# 从train_loader获取第一个批次的数据\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 查看批次数据的形状\n",
    "print(\"批次图像形状:\", images.shape)\n",
    "print(\"批次标签形状:\", labels.shape)\n",
    "\n",
    "\n",
    "print('-'*100)\n",
    "# 进行前向传播\n",
    "with torch.no_grad():  # 不需要计算梯度\n",
    "    outputs = model(images)\n",
    "\n",
    "\n",
    "print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.203053Z",
     "start_time": "2025-06-26T01:43:33.199532Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8zEsAla4pNv",
    "outputId": "4181b35c-6340-42b6-8892-2dc9821e4e7b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "需要求梯度的参数总量: 15532810\n",
      "模型总参数量: 15532810\n",
      "\n",
      "各层参数量明细:\n",
      "conv_block1.0.weight: 1728 参数\n",
      "conv_block1.0.bias: 64 参数\n",
      "conv_block1.1.weight: 64 参数\n",
      "conv_block1.1.bias: 64 参数\n",
      "conv_block2.0.weight: 73728 参数\n",
      "conv_block2.0.bias: 128 参数\n",
      "conv_block2.1.weight: 128 参数\n",
      "conv_block2.1.bias: 128 参数\n",
      "conv_block3.0.weight: 294912 参数\n",
      "conv_block3.0.bias: 256 参数\n",
      "conv_block3.1.weight: 256 参数\n",
      "conv_block3.1.bias: 256 参数\n",
      "conv_block3.3.weight: 589824 参数\n",
      "conv_block3.3.bias: 256 参数\n",
      "conv_block3.4.weight: 256 参数\n",
      "conv_block3.4.bias: 256 参数\n",
      "conv_block4.0.weight: 1179648 参数\n",
      "conv_block4.0.bias: 512 参数\n",
      "conv_block4.1.weight: 512 参数\n",
      "conv_block4.1.bias: 512 参数\n",
      "conv_block4.3.weight: 2359296 参数\n",
      "conv_block4.3.bias: 512 参数\n",
      "conv_block4.4.weight: 512 参数\n",
      "conv_block4.4.bias: 512 参数\n",
      "conv_block5.0.weight: 2359296 参数\n",
      "conv_block5.0.bias: 512 参数\n",
      "conv_block5.1.weight: 512 参数\n",
      "conv_block5.1.bias: 512 参数\n",
      "conv_block5.3.weight: 2359296 参数\n",
      "conv_block5.3.bias: 512 参数\n",
      "conv_block5.4.weight: 512 参数\n",
      "conv_block5.4.bias: 512 参数\n",
      "classifier.0.weight: 2097152 参数\n",
      "classifier.0.bias: 4096 参数\n",
      "classifier.3.weight: 4194304 参数\n",
      "classifier.3.bias: 1024 参数\n",
      "classifier.6.weight: 10240 参数\n",
      "classifier.6.bias: 10 参数\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数量\n",
    "# 统计需要求梯度的参数总量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"需要求梯度的参数总量: {total_params}\")\n",
    "\n",
    "# 统计所有参数总量\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {all_params}\")\n",
    "\n",
    "# 查看每层参数量明细\n",
    "print(\"\\n各层参数量明细:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} 参数\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.217395Z",
     "start_time": "2025-06-26T01:43:33.203561Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "al9xZTJQ4pNv",
    "outputId": "3627c62e-e628-4d0d-de96-5b2914772667"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block1.0.weight',\n",
       "              tensor([[[[ 0.0900,  0.0059,  0.0995],\n",
       "                        [ 0.0300, -0.0465, -0.0303],\n",
       "                        [ 0.0169, -0.0763,  0.0283]],\n",
       "              \n",
       "                       [[ 0.0094,  0.0316,  0.0394],\n",
       "                        [-0.0784, -0.0215,  0.0261],\n",
       "                        [ 0.0092, -0.0093, -0.0645]],\n",
       "              \n",
       "                       [[ 0.0025, -0.0841, -0.0413],\n",
       "                        [-0.0718,  0.0645,  0.0164],\n",
       "                        [-0.0739, -0.0705,  0.0534]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0015, -0.0364, -0.0880],\n",
       "                        [ 0.0333, -0.0337, -0.0865],\n",
       "                        [ 0.0344, -0.0443,  0.0888]],\n",
       "              \n",
       "                       [[ 0.0941,  0.0581,  0.0047],\n",
       "                        [ 0.0537, -0.0147, -0.0713],\n",
       "                        [ 0.0410, -0.0648, -0.0805]],\n",
       "              \n",
       "                       [[-0.0515,  0.0528,  0.0913],\n",
       "                        [ 0.0939,  0.0871, -0.0319],\n",
       "                        [-0.0236,  0.0542, -0.0290]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0199, -0.0835,  0.0158],\n",
       "                        [-0.0301,  0.0983,  0.0423],\n",
       "                        [ 0.0515,  0.0282,  0.0185]],\n",
       "              \n",
       "                       [[ 0.0882,  0.0943,  0.0347],\n",
       "                        [-0.0941, -0.0630,  0.0419],\n",
       "                        [-0.0216,  0.0338,  0.0131]],\n",
       "              \n",
       "                       [[-0.0193,  0.0828, -0.0336],\n",
       "                        [-0.0022,  0.0178,  0.0390],\n",
       "                        [-0.0383,  0.0361,  0.0776]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0872,  0.0673, -0.0250],\n",
       "                        [-0.0487,  0.0760, -0.0762],\n",
       "                        [ 0.0616, -0.0409, -0.0728]],\n",
       "              \n",
       "                       [[-0.0561, -0.0778, -0.0754],\n",
       "                        [ 0.0647,  0.0612,  0.0812],\n",
       "                        [-0.0503, -0.0554, -0.0677]],\n",
       "              \n",
       "                       [[-0.0882,  0.0153,  0.0488],\n",
       "                        [-0.0249,  0.0714,  0.0337],\n",
       "                        [ 0.0469, -0.0189, -0.0729]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0216,  0.0133,  0.0903],\n",
       "                        [ 0.0344, -0.0610,  0.0771],\n",
       "                        [-0.0922,  0.0708,  0.0365]],\n",
       "              \n",
       "                       [[-0.0955, -0.0697, -0.0564],\n",
       "                        [-0.0709, -0.0676, -0.0953],\n",
       "                        [-0.0635,  0.0876,  0.0391]],\n",
       "              \n",
       "                       [[ 0.0590,  0.0502,  0.0635],\n",
       "                        [-0.0783, -0.0404,  0.0851],\n",
       "                        [-0.0606, -0.0293,  0.0125]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0414, -0.0440,  0.0784],\n",
       "                        [ 0.0091, -0.0637, -0.0906],\n",
       "                        [-0.0018,  0.0595, -0.0553]],\n",
       "              \n",
       "                       [[ 0.0569, -0.0267, -0.0153],\n",
       "                        [ 0.0540,  0.0580, -0.0059],\n",
       "                        [ 0.0160, -0.0936,  0.0718]],\n",
       "              \n",
       "                       [[-0.0781,  0.0724, -0.0796],\n",
       "                        [ 0.0851,  0.0747, -0.0814],\n",
       "                        [ 0.0392, -0.0020, -0.0175]]]])),\n",
       "             ('conv_block1.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block1.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('conv_block1.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block1.1.running_mean',\n",
       "              tensor([ 7.1721e-04, -3.5908e-04, -3.8186e-03,  2.0438e-03,  4.4005e-03,\n",
       "                      -3.0785e-03, -4.0387e-03,  1.3840e-03,  2.2866e-05,  5.9976e-05,\n",
       "                      -6.0160e-04, -2.7305e-04, -2.2461e-03, -9.8419e-04,  3.6463e-03,\n",
       "                      -2.0661e-03,  3.5583e-03, -1.6455e-03,  2.3001e-03,  4.7409e-04,\n",
       "                      -1.9348e-03,  2.5868e-03, -3.3394e-03,  1.7338e-03, -1.5330e-03,\n",
       "                      -3.1691e-03, -1.6673e-03, -2.7347e-04, -2.0141e-04,  3.7409e-03,\n",
       "                       3.8050e-03, -1.5173e-04,  5.2375e-03, -4.9211e-04, -3.0166e-03,\n",
       "                       3.4960e-03, -2.7201e-03, -7.4584e-04, -1.9297e-03, -8.7149e-04,\n",
       "                      -5.0593e-03, -7.2162e-04, -2.4142e-03,  2.7855e-04, -5.1532e-03,\n",
       "                       5.6870e-03,  1.7079e-03, -1.8437e-03,  1.7748e-03, -3.2961e-04,\n",
       "                       6.5807e-03, -1.4471e-03,  8.7947e-04, -8.6424e-04, -6.5869e-05,\n",
       "                      -3.6093e-06,  3.8629e-03,  3.6895e-05, -3.6339e-03, -5.2028e-03,\n",
       "                      -4.6121e-03,  3.5548e-03,  1.5483e-03,  5.8655e-04])),\n",
       "             ('conv_block1.1.running_var',\n",
       "              tensor([0.9073, 0.9090, 0.9206, 0.9059, 0.9308, 0.9177, 0.9373, 0.9084, 0.9022,\n",
       "                      0.9034, 0.9040, 0.9032, 0.9076, 0.9076, 0.9159, 0.9070, 0.9133, 0.9046,\n",
       "                      0.9115, 0.9012, 0.9048, 0.9139, 0.9213, 0.9043, 0.9053, 0.9121, 0.9093,\n",
       "                      0.9023, 0.9078, 0.9322, 0.9200, 0.9028, 0.9321, 0.9017, 0.9102, 0.9184,\n",
       "                      0.9110, 0.9031, 0.9036, 0.9011, 0.9364, 0.9036, 0.9076, 0.9055, 0.9257,\n",
       "                      0.9493, 0.9036, 0.9059, 0.9110, 0.9025, 0.9563, 0.9039, 0.9019, 0.9064,\n",
       "                      0.9101, 0.9020, 0.9260, 0.9035, 0.9114, 0.9278, 0.9387, 0.9104, 0.9112,\n",
       "                      0.9027])),\n",
       "             ('conv_block1.1.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block2.0.weight',\n",
       "              tensor([[[[ 0.0373,  0.0097, -0.0583],\n",
       "                        [ 0.0189, -0.0194, -0.0202],\n",
       "                        [ 0.0185,  0.0242, -0.0584]],\n",
       "              \n",
       "                       [[ 0.0384,  0.0350,  0.0197],\n",
       "                        [-0.0178, -0.0076,  0.0317],\n",
       "                        [-0.0039,  0.0107, -0.0547]],\n",
       "              \n",
       "                       [[-0.0382,  0.0316,  0.0421],\n",
       "                        [ 0.0043,  0.0250, -0.0105],\n",
       "                        [-0.0248, -0.0387, -0.0285]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0267,  0.0180,  0.0197],\n",
       "                        [ 0.0569, -0.0121, -0.0559],\n",
       "                        [ 0.0078, -0.0047, -0.0521]],\n",
       "              \n",
       "                       [[ 0.0364, -0.0550, -0.0355],\n",
       "                        [-0.0194,  0.0406,  0.0531],\n",
       "                        [-0.0069, -0.0177, -0.0002]],\n",
       "              \n",
       "                       [[ 0.0150, -0.0476, -0.0513],\n",
       "                        [ 0.0370,  0.0160,  0.0292],\n",
       "                        [ 0.0283, -0.0073,  0.0400]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0124,  0.0534, -0.0246],\n",
       "                        [ 0.0292,  0.0210,  0.0109],\n",
       "                        [ 0.0541,  0.0262, -0.0171]],\n",
       "              \n",
       "                       [[-0.0372,  0.0114, -0.0289],\n",
       "                        [ 0.0008, -0.0452, -0.0502],\n",
       "                        [-0.0058,  0.0143, -0.0068]],\n",
       "              \n",
       "                       [[ 0.0492,  0.0561, -0.0463],\n",
       "                        [ 0.0409, -0.0507, -0.0109],\n",
       "                        [-0.0206, -0.0058,  0.0435]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0383, -0.0356,  0.0025],\n",
       "                        [-0.0039,  0.0567, -0.0114],\n",
       "                        [ 0.0072, -0.0234, -0.0583]],\n",
       "              \n",
       "                       [[-0.0029,  0.0420, -0.0086],\n",
       "                        [-0.0434,  0.0024, -0.0152],\n",
       "                        [-0.0106,  0.0496,  0.0135]],\n",
       "              \n",
       "                       [[-0.0550,  0.0505, -0.0382],\n",
       "                        [-0.0134, -0.0565,  0.0580],\n",
       "                        [-0.0473, -0.0451,  0.0058]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0390,  0.0185, -0.0037],\n",
       "                        [-0.0318,  0.0040,  0.0130],\n",
       "                        [-0.0183, -0.0269,  0.0031]],\n",
       "              \n",
       "                       [[ 0.0107, -0.0213,  0.0292],\n",
       "                        [-0.0433,  0.0491, -0.0068],\n",
       "                        [-0.0154,  0.0424, -0.0480]],\n",
       "              \n",
       "                       [[ 0.0063, -0.0363,  0.0185],\n",
       "                        [ 0.0472, -0.0521,  0.0375],\n",
       "                        [-0.0021,  0.0508, -0.0104]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0051,  0.0024,  0.0177],\n",
       "                        [-0.0068, -0.0322, -0.0384],\n",
       "                        [ 0.0419, -0.0419, -0.0499]],\n",
       "              \n",
       "                       [[ 0.0480,  0.0236, -0.0106],\n",
       "                        [ 0.0471, -0.0570,  0.0388],\n",
       "                        [-0.0572,  0.0052, -0.0446]],\n",
       "              \n",
       "                       [[-0.0088, -0.0542,  0.0263],\n",
       "                        [ 0.0247, -0.0446,  0.0321],\n",
       "                        [-0.0388, -0.0305,  0.0066]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0401, -0.0186, -0.0261],\n",
       "                        [ 0.0230, -0.0050,  0.0126],\n",
       "                        [ 0.0109, -0.0288,  0.0374]],\n",
       "              \n",
       "                       [[-0.0461,  0.0382, -0.0556],\n",
       "                        [ 0.0397,  0.0053,  0.0197],\n",
       "                        [ 0.0023, -0.0567, -0.0485]],\n",
       "              \n",
       "                       [[ 0.0365,  0.0534,  0.0506],\n",
       "                        [ 0.0059,  0.0351,  0.0430],\n",
       "                        [-0.0029,  0.0135,  0.0183]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0531,  0.0331, -0.0539],\n",
       "                        [-0.0061, -0.0162,  0.0042],\n",
       "                        [-0.0074,  0.0233, -0.0521]],\n",
       "              \n",
       "                       [[ 0.0404, -0.0262, -0.0397],\n",
       "                        [ 0.0077, -0.0306,  0.0077],\n",
       "                        [-0.0506,  0.0264,  0.0424]],\n",
       "              \n",
       "                       [[-0.0201, -0.0159, -0.0229],\n",
       "                        [ 0.0187,  0.0066,  0.0287],\n",
       "                        [-0.0247, -0.0485,  0.0361]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0039,  0.0527, -0.0293],\n",
       "                        [-0.0139, -0.0478, -0.0022],\n",
       "                        [-0.0294,  0.0190,  0.0153]],\n",
       "              \n",
       "                       [[-0.0120, -0.0456, -0.0225],\n",
       "                        [ 0.0465, -0.0066,  0.0097],\n",
       "                        [ 0.0281, -0.0483, -0.0319]],\n",
       "              \n",
       "                       [[-0.0038, -0.0479, -0.0405],\n",
       "                        [ 0.0414,  0.0058,  0.0524],\n",
       "                        [ 0.0579,  0.0285,  0.0509]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0380, -0.0333,  0.0160],\n",
       "                        [ 0.0518, -0.0396,  0.0444],\n",
       "                        [-0.0093,  0.0522,  0.0005]],\n",
       "              \n",
       "                       [[ 0.0125,  0.0034,  0.0474],\n",
       "                        [ 0.0142, -0.0351, -0.0069],\n",
       "                        [ 0.0121, -0.0275, -0.0226]],\n",
       "              \n",
       "                       [[ 0.0415,  0.0453, -0.0298],\n",
       "                        [ 0.0513,  0.0274, -0.0420],\n",
       "                        [ 0.0465, -0.0393,  0.0109]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0203,  0.0501,  0.0301],\n",
       "                        [-0.0054,  0.0256, -0.0007],\n",
       "                        [ 0.0240, -0.0354,  0.0287]],\n",
       "              \n",
       "                       [[ 0.0130,  0.0426,  0.0444],\n",
       "                        [ 0.0201, -0.0542, -0.0355],\n",
       "                        [ 0.0444, -0.0100, -0.0292]],\n",
       "              \n",
       "                       [[-0.0348,  0.0467,  0.0436],\n",
       "                        [ 0.0532,  0.0513,  0.0218],\n",
       "                        [-0.0342, -0.0325,  0.0575]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0546, -0.0079,  0.0567],\n",
       "                        [-0.0499, -0.0106,  0.0412],\n",
       "                        [-0.0322,  0.0414,  0.0537]],\n",
       "              \n",
       "                       [[-0.0330,  0.0163, -0.0320],\n",
       "                        [ 0.0432,  0.0169, -0.0275],\n",
       "                        [ 0.0113, -0.0529,  0.0081]],\n",
       "              \n",
       "                       [[-0.0088, -0.0389,  0.0028],\n",
       "                        [ 0.0175, -0.0558, -0.0503],\n",
       "                        [ 0.0068, -0.0114, -0.0041]]]])),\n",
       "             ('conv_block2.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block2.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('conv_block2.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block2.1.running_mean',\n",
       "              tensor([-0.0365, -0.0155, -0.0462, -0.0266, -0.0096,  0.0696,  0.0369,  0.0027,\n",
       "                       0.0205, -0.0826, -0.0453,  0.0508,  0.0508, -0.0248,  0.0592, -0.0933,\n",
       "                      -0.0067,  0.0304,  0.0151, -0.0409, -0.0045,  0.0328, -0.0026, -0.0189,\n",
       "                       0.0777, -0.0104, -0.0260,  0.0198, -0.0280, -0.0682,  0.0248,  0.0277,\n",
       "                       0.0428, -0.0451,  0.0939, -0.0510, -0.0259,  0.0710, -0.0363,  0.0256,\n",
       "                      -0.0071, -0.0668, -0.0332,  0.0662, -0.0406, -0.0012, -0.0478, -0.0503,\n",
       "                      -0.0284,  0.0338, -0.0330,  0.0694,  0.0593, -0.0249, -0.0240, -0.0429,\n",
       "                       0.0027, -0.0041, -0.0199, -0.0012,  0.0572,  0.0006,  0.0466,  0.0006,\n",
       "                       0.0173,  0.0676, -0.0421,  0.0141,  0.0169, -0.0905,  0.0214, -0.0346,\n",
       "                      -0.0376, -0.0648, -0.0408, -0.0583, -0.0769,  0.0556, -0.0304, -0.0089,\n",
       "                       0.0223,  0.0318,  0.0327, -0.0091, -0.0166,  0.0553, -0.0570,  0.0120,\n",
       "                       0.0662,  0.0032,  0.0722, -0.0244,  0.0924,  0.0212, -0.0115, -0.0252,\n",
       "                      -0.0029,  0.0080,  0.0274, -0.0145, -0.0031, -0.0866, -0.0687,  0.0019,\n",
       "                       0.0099, -0.0269, -0.0712,  0.0595, -0.0396, -0.0081, -0.0138, -0.0384,\n",
       "                       0.0689, -0.0068,  0.0600,  0.0196, -0.0080, -0.0035, -0.0018, -0.0089,\n",
       "                       0.0497, -0.0101,  0.0224, -0.0055, -0.0613,  0.0612,  0.0076,  0.0382])),\n",
       "             ('conv_block2.1.running_var',\n",
       "              tensor([0.9275, 0.9342, 0.9224, 0.9194, 0.9231, 0.9398, 0.9207, 0.9504, 0.9262,\n",
       "                      0.9274, 0.9347, 0.9731, 0.9225, 0.9264, 0.9236, 0.9487, 0.9482, 0.9287,\n",
       "                      0.9290, 0.9261, 0.9297, 0.9191, 0.9250, 0.9173, 0.9312, 0.9320, 0.9150,\n",
       "                      0.9735, 0.9238, 0.9307, 0.9284, 0.9366, 0.9351, 0.9197, 0.9443, 0.9198,\n",
       "                      0.9269, 0.9624, 0.9393, 0.9184, 0.9308, 0.9434, 0.9263, 0.9391, 0.9224,\n",
       "                      0.9219, 0.9305, 0.9301, 0.9434, 0.9439, 0.9280, 0.9290, 0.9175, 0.9320,\n",
       "                      0.9441, 0.9288, 0.9226, 0.9183, 0.9671, 0.9158, 0.9247, 0.9291, 0.9250,\n",
       "                      0.9293, 0.9246, 0.9299, 0.9337, 0.9174, 0.9227, 0.9632, 0.9228, 0.9228,\n",
       "                      0.9258, 0.9690, 0.9397, 0.9212, 0.9467, 0.9251, 0.9879, 0.9367, 0.9326,\n",
       "                      0.9193, 0.9211, 0.9257, 0.9408, 0.9311, 0.9361, 0.9326, 0.9314, 0.9174,\n",
       "                      0.9463, 0.9277, 0.9304, 0.9211, 0.9194, 0.9200, 0.9185, 0.9386, 0.9155,\n",
       "                      0.9163, 0.9526, 0.9517, 0.9341, 0.9307, 0.9170, 0.9265, 0.9596, 0.9468,\n",
       "                      0.9249, 0.9275, 0.9246, 0.9410, 0.9667, 0.9338, 0.9168, 0.9410, 0.9366,\n",
       "                      0.9144, 0.9201, 0.9354, 0.9391, 0.9248, 0.9421, 0.9091, 0.9224, 0.9408,\n",
       "                      0.9196, 0.9612])),\n",
       "             ('conv_block2.1.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block3.0.weight',\n",
       "              tensor([[[[ 7.7951e-04, -2.0521e-02,  2.9849e-02],\n",
       "                        [-3.7995e-02, -6.3643e-03, -3.6753e-02],\n",
       "                        [ 1.8578e-02,  1.0511e-03, -5.8007e-03]],\n",
       "              \n",
       "                       [[ 3.4615e-02, -1.5688e-02,  2.4563e-02],\n",
       "                        [-2.7093e-02,  2.6573e-02, -2.9480e-02],\n",
       "                        [ 2.9253e-02, -2.0036e-02, -1.8254e-02]],\n",
       "              \n",
       "                       [[-2.6077e-02,  3.3765e-03,  9.7583e-03],\n",
       "                        [ 1.2890e-02,  8.8782e-03, -2.4904e-03],\n",
       "                        [ 3.4919e-02,  1.0696e-02,  3.0568e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5470e-02,  2.8040e-02,  1.6272e-02],\n",
       "                        [ 1.8145e-02,  1.1948e-02, -1.4115e-02],\n",
       "                        [-3.6304e-02,  8.9102e-03, -3.1047e-02]],\n",
       "              \n",
       "                       [[-3.2076e-02,  1.5018e-02, -1.0211e-02],\n",
       "                        [-5.5355e-03,  2.9920e-02, -3.2051e-02],\n",
       "                        [ 2.0601e-03,  3.5161e-02, -3.4079e-02]],\n",
       "              \n",
       "                       [[-3.6132e-03,  3.5562e-02, -1.9953e-03],\n",
       "                        [ 3.0400e-02,  1.4036e-02, -1.9808e-02],\n",
       "                        [-3.8130e-02,  4.0682e-02,  2.0480e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.1583e-03,  2.3923e-02,  3.2124e-02],\n",
       "                        [-2.7196e-02, -2.5307e-02,  2.0927e-02],\n",
       "                        [ 4.1048e-02,  1.2111e-02,  1.6760e-02]],\n",
       "              \n",
       "                       [[ 2.3950e-02, -1.3742e-02,  3.3595e-02],\n",
       "                        [-1.2858e-02,  2.2278e-02,  1.8157e-02],\n",
       "                        [ 1.5231e-02,  7.4726e-03,  2.4243e-02]],\n",
       "              \n",
       "                       [[-1.4871e-02,  3.5980e-02, -1.6664e-02],\n",
       "                        [ 2.5752e-02, -3.6109e-02, -3.7961e-02],\n",
       "                        [ 1.9345e-02,  4.6663e-03, -2.0712e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.4933e-02, -3.1092e-03, -2.7547e-02],\n",
       "                        [ 3.4399e-02,  1.1488e-02, -3.1315e-02],\n",
       "                        [-3.0310e-02,  1.7633e-03, -2.9852e-02]],\n",
       "              \n",
       "                       [[-3.5956e-02,  1.2440e-02,  9.3889e-03],\n",
       "                        [ 2.8855e-04,  2.0455e-02,  1.4701e-02],\n",
       "                        [-2.8581e-02, -3.2025e-02, -4.0969e-02]],\n",
       "              \n",
       "                       [[-2.3479e-03, -1.2891e-02, -1.7764e-02],\n",
       "                        [-4.0656e-02, -1.7264e-02,  1.6369e-02],\n",
       "                        [ 2.2897e-02, -8.7743e-03, -2.1586e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8354e-02,  2.3905e-02,  5.0964e-03],\n",
       "                        [-3.4670e-02,  3.1283e-02, -3.7785e-02],\n",
       "                        [ 1.3290e-02,  7.5739e-04, -3.8247e-02]],\n",
       "              \n",
       "                       [[ 2.8172e-02,  2.9324e-02, -3.3584e-02],\n",
       "                        [ 1.8771e-02, -1.2756e-02, -2.6274e-02],\n",
       "                        [ 2.6463e-02,  2.1719e-02,  2.7584e-02]],\n",
       "              \n",
       "                       [[ 6.3767e-03, -7.3835e-03,  3.4400e-02],\n",
       "                        [-1.2710e-02,  3.9001e-02, -2.3404e-03],\n",
       "                        [-8.1106e-03, -1.9036e-02,  2.5607e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.3083e-02, -3.4493e-03,  6.8314e-03],\n",
       "                        [-3.4777e-02, -5.3508e-03,  3.3350e-02],\n",
       "                        [-3.3822e-02, -5.7343e-03, -2.0977e-02]],\n",
       "              \n",
       "                       [[ 3.1685e-02, -5.6966e-03,  6.8235e-03],\n",
       "                        [-3.9184e-02, -1.1077e-02, -1.0131e-02],\n",
       "                        [-7.4970e-03,  1.7180e-02,  9.4819e-03]],\n",
       "              \n",
       "                       [[ 1.9077e-02, -1.5741e-02,  1.4921e-02],\n",
       "                        [-6.0926e-03,  2.1304e-02, -2.4618e-02],\n",
       "                        [-3.4635e-02,  3.7857e-02, -2.7631e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5142e-02, -3.4894e-02, -8.8607e-03],\n",
       "                        [-2.0419e-02,  3.8927e-02,  7.3121e-03],\n",
       "                        [ 3.4822e-02, -2.1942e-02,  2.8393e-03]],\n",
       "              \n",
       "                       [[ 2.5525e-02,  2.2160e-02, -3.0710e-02],\n",
       "                        [ 1.0547e-02, -3.5218e-02, -2.3903e-02],\n",
       "                        [ 3.5020e-02,  3.0866e-02, -3.2380e-02]],\n",
       "              \n",
       "                       [[ 1.6813e-02, -2.2977e-02, -4.0861e-02],\n",
       "                        [-1.6706e-02,  1.6294e-02,  2.2297e-02],\n",
       "                        [-2.6474e-02, -1.1054e-02, -3.9978e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8785e-02,  3.0236e-02,  3.8953e-02],\n",
       "                        [ 1.1391e-02,  3.2869e-02,  3.6581e-02],\n",
       "                        [ 2.9924e-02, -2.5500e-02, -2.7119e-02]],\n",
       "              \n",
       "                       [[-1.1342e-02,  3.9065e-02,  1.5356e-02],\n",
       "                        [-3.5628e-02,  1.0936e-02,  3.8212e-02],\n",
       "                        [ 2.9660e-02,  1.0403e-03, -3.8576e-02]],\n",
       "              \n",
       "                       [[-4.7817e-04, -4.0994e-02, -2.3776e-02],\n",
       "                        [-3.0564e-02, -1.5824e-02,  3.6637e-03],\n",
       "                        [-3.6760e-02,  2.8401e-02,  3.0106e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0907e-02,  2.6720e-02,  8.3727e-03],\n",
       "                        [ 1.5366e-02, -1.5682e-02, -2.1997e-02],\n",
       "                        [-6.5252e-03,  3.9475e-02,  2.7328e-02]],\n",
       "              \n",
       "                       [[-4.0992e-02, -2.7129e-02, -7.2002e-03],\n",
       "                        [-3.6087e-02,  2.7877e-02, -1.4347e-02],\n",
       "                        [ 1.6583e-02,  3.0020e-02, -2.0694e-02]],\n",
       "              \n",
       "                       [[ 2.8975e-02,  1.0216e-02, -8.1128e-03],\n",
       "                        [-1.9219e-02, -1.0802e-02, -3.3557e-02],\n",
       "                        [-3.9810e-02, -1.5570e-03, -3.4964e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0401e-02, -2.3398e-02, -8.6397e-03],\n",
       "                        [-2.9119e-03, -3.6929e-02, -8.4665e-03],\n",
       "                        [ 4.0616e-02, -1.6103e-02, -4.9711e-03]],\n",
       "              \n",
       "                       [[ 4.0304e-02, -1.6992e-02,  3.3784e-02],\n",
       "                        [-4.0261e-02,  3.8796e-02,  1.5696e-02],\n",
       "                        [ 1.4986e-02,  3.5922e-02, -2.8797e-02]],\n",
       "              \n",
       "                       [[ 1.0135e-03, -4.0422e-02, -2.1348e-02],\n",
       "                        [ 2.4431e-02, -7.3403e-03,  1.7116e-02],\n",
       "                        [ 7.3021e-03, -1.4903e-02,  5.9696e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9201e-02, -2.7713e-02,  3.7680e-02],\n",
       "                        [ 3.5548e-02, -1.3779e-02,  6.6100e-04],\n",
       "                        [-3.4967e-03,  1.1284e-02,  9.3316e-03]],\n",
       "              \n",
       "                       [[ 3.6500e-02, -2.9467e-04,  1.6469e-02],\n",
       "                        [ 2.5765e-03, -3.8813e-02,  2.3844e-02],\n",
       "                        [ 3.4335e-02,  6.7304e-03, -3.2942e-02]],\n",
       "              \n",
       "                       [[ 9.9711e-03, -4.0743e-02, -2.6181e-02],\n",
       "                        [ 3.6778e-02,  5.5764e-03, -4.1720e-03],\n",
       "                        [-3.3865e-02,  1.1037e-02,  1.0713e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7574e-03, -1.4033e-02,  1.5066e-02],\n",
       "                        [-8.1389e-03, -4.2432e-03,  2.3427e-02],\n",
       "                        [-2.2486e-02,  2.1545e-02,  1.9694e-02]],\n",
       "              \n",
       "                       [[-6.0369e-03,  3.1585e-02, -2.8286e-02],\n",
       "                        [ 1.4889e-02,  3.1174e-02, -6.1152e-04],\n",
       "                        [ 4.0378e-02,  1.6628e-02,  3.9483e-02]],\n",
       "              \n",
       "                       [[-6.3186e-03, -3.6149e-02,  3.6806e-02],\n",
       "                        [-1.5515e-03, -1.8717e-02,  2.8609e-02],\n",
       "                        [-1.8463e-05,  3.8629e-02,  3.5071e-02]]]])),\n",
       "             ('conv_block3.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block3.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('conv_block3.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block3.1.running_mean',\n",
       "              tensor([ 1.1061e-02, -6.4689e-03,  1.1685e-01,  2.9623e-02, -8.3275e-03,\n",
       "                       3.6393e-02,  5.2140e-02, -2.6648e-02, -2.7876e-03,  3.8507e-02,\n",
       "                      -4.9871e-02,  7.0497e-02, -3.4801e-03,  2.3621e-02,  1.4710e-02,\n",
       "                      -3.6327e-02,  5.8142e-02,  1.8341e-02,  4.0528e-02,  1.3356e-03,\n",
       "                      -2.6162e-02, -7.2008e-02,  5.1407e-02, -1.0488e-01,  1.1651e-01,\n",
       "                      -6.3679e-02, -8.5248e-02, -7.5050e-02, -6.9498e-03, -5.1539e-02,\n",
       "                      -1.9608e-02, -4.1369e-02,  2.2747e-02, -7.8234e-02,  3.5812e-02,\n",
       "                       2.2067e-02, -1.3951e-02,  1.5819e-02,  9.6007e-02,  6.0226e-02,\n",
       "                       2.2402e-02, -1.5196e-04,  6.0356e-02,  5.0908e-02,  5.8260e-03,\n",
       "                       4.1138e-02, -4.4209e-02, -5.0574e-02, -1.2276e-02, -2.7605e-02,\n",
       "                      -4.8781e-03, -6.0541e-03, -1.0783e-01,  2.3900e-04, -1.2833e-02,\n",
       "                      -5.0734e-02, -2.4707e-02,  8.5585e-02, -4.3885e-03, -5.5691e-02,\n",
       "                      -5.8821e-02,  1.1580e-01,  8.9746e-02, -5.6115e-02, -8.2742e-02,\n",
       "                      -1.3371e-02,  1.2476e-01,  6.6509e-02,  6.7953e-02, -9.8334e-03,\n",
       "                      -3.1325e-02,  2.1034e-02,  6.2407e-02,  7.6374e-02, -1.7126e-02,\n",
       "                      -3.0873e-02,  3.0857e-02, -9.7883e-05,  3.9509e-02, -3.6447e-02,\n",
       "                      -7.9698e-03, -3.7143e-02, -1.2433e-02,  1.2857e-02,  4.5461e-02,\n",
       "                      -6.9196e-02,  4.1543e-02, -6.7880e-02,  5.5650e-03, -1.0051e-03,\n",
       "                      -2.1074e-02,  1.8695e-02,  3.3778e-02,  5.6040e-02, -1.6760e-02,\n",
       "                      -1.0077e-02, -3.9491e-02, -8.4289e-02, -8.9654e-02, -1.4467e-02,\n",
       "                       4.7183e-03, -2.8108e-02, -3.7855e-02, -1.6454e-02, -1.3348e-01,\n",
       "                      -2.2585e-02, -4.5414e-02, -1.0156e-01,  4.5752e-02,  3.6345e-02,\n",
       "                       4.3702e-02,  4.9469e-02,  1.3149e-02,  8.2332e-02,  6.9193e-02,\n",
       "                       6.5660e-02, -1.0918e-02,  3.9418e-02,  9.2414e-02,  9.1160e-03,\n",
       "                       4.6763e-02,  4.3385e-03,  4.3774e-03, -8.0070e-02, -7.1312e-03,\n",
       "                      -3.7036e-03,  1.5290e-02, -8.1510e-02, -4.2409e-02,  7.5380e-02,\n",
       "                      -3.2316e-02, -6.0311e-02,  6.8636e-02, -4.5310e-02,  3.5768e-03,\n",
       "                       1.2641e-02, -4.3989e-02, -2.2476e-02,  7.3843e-02, -2.9146e-02,\n",
       "                      -1.3396e-02, -2.0254e-02, -1.0449e-03,  3.3294e-02,  6.8087e-02,\n",
       "                      -1.1729e-03, -3.3637e-02,  2.9312e-02, -2.4230e-02,  3.1410e-02,\n",
       "                      -1.0030e-01, -1.3827e-02,  7.3774e-02,  3.9783e-02,  2.6266e-02,\n",
       "                       5.8895e-02, -5.8577e-02,  2.1375e-02,  6.8270e-02,  2.4042e-02,\n",
       "                       5.8618e-02,  2.8838e-02, -2.3213e-02, -4.9029e-02, -4.0107e-02,\n",
       "                      -1.3074e-02, -4.9545e-02, -6.5340e-03, -6.8347e-02, -3.6883e-03,\n",
       "                      -8.0095e-03,  6.8992e-02,  7.2079e-02,  1.1783e-02, -1.6437e-02,\n",
       "                       1.5612e-02, -8.2976e-02, -4.3081e-02, -9.0703e-03,  4.1686e-02,\n",
       "                       1.7552e-02, -5.6966e-03, -4.1132e-02,  7.9117e-02, -7.1687e-02,\n",
       "                       1.6091e-02, -1.3158e-02, -4.2505e-02,  8.9616e-02,  6.8055e-03,\n",
       "                       1.4335e-01,  2.6731e-02, -1.8254e-02, -8.2523e-02, -2.1372e-02,\n",
       "                       1.1099e-01,  7.1219e-03,  8.3337e-02,  6.5300e-02,  1.2172e-02,\n",
       "                      -3.3676e-02,  6.6194e-02,  4.8125e-02, -5.6700e-03, -4.0869e-02,\n",
       "                       1.2599e-02,  6.1498e-02, -6.4238e-03, -2.7700e-02, -5.3836e-02,\n",
       "                       8.2244e-03, -5.4264e-02,  7.2522e-02,  5.8768e-02,  2.1207e-02,\n",
       "                      -2.5397e-02,  7.9759e-02, -4.2535e-02,  4.4001e-03,  1.6141e-02,\n",
       "                      -4.2292e-03,  4.6598e-02,  8.2979e-02,  1.7275e-02, -6.4211e-02,\n",
       "                      -3.0850e-03,  3.5755e-02,  2.4088e-02,  7.6411e-02, -1.6424e-02,\n",
       "                      -7.8766e-02,  4.1673e-03, -2.7210e-02, -5.6590e-02,  1.4677e-02,\n",
       "                       8.7840e-02, -5.9742e-02,  4.1195e-02, -5.6481e-02, -4.0559e-02,\n",
       "                       5.3340e-02,  3.3735e-02,  7.9530e-02, -2.1645e-02,  5.7334e-02,\n",
       "                       5.3211e-02, -2.1347e-02, -1.6576e-02,  2.7862e-02,  3.4489e-02,\n",
       "                       3.1120e-02,  8.3343e-02,  8.8591e-02, -1.8731e-02, -4.4525e-02,\n",
       "                      -1.5728e-02])),\n",
       "             ('conv_block3.1.running_var',\n",
       "              tensor([0.9288, 0.9476, 0.9403, 0.9266, 0.9274, 0.9401, 0.9270, 0.9356, 0.9273,\n",
       "                      0.9470, 0.9397, 0.9300, 0.9192, 0.9202, 0.9225, 0.9392, 0.9533, 0.9261,\n",
       "                      0.9402, 0.9413, 0.9320, 0.9591, 0.9269, 0.9382, 0.9399, 0.9433, 0.9480,\n",
       "                      0.9429, 0.9232, 0.9251, 0.9331, 0.9540, 0.9272, 0.9522, 0.9406, 0.9279,\n",
       "                      0.9212, 0.9321, 0.9517, 0.9261, 0.9273, 0.9377, 0.9563, 0.9214, 0.9283,\n",
       "                      0.9452, 0.9283, 0.9385, 0.9308, 0.9243, 0.9282, 0.9416, 0.9352, 0.9235,\n",
       "                      0.9252, 0.9365, 0.9524, 0.9289, 0.9350, 0.9318, 0.9381, 0.9542, 0.9482,\n",
       "                      0.9331, 0.9384, 0.9220, 0.9331, 0.9310, 0.9504, 0.9237, 0.9452, 0.9403,\n",
       "                      0.9373, 0.9262, 0.9424, 0.9363, 0.9477, 0.9378, 0.9521, 0.9396, 0.9296,\n",
       "                      0.9618, 0.9302, 0.9219, 0.9384, 0.9360, 0.9603, 0.9486, 0.9311, 0.9266,\n",
       "                      0.9296, 0.9257, 0.9349, 0.9375, 0.9436, 0.9357, 0.9249, 0.9549, 0.9348,\n",
       "                      0.9213, 0.9376, 0.9249, 0.9493, 0.9356, 0.9533, 0.9459, 0.9316, 0.9481,\n",
       "                      0.9282, 0.9290, 0.9249, 0.9360, 0.9242, 0.9328, 0.9301, 0.9306, 0.9266,\n",
       "                      0.9218, 0.9575, 0.9263, 0.9332, 0.9385, 0.9255, 0.9471, 0.9304, 0.9221,\n",
       "                      0.9276, 0.9702, 0.9237, 0.9292, 0.9352, 0.9471, 0.9399, 0.9453, 0.9234,\n",
       "                      0.9277, 0.9397, 0.9403, 0.9623, 0.9353, 0.9298, 0.9342, 0.9387, 0.9273,\n",
       "                      0.9297, 0.9409, 0.9441, 0.9388, 0.9291, 0.9245, 0.9698, 0.9234, 0.9366,\n",
       "                      0.9242, 0.9434, 0.9521, 0.9269, 0.9289, 0.9368, 0.9219, 0.9308, 0.9300,\n",
       "                      0.9332, 0.9412, 0.9385, 0.9536, 0.9242, 0.9223, 0.9847, 0.9310, 0.9369,\n",
       "                      0.9431, 0.9376, 0.9430, 0.9711, 0.9369, 0.9431, 0.9275, 0.9389, 0.9276,\n",
       "                      0.9401, 0.9351, 0.9263, 0.9417, 0.9508, 0.9257, 0.9250, 0.9219, 0.9387,\n",
       "                      0.9274, 0.9430, 0.9277, 0.9245, 0.9327, 0.9330, 0.9379, 0.9196, 0.9291,\n",
       "                      0.9682, 0.9211, 0.9465, 0.9452, 0.9365, 0.9265, 0.9330, 0.9393, 0.9218,\n",
       "                      0.9273, 0.9246, 0.9387, 0.9224, 0.9297, 0.9286, 0.9317, 0.9374, 0.9246,\n",
       "                      0.9364, 0.9500, 0.9361, 0.9402, 0.9236, 0.9269, 0.9350, 0.9481, 0.9263,\n",
       "                      0.9270, 0.9348, 0.9415, 0.9302, 0.9209, 0.9387, 0.9268, 0.9213, 0.9382,\n",
       "                      0.9234, 0.9354, 0.9476, 0.9304, 0.9229, 0.9320, 0.9397, 0.9223, 0.9399,\n",
       "                      0.9336, 0.9439, 0.9276, 0.9207, 0.9398, 0.9302, 0.9296, 0.9694, 0.9563,\n",
       "                      0.9358, 0.9237, 0.9362, 0.9187])),\n",
       "             ('conv_block3.1.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block3.3.weight',\n",
       "              tensor([[[[-5.9732e-05, -4.4388e-03,  1.5257e-02],\n",
       "                        [ 3.4986e-02,  3.1283e-03, -1.1927e-02],\n",
       "                        [-1.9493e-02,  3.1270e-02, -8.9562e-04]],\n",
       "              \n",
       "                       [[-6.2289e-03,  1.7054e-02,  3.5719e-02],\n",
       "                        [ 1.3505e-03, -7.0164e-03,  1.2166e-02],\n",
       "                        [-3.4234e-02,  2.6173e-02,  2.0464e-03]],\n",
       "              \n",
       "                       [[-1.9645e-03, -1.6776e-02, -3.2679e-02],\n",
       "                        [-1.0534e-02, -8.6024e-03,  1.3546e-02],\n",
       "                        [-7.1690e-04, -3.0563e-02, -2.3155e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.1589e-02, -2.1832e-02,  3.0378e-02],\n",
       "                        [-1.8613e-02, -1.0656e-02, -3.1734e-02],\n",
       "                        [ 1.6982e-02, -1.7750e-02, -1.4314e-03]],\n",
       "              \n",
       "                       [[-9.5743e-03, -3.1847e-02,  1.6804e-03],\n",
       "                        [ 2.1318e-02,  8.9846e-03,  3.2372e-02],\n",
       "                        [-1.3390e-03, -3.4911e-02, -8.1687e-03]],\n",
       "              \n",
       "                       [[-2.5396e-02,  2.2379e-03, -2.6148e-02],\n",
       "                        [ 1.0025e-02,  3.5974e-02, -1.5430e-02],\n",
       "                        [ 2.2362e-02, -1.6759e-02,  3.0628e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7008e-02,  4.6141e-04, -2.5659e-02],\n",
       "                        [-1.3331e-02, -2.5220e-02,  4.5747e-03],\n",
       "                        [ 2.8866e-02,  3.4024e-02, -2.4810e-02]],\n",
       "              \n",
       "                       [[ 3.3832e-02,  1.2522e-03, -2.3721e-02],\n",
       "                        [-1.6954e-02,  2.1073e-02, -1.6777e-02],\n",
       "                        [ 1.9550e-02,  3.4953e-02, -8.1860e-03]],\n",
       "              \n",
       "                       [[ 6.8039e-03,  4.1232e-03, -1.2889e-02],\n",
       "                        [ 2.8422e-02, -6.5329e-03, -3.4698e-02],\n",
       "                        [-3.4463e-03,  4.0089e-03,  7.7719e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.4586e-02,  5.3795e-03, -2.0306e-02],\n",
       "                        [ 2.9853e-02,  1.8956e-02, -1.1798e-02],\n",
       "                        [ 1.1288e-03,  1.1600e-02, -3.2564e-02]],\n",
       "              \n",
       "                       [[-9.5566e-03,  2.3661e-02,  1.6006e-02],\n",
       "                        [-1.8875e-02, -2.6093e-02, -1.7087e-02],\n",
       "                        [-1.1917e-02, -2.5018e-02, -1.5916e-02]],\n",
       "              \n",
       "                       [[ 2.9990e-02, -8.3808e-05,  1.3170e-02],\n",
       "                        [-9.8000e-03,  1.0967e-02, -3.4632e-02],\n",
       "                        [ 4.7450e-03,  2.9564e-02, -1.9544e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3182e-02,  1.7293e-02,  2.9023e-02],\n",
       "                        [ 3.7431e-03, -3.3352e-02,  1.3136e-02],\n",
       "                        [ 3.0106e-02, -9.4211e-03, -1.7806e-02]],\n",
       "              \n",
       "                       [[-1.3241e-03, -2.4017e-02,  1.4243e-02],\n",
       "                        [-2.8652e-02,  1.4446e-02, -3.1954e-03],\n",
       "                        [ 2.8327e-02, -3.8381e-04,  2.5938e-02]],\n",
       "              \n",
       "                       [[-1.2659e-02,  1.6595e-02,  6.3836e-03],\n",
       "                        [ 8.0894e-03,  2.6320e-02,  2.0349e-02],\n",
       "                        [-1.9547e-02, -1.3421e-02,  4.8697e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0964e-02,  2.0348e-02, -2.0460e-02],\n",
       "                        [ 2.9534e-02, -1.5180e-02, -2.8123e-02],\n",
       "                        [ 1.1662e-02, -2.3422e-02,  2.4941e-03]],\n",
       "              \n",
       "                       [[-4.9070e-04,  3.4464e-02, -1.1360e-02],\n",
       "                        [-1.2866e-02, -1.7768e-02,  1.0438e-02],\n",
       "                        [-3.2288e-02,  3.6012e-02, -9.3501e-03]],\n",
       "              \n",
       "                       [[ 3.4061e-02, -8.1154e-04,  1.7896e-02],\n",
       "                        [-9.9617e-03,  4.8454e-03,  3.1512e-02],\n",
       "                        [ 1.3343e-02, -2.3691e-02, -5.1359e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8125e-02,  1.1645e-02, -2.5353e-02],\n",
       "                        [-3.6207e-04,  2.4579e-02, -2.8754e-02],\n",
       "                        [ 1.2994e-03,  1.4807e-03,  1.5220e-02]],\n",
       "              \n",
       "                       [[ 2.1025e-02,  3.6036e-02, -3.1021e-02],\n",
       "                        [ 3.0436e-02,  2.3385e-03,  1.6001e-02],\n",
       "                        [ 1.1068e-02,  1.3172e-02,  3.0878e-02]],\n",
       "              \n",
       "                       [[ 2.8381e-02, -1.4236e-02,  3.3839e-02],\n",
       "                        [-8.9103e-05,  2.7303e-02,  3.4600e-02],\n",
       "                        [ 3.2760e-02,  2.7268e-02, -1.8670e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.1603e-02, -2.0793e-02,  2.1293e-02],\n",
       "                        [ 2.1044e-03, -2.8456e-02, -2.8917e-03],\n",
       "                        [-2.8790e-02, -1.2803e-02, -1.7343e-02]],\n",
       "              \n",
       "                       [[ 6.0571e-03,  1.8282e-02,  1.2031e-03],\n",
       "                        [-1.4168e-02,  3.3329e-02,  1.8982e-02],\n",
       "                        [ 1.2148e-02, -8.2972e-03, -2.4487e-02]],\n",
       "              \n",
       "                       [[ 2.1590e-02, -3.3981e-02,  2.3037e-02],\n",
       "                        [-2.7131e-02,  2.2734e-02,  1.5628e-02],\n",
       "                        [-2.1911e-02, -1.4721e-03,  1.9929e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.1859e-05, -3.0754e-02,  2.5402e-02],\n",
       "                        [ 7.1831e-03, -1.1878e-02, -2.8247e-02],\n",
       "                        [ 9.5029e-03, -3.3973e-02, -2.0750e-04]],\n",
       "              \n",
       "                       [[-1.4011e-02, -1.4015e-02, -2.9993e-02],\n",
       "                        [ 3.0362e-02, -1.0833e-02,  3.6571e-03],\n",
       "                        [ 1.9111e-02, -2.6417e-02,  1.8423e-02]],\n",
       "              \n",
       "                       [[ 1.7931e-02, -3.1148e-02,  1.4448e-02],\n",
       "                        [-2.4495e-02,  2.7415e-02, -1.1104e-03],\n",
       "                        [-5.4648e-03, -1.8028e-02,  2.9204e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.5559e-02, -2.0125e-02, -2.3320e-02],\n",
       "                        [ 6.2010e-04,  1.6070e-02, -4.0810e-03],\n",
       "                        [-2.6895e-02, -9.3650e-04, -2.0503e-02]],\n",
       "              \n",
       "                       [[-2.5320e-03, -5.8320e-03, -5.1721e-03],\n",
       "                        [-1.9671e-02,  3.0181e-02, -1.2617e-02],\n",
       "                        [ 2.6640e-02,  2.9944e-02,  5.0036e-03]],\n",
       "              \n",
       "                       [[-1.1541e-02,  3.0827e-02, -1.2020e-02],\n",
       "                        [-3.0844e-02,  5.5736e-03,  7.8299e-03],\n",
       "                        [-1.7972e-02, -1.9521e-02,  2.5705e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2188e-02, -2.4690e-02, -1.6633e-02],\n",
       "                        [-1.1490e-02, -1.3941e-02,  3.2848e-02],\n",
       "                        [-3.2858e-03,  2.3075e-02, -2.9661e-02]],\n",
       "              \n",
       "                       [[-3.4302e-02, -1.1329e-02, -2.5288e-02],\n",
       "                        [ 2.1929e-02,  3.3512e-02, -6.1983e-03],\n",
       "                        [ 7.7154e-03, -7.2092e-04,  6.2729e-03]],\n",
       "              \n",
       "                       [[ 2.5246e-02, -2.5195e-02, -3.9309e-03],\n",
       "                        [ 7.4724e-03,  1.0444e-02,  2.3682e-02],\n",
       "                        [-3.6240e-03, -1.4612e-02,  2.3243e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.5954e-02,  3.5266e-02, -2.1418e-02],\n",
       "                        [ 3.1349e-03,  4.6327e-03,  2.0082e-02],\n",
       "                        [ 2.9191e-02,  5.3660e-03, -1.4868e-02]],\n",
       "              \n",
       "                       [[-2.6684e-02, -1.2705e-02, -5.8100e-03],\n",
       "                        [ 1.6057e-02, -3.6435e-03,  3.5051e-03],\n",
       "                        [-2.7754e-02, -2.5373e-02, -1.1243e-02]],\n",
       "              \n",
       "                       [[-1.0952e-02,  3.2645e-04, -8.1049e-03],\n",
       "                        [ 3.3170e-02,  1.0125e-02,  2.5316e-04],\n",
       "                        [ 8.9368e-03,  2.3815e-02,  1.0339e-02]]]])),\n",
       "             ('conv_block3.3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block3.4.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('conv_block3.4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block3.4.running_mean',\n",
       "              tensor([ 0.0119,  0.0325,  0.0506, -0.0092,  0.0262, -0.0143, -0.0208, -0.0108,\n",
       "                       0.0375, -0.0246,  0.0173,  0.0308, -0.0029, -0.0226, -0.0383, -0.0504,\n",
       "                      -0.0109, -0.0388,  0.0024, -0.0188,  0.0056, -0.0042, -0.0007,  0.0293,\n",
       "                       0.0039, -0.0237, -0.0124, -0.0717,  0.0293,  0.0145, -0.0043,  0.0304,\n",
       "                      -0.0762,  0.0063,  0.0002,  0.0184,  0.0069,  0.0157, -0.0017, -0.0462,\n",
       "                       0.0122, -0.0126,  0.0165, -0.0134, -0.0029, -0.0443,  0.0878,  0.0147,\n",
       "                      -0.0377, -0.0116,  0.0368,  0.0183,  0.0269, -0.0369,  0.0040,  0.0563,\n",
       "                       0.0259, -0.0160, -0.0072,  0.0462,  0.0495,  0.0445,  0.1153,  0.0344,\n",
       "                       0.0144, -0.0659, -0.0001,  0.0248,  0.0732,  0.0235,  0.0267,  0.0283,\n",
       "                       0.0241, -0.0220, -0.0114, -0.0089,  0.0128,  0.0237,  0.0628, -0.0083,\n",
       "                      -0.0203,  0.0067, -0.0051,  0.0411,  0.0024,  0.0451, -0.0055, -0.0204,\n",
       "                       0.0072, -0.0175,  0.0126, -0.0064,  0.0239, -0.0252,  0.0313, -0.0272,\n",
       "                      -0.0044,  0.0149,  0.0134, -0.0273,  0.0090,  0.0214, -0.0232, -0.0046,\n",
       "                       0.0290,  0.0288,  0.0077, -0.0501,  0.0285,  0.0008,  0.0057,  0.0002,\n",
       "                       0.0855,  0.0096,  0.0501, -0.0444,  0.0435, -0.0103, -0.0018, -0.0193,\n",
       "                      -0.0049,  0.0210,  0.0492,  0.0412,  0.0367, -0.0252,  0.0013, -0.0182,\n",
       "                      -0.0050, -0.0366,  0.0614,  0.0112, -0.0349,  0.0657,  0.0107,  0.0257,\n",
       "                      -0.0380, -0.0161,  0.0170,  0.0510,  0.0415,  0.0111, -0.0079, -0.0130,\n",
       "                      -0.1024, -0.0255, -0.0375, -0.0106, -0.0304, -0.0058, -0.0307,  0.0020,\n",
       "                      -0.0242, -0.0465, -0.0417,  0.0494, -0.0109, -0.0589, -0.0528, -0.0027,\n",
       "                      -0.0320, -0.0310, -0.0111,  0.0073,  0.0125, -0.0020, -0.0327, -0.0414,\n",
       "                      -0.0146,  0.0091,  0.0094,  0.0106,  0.0175, -0.0388, -0.0163,  0.0192,\n",
       "                      -0.0095, -0.0118,  0.0167, -0.0639, -0.0226,  0.0090,  0.0242, -0.0593,\n",
       "                       0.0292,  0.0491, -0.0216,  0.0249,  0.0397, -0.0111,  0.0285, -0.0231,\n",
       "                       0.0240,  0.0139,  0.0040,  0.0453,  0.0049,  0.0037,  0.0124,  0.0431,\n",
       "                       0.0264, -0.0375, -0.1040,  0.0127,  0.0523,  0.0174,  0.0099,  0.0026,\n",
       "                       0.0335,  0.0059, -0.0057, -0.0657, -0.0117, -0.0246,  0.0089,  0.0247,\n",
       "                      -0.0111,  0.0101,  0.0403,  0.0814,  0.0445, -0.0263,  0.0201, -0.0482,\n",
       "                      -0.0082,  0.0331, -0.0841, -0.0390, -0.0142,  0.0248, -0.0148,  0.0084,\n",
       "                      -0.0208, -0.0071, -0.0045,  0.0201,  0.0037,  0.0115,  0.0219,  0.0060,\n",
       "                       0.0386,  0.0100, -0.0098, -0.0337,  0.0267,  0.0448, -0.0107, -0.0101,\n",
       "                      -0.0446, -0.0187,  0.0257,  0.0156, -0.0005,  0.0310,  0.0589, -0.0164])),\n",
       "             ('conv_block3.4.running_var',\n",
       "              tensor([0.9236, 0.9247, 0.9331, 0.9320, 0.9305, 0.9325, 0.9324, 0.9315, 0.9244,\n",
       "                      0.9321, 0.9282, 0.9324, 0.9267, 0.9327, 0.9390, 0.9293, 0.9242, 0.9376,\n",
       "                      0.9282, 0.9256, 0.9261, 0.9385, 0.9287, 0.9298, 0.9318, 0.9285, 0.9328,\n",
       "                      0.9254, 0.9273, 0.9261, 0.9371, 0.9244, 0.9372, 0.9257, 0.9254, 0.9371,\n",
       "                      0.9293, 0.9316, 0.9304, 0.9284, 0.9243, 0.9318, 0.9415, 0.9267, 0.9295,\n",
       "                      0.9312, 0.9479, 0.9319, 0.9274, 0.9242, 0.9304, 0.9273, 0.9262, 0.9313,\n",
       "                      0.9470, 0.9298, 0.9287, 0.9211, 0.9439, 0.9255, 0.9342, 0.9530, 0.9563,\n",
       "                      0.9336, 0.9319, 0.9243, 0.9357, 0.9310, 0.9357, 0.9305, 0.9263, 0.9322,\n",
       "                      0.9348, 0.9429, 0.9372, 0.9300, 0.9255, 0.9267, 0.9370, 0.9379, 0.9266,\n",
       "                      0.9345, 0.9248, 0.9466, 0.9300, 0.9268, 0.9333, 0.9282, 0.9228, 0.9337,\n",
       "                      0.9364, 0.9333, 0.9348, 0.9263, 0.9262, 0.9309, 0.9295, 0.9259, 0.9283,\n",
       "                      0.9294, 0.9289, 0.9482, 0.9323, 0.9287, 0.9258, 0.9409, 0.9503, 0.9403,\n",
       "                      0.9241, 0.9308, 0.9312, 0.9327, 0.9568, 0.9367, 0.9333, 0.9283, 0.9290,\n",
       "                      0.9351, 0.9300, 0.9331, 0.9294, 0.9291, 0.9343, 0.9358, 0.9368, 0.9398,\n",
       "                      0.9336, 0.9359, 0.9310, 0.9243, 0.9329, 0.9268, 0.9263, 0.9438, 0.9292,\n",
       "                      0.9371, 0.9312, 0.9240, 0.9296, 0.9274, 0.9425, 0.9298, 0.9362, 0.9294,\n",
       "                      0.9366, 0.9310, 0.9331, 0.9339, 0.9273, 0.9338, 0.9271, 0.9262, 0.9442,\n",
       "                      0.9356, 0.9329, 0.9319, 0.9270, 0.9414, 0.9439, 0.9261, 0.9266, 0.9249,\n",
       "                      0.9310, 0.9266, 0.9389, 0.9383, 0.9402, 0.9323, 0.9284, 0.9313, 0.9354,\n",
       "                      0.9269, 0.9302, 0.9348, 0.9309, 0.9281, 0.9261, 0.9396, 0.9325, 0.9251,\n",
       "                      0.9356, 0.9251, 0.9235, 0.9357, 0.9260, 0.9336, 0.9267, 0.9340, 0.9331,\n",
       "                      0.9242, 0.9239, 0.9252, 0.9238, 0.9416, 0.9364, 0.9363, 0.9272, 0.9391,\n",
       "                      0.9270, 0.9270, 0.9375, 0.9319, 0.9437, 0.9263, 0.9372, 0.9337, 0.9271,\n",
       "                      0.9325, 0.9282, 0.9361, 0.9311, 0.9375, 0.9287, 0.9303, 0.9305, 0.9308,\n",
       "                      0.9339, 0.9305, 0.9386, 0.9372, 0.9384, 0.9325, 0.9378, 0.9269, 0.9273,\n",
       "                      0.9327, 0.9557, 0.9272, 0.9379, 0.9267, 0.9291, 0.9433, 0.9250, 0.9454,\n",
       "                      0.9403, 0.9378, 0.9276, 0.9284, 0.9291, 0.9253, 0.9339, 0.9255, 0.9283,\n",
       "                      0.9357, 0.9265, 0.9315, 0.9247, 0.9236, 0.9280, 0.9257, 0.9260, 0.9240,\n",
       "                      0.9246, 0.9317, 0.9354, 0.9263])),\n",
       "             ('conv_block3.4.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block4.0.weight',\n",
       "              tensor([[[[-0.0084,  0.0164,  0.0178],\n",
       "                        [ 0.0129,  0.0198,  0.0024],\n",
       "                        [-0.0075,  0.0058,  0.0012]],\n",
       "              \n",
       "                       [[-0.0176,  0.0111,  0.0123],\n",
       "                        [ 0.0022,  0.0234, -0.0265],\n",
       "                        [ 0.0154, -0.0020, -0.0291]],\n",
       "              \n",
       "                       [[ 0.0122, -0.0006, -0.0186],\n",
       "                        [ 0.0167, -0.0155, -0.0204],\n",
       "                        [ 0.0025,  0.0084, -0.0087]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0018,  0.0229, -0.0084],\n",
       "                        [ 0.0110,  0.0238,  0.0167],\n",
       "                        [ 0.0233, -0.0025,  0.0095]],\n",
       "              \n",
       "                       [[ 0.0267,  0.0225,  0.0009],\n",
       "                        [ 0.0114, -0.0180,  0.0062],\n",
       "                        [-0.0121,  0.0224, -0.0074]],\n",
       "              \n",
       "                       [[-0.0018, -0.0180,  0.0161],\n",
       "                        [-0.0263, -0.0059,  0.0133],\n",
       "                        [-0.0041,  0.0261, -0.0272]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0063,  0.0155, -0.0260],\n",
       "                        [-0.0039, -0.0278,  0.0243],\n",
       "                        [ 0.0279, -0.0249, -0.0275]],\n",
       "              \n",
       "                       [[-0.0279, -0.0231,  0.0146],\n",
       "                        [-0.0081, -0.0042,  0.0041],\n",
       "                        [-0.0145, -0.0230, -0.0133]],\n",
       "              \n",
       "                       [[-0.0038, -0.0178, -0.0121],\n",
       "                        [ 0.0103, -0.0205,  0.0079],\n",
       "                        [-0.0047, -0.0293, -0.0235]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0192, -0.0236, -0.0200],\n",
       "                        [ 0.0222, -0.0276,  0.0040],\n",
       "                        [ 0.0071,  0.0124,  0.0056]],\n",
       "              \n",
       "                       [[-0.0270, -0.0084, -0.0100],\n",
       "                        [-0.0249, -0.0284,  0.0043],\n",
       "                        [ 0.0291, -0.0181,  0.0083]],\n",
       "              \n",
       "                       [[-0.0022,  0.0246,  0.0189],\n",
       "                        [ 0.0070, -0.0016,  0.0168],\n",
       "                        [-0.0073,  0.0116, -0.0126]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0214,  0.0115,  0.0146],\n",
       "                        [ 0.0015, -0.0254,  0.0191],\n",
       "                        [ 0.0131,  0.0161,  0.0113]],\n",
       "              \n",
       "                       [[ 0.0161,  0.0128,  0.0028],\n",
       "                        [-0.0194, -0.0120,  0.0077],\n",
       "                        [ 0.0190,  0.0202, -0.0253]],\n",
       "              \n",
       "                       [[ 0.0151, -0.0240, -0.0209],\n",
       "                        [ 0.0047,  0.0236,  0.0141],\n",
       "                        [ 0.0211, -0.0018, -0.0137]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0255,  0.0271, -0.0123],\n",
       "                        [-0.0154, -0.0127, -0.0290],\n",
       "                        [ 0.0157,  0.0068, -0.0091]],\n",
       "              \n",
       "                       [[ 0.0057, -0.0242, -0.0171],\n",
       "                        [-0.0202,  0.0072, -0.0150],\n",
       "                        [ 0.0241, -0.0223,  0.0220]],\n",
       "              \n",
       "                       [[ 0.0204, -0.0079, -0.0022],\n",
       "                        [ 0.0219, -0.0099,  0.0261],\n",
       "                        [ 0.0140, -0.0238, -0.0118]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0148, -0.0011,  0.0153],\n",
       "                        [-0.0082,  0.0149,  0.0185],\n",
       "                        [-0.0232,  0.0231, -0.0003]],\n",
       "              \n",
       "                       [[-0.0174,  0.0098,  0.0079],\n",
       "                        [ 0.0114, -0.0220, -0.0008],\n",
       "                        [ 0.0135,  0.0194, -0.0034]],\n",
       "              \n",
       "                       [[-0.0169, -0.0021,  0.0252],\n",
       "                        [-0.0204, -0.0250, -0.0169],\n",
       "                        [ 0.0119,  0.0113,  0.0101]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0063, -0.0190, -0.0152],\n",
       "                        [-0.0206, -0.0038,  0.0079],\n",
       "                        [ 0.0110, -0.0023,  0.0071]],\n",
       "              \n",
       "                       [[-0.0243,  0.0018,  0.0011],\n",
       "                        [-0.0238, -0.0278,  0.0266],\n",
       "                        [-0.0242,  0.0184,  0.0132]],\n",
       "              \n",
       "                       [[-0.0006,  0.0289, -0.0257],\n",
       "                        [ 0.0251, -0.0217, -0.0149],\n",
       "                        [-0.0093,  0.0158, -0.0181]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0159,  0.0190,  0.0048],\n",
       "                        [-0.0112,  0.0109, -0.0288],\n",
       "                        [ 0.0042, -0.0198, -0.0110]],\n",
       "              \n",
       "                       [[ 0.0249, -0.0276,  0.0237],\n",
       "                        [ 0.0220,  0.0058,  0.0292],\n",
       "                        [-0.0222,  0.0228,  0.0209]],\n",
       "              \n",
       "                       [[ 0.0169,  0.0105,  0.0085],\n",
       "                        [ 0.0094, -0.0211,  0.0066],\n",
       "                        [-0.0280, -0.0224, -0.0263]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0038, -0.0154, -0.0082],\n",
       "                        [-0.0074, -0.0030,  0.0188],\n",
       "                        [-0.0268,  0.0019, -0.0103]],\n",
       "              \n",
       "                       [[ 0.0162, -0.0236, -0.0117],\n",
       "                        [ 0.0035, -0.0031, -0.0156],\n",
       "                        [-0.0214,  0.0028, -0.0201]],\n",
       "              \n",
       "                       [[-0.0279,  0.0016,  0.0001],\n",
       "                        [-0.0252,  0.0273,  0.0121],\n",
       "                        [ 0.0009,  0.0128,  0.0086]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0112, -0.0114,  0.0055],\n",
       "                        [-0.0097, -0.0274,  0.0017],\n",
       "                        [ 0.0183,  0.0059, -0.0021]],\n",
       "              \n",
       "                       [[-0.0288, -0.0221,  0.0196],\n",
       "                        [-0.0260,  0.0100,  0.0034],\n",
       "                        [-0.0275, -0.0254,  0.0213]],\n",
       "              \n",
       "                       [[-0.0238,  0.0077,  0.0040],\n",
       "                        [ 0.0132, -0.0140,  0.0292],\n",
       "                        [-0.0038, -0.0113,  0.0018]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0180,  0.0151,  0.0069],\n",
       "                        [ 0.0029,  0.0251, -0.0135],\n",
       "                        [-0.0260,  0.0067,  0.0234]],\n",
       "              \n",
       "                       [[-0.0048, -0.0128,  0.0034],\n",
       "                        [-0.0146,  0.0097,  0.0290],\n",
       "                        [-0.0175, -0.0002,  0.0148]],\n",
       "              \n",
       "                       [[-0.0118,  0.0116,  0.0146],\n",
       "                        [ 0.0140, -0.0026,  0.0015],\n",
       "                        [ 0.0269,  0.0103, -0.0080]]]])),\n",
       "             ('conv_block4.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block4.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('conv_block4.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block4.1.running_mean',\n",
       "              tensor([-4.2288e-03, -4.7690e-03,  4.7991e-03,  9.6397e-02,  5.3092e-02,\n",
       "                       5.1603e-02, -6.9128e-02,  6.3761e-02,  4.2370e-02,  2.1694e-02,\n",
       "                      -1.4682e-02,  1.2591e-02,  8.9681e-02,  7.4032e-02, -4.5238e-02,\n",
       "                       4.1980e-02,  7.9255e-02,  1.0206e-02, -2.1852e-02, -2.3395e-02,\n",
       "                      -6.4809e-02, -1.3595e-01,  6.6528e-02, -1.9771e-02, -6.9116e-02,\n",
       "                      -3.4604e-02,  5.6455e-02,  2.3960e-02,  9.7380e-02,  5.9282e-02,\n",
       "                       5.9646e-02, -1.1126e-01,  7.3172e-02, -4.9007e-02,  5.2013e-02,\n",
       "                      -2.6372e-02, -3.0854e-02, -3.0691e-04,  3.2781e-02,  1.0839e-01,\n",
       "                      -4.5225e-02,  1.7626e-02,  1.5690e-02,  1.8689e-03,  2.6629e-02,\n",
       "                       3.5580e-02, -2.6670e-02, -1.2481e-02,  5.1039e-02,  9.2375e-03,\n",
       "                       5.0924e-04, -2.4090e-02, -1.5487e-02, -5.4753e-03,  7.4966e-02,\n",
       "                      -8.2959e-03,  7.4606e-02,  1.7629e-02,  3.6557e-02, -1.2023e-01,\n",
       "                       4.7368e-03, -3.8781e-02, -2.9757e-02,  4.4516e-02, -6.7278e-02,\n",
       "                      -4.6174e-02,  4.6471e-02,  1.1775e-02,  2.4241e-02,  1.4521e-02,\n",
       "                      -1.6879e-02, -1.5550e-01,  1.3314e-02,  3.4570e-02, -1.0365e-01,\n",
       "                      -3.5989e-02,  1.1463e-01,  2.3116e-02, -2.9806e-03, -2.0613e-03,\n",
       "                       1.1318e-02, -5.4708e-02, -1.4967e-02,  1.4289e-02,  1.4262e-02,\n",
       "                       1.7835e-02, -1.2322e-02, -5.6895e-02,  5.9823e-02, -1.4704e-03,\n",
       "                      -3.8505e-02, -4.4811e-02, -1.9432e-03, -1.7138e-02, -4.3387e-02,\n",
       "                      -4.5056e-02,  6.7023e-02,  1.2182e-01, -1.0421e-01, -4.3246e-02,\n",
       "                       1.4098e-01,  4.8322e-02, -6.8167e-02, -2.7091e-02,  8.4036e-02,\n",
       "                      -3.8887e-02, -2.4741e-02,  1.9442e-02, -1.0410e-01,  4.5511e-02,\n",
       "                      -7.9710e-02,  5.8523e-02, -4.7093e-02, -7.7306e-02,  5.6410e-02,\n",
       "                       3.8277e-02,  6.5785e-02,  9.3228e-02, -1.7776e-02, -2.8584e-02,\n",
       "                      -1.2628e-02, -1.0538e-01, -7.3245e-02,  3.9352e-02, -1.3511e-01,\n",
       "                      -3.8270e-02,  4.3596e-02, -1.8499e-02,  1.3247e-02,  4.6945e-02,\n",
       "                      -8.1191e-02, -3.1709e-02, -3.8015e-02, -1.0034e-02,  1.1929e-01,\n",
       "                       3.3536e-02, -6.8407e-02, -1.3132e-02,  2.5306e-03, -1.0830e-01,\n",
       "                      -2.6242e-02,  3.4667e-03, -3.5950e-03,  2.7230e-03, -1.2260e-01,\n",
       "                       1.5451e-02, -3.0631e-02,  1.4796e-02, -6.2001e-02, -1.9134e-02,\n",
       "                       2.2640e-02,  5.8891e-03, -4.0527e-02, -2.5713e-02, -1.1031e-02,\n",
       "                      -4.3049e-02,  4.0873e-02, -3.4551e-02,  2.5152e-02, -8.4399e-02,\n",
       "                      -7.9576e-02,  2.5996e-02, -9.5590e-02, -4.7288e-02,  2.3908e-02,\n",
       "                      -9.6060e-02, -3.4457e-02, -6.7826e-02,  2.8358e-02, -2.6967e-02,\n",
       "                      -9.7237e-02, -6.9906e-02, -8.9202e-02, -7.7685e-02, -6.7699e-03,\n",
       "                      -4.5793e-02, -8.1971e-02,  1.4712e-02,  3.6267e-02,  2.2658e-02,\n",
       "                      -8.1478e-02,  1.2547e-02, -2.2185e-02, -2.0563e-02, -1.7864e-02,\n",
       "                      -1.4274e-02, -1.9510e-02, -7.9653e-02, -1.3857e-02,  1.1499e-03,\n",
       "                       1.6843e-02, -2.7144e-02, -2.0248e-02, -5.6584e-02,  7.7192e-03,\n",
       "                      -1.0890e-01, -4.0548e-02, -4.5458e-04,  4.6716e-02,  6.6946e-02,\n",
       "                       3.2899e-02, -4.0644e-03, -2.5740e-02, -4.3166e-02, -2.6922e-02,\n",
       "                       2.9202e-02,  5.4854e-02, -3.6657e-02,  3.3131e-02,  7.1968e-02,\n",
       "                      -5.2553e-02,  8.8187e-02,  3.3995e-02, -2.5573e-02, -7.5712e-02,\n",
       "                       2.6520e-02, -8.1002e-02,  1.5465e-02, -1.0537e-02, -4.6762e-02,\n",
       "                       7.5087e-03,  4.1091e-02,  8.2163e-02, -3.2034e-02,  4.0791e-03,\n",
       "                      -5.9347e-02, -1.0207e-02, -1.2972e-01,  8.4687e-02, -6.8490e-02,\n",
       "                       1.1688e-01,  1.5232e-02,  5.1833e-02, -6.4627e-02,  3.2048e-02,\n",
       "                      -1.7456e-02, -6.2490e-02,  5.8476e-02, -4.2671e-02, -3.8925e-02,\n",
       "                      -7.9981e-02,  8.2144e-02,  6.7486e-02, -3.0149e-02, -2.1444e-02,\n",
       "                      -1.1942e-01, -8.0593e-02,  8.5205e-02, -9.2039e-02, -2.1849e-03,\n",
       "                      -9.5628e-02, -3.5896e-02,  7.6434e-02,  4.9205e-02,  3.3378e-02,\n",
       "                      -4.9907e-02, -3.5128e-02, -4.8075e-02, -2.2074e-03, -2.0442e-02,\n",
       "                       5.0380e-02,  5.5434e-02,  3.5161e-02,  3.6876e-02,  6.7578e-02,\n",
       "                      -8.8137e-02, -7.0287e-02, -1.0273e-01, -3.1119e-02,  7.3093e-02,\n",
       "                      -5.4901e-02,  9.6852e-02,  2.2789e-02,  1.1149e-01,  1.7422e-02,\n",
       "                      -9.8357e-03,  2.9484e-03, -3.8646e-02, -6.6402e-02,  4.0793e-02,\n",
       "                      -5.8934e-02, -1.1275e-02,  4.2738e-02, -2.9738e-02, -4.5308e-02,\n",
       "                       2.7365e-02,  2.3321e-02, -4.0554e-02, -4.0176e-02,  4.6612e-02,\n",
       "                      -2.0410e-03, -7.3653e-03,  2.7188e-02, -1.0675e-02,  4.1760e-02,\n",
       "                      -1.2024e-02,  2.8972e-02, -4.6950e-02,  1.5864e-02, -5.1882e-02,\n",
       "                       6.2552e-02,  7.6103e-02, -2.4320e-02, -1.6159e-04,  1.1290e-03,\n",
       "                       4.1633e-02,  1.0983e-01,  9.9154e-04,  4.5656e-02, -3.7059e-02,\n",
       "                      -4.9943e-02,  8.5299e-02,  7.5551e-02,  2.6808e-02,  6.3121e-02,\n",
       "                      -2.6975e-02,  8.5010e-02,  3.1505e-02,  1.2139e-02,  3.9909e-02,\n",
       "                       7.0970e-03, -4.2038e-02,  5.5810e-02,  5.4746e-02,  4.2074e-02,\n",
       "                      -3.8865e-03,  1.6038e-02,  7.8356e-03, -4.2466e-02, -9.4834e-02,\n",
       "                       1.7891e-03, -1.3150e-02,  5.2716e-02, -2.9274e-02, -3.8281e-02,\n",
       "                      -2.2365e-02,  3.5577e-02,  4.0780e-03, -2.0370e-02, -2.7851e-02,\n",
       "                      -7.8928e-02, -2.9568e-02, -4.7406e-02,  8.3081e-03, -5.8244e-02,\n",
       "                      -1.5570e-02,  6.0561e-02, -1.5854e-02, -1.5203e-02, -7.8004e-03,\n",
       "                      -7.6996e-02, -7.9743e-02, -1.1367e-01,  6.0762e-02, -3.5163e-02,\n",
       "                      -4.6113e-02,  8.4385e-02,  6.5454e-02,  2.6779e-02, -4.8049e-03,\n",
       "                       2.6422e-02, -3.7746e-03, -4.9710e-02,  3.3632e-02, -2.5016e-02,\n",
       "                      -1.0428e-01,  5.1306e-02, -5.2184e-02, -7.8035e-03,  5.4595e-02,\n",
       "                       2.3889e-02,  2.3288e-02, -1.3998e-02, -5.2553e-02,  1.9397e-03,\n",
       "                      -1.1071e-04, -7.3218e-02, -5.4618e-02,  3.5029e-02, -5.4797e-02,\n",
       "                       7.2695e-02,  1.2758e-01, -7.7972e-03,  2.3583e-03,  1.8843e-03,\n",
       "                       1.1484e-01, -9.4338e-02, -1.6766e-04, -1.5420e-03, -5.8435e-02,\n",
       "                       6.6131e-03, -7.7965e-03, -5.2482e-02, -4.0629e-02, -6.4808e-02,\n",
       "                      -2.8267e-02, -4.3435e-02,  4.0265e-02,  7.6298e-02,  7.1572e-02,\n",
       "                      -1.2868e-02, -4.7346e-02, -8.0106e-02, -4.6841e-02, -8.7475e-02,\n",
       "                      -3.4448e-02,  1.4269e-02,  3.5773e-02, -1.0934e-01, -3.9608e-02,\n",
       "                      -4.7908e-02,  4.7501e-02,  7.7852e-03, -3.8841e-02,  5.5564e-02,\n",
       "                       3.9053e-02,  9.7160e-03,  6.5188e-02, -2.9094e-02, -3.1451e-02,\n",
       "                       3.3068e-02,  3.2416e-03, -7.2258e-03,  6.9645e-02, -4.7363e-02,\n",
       "                       3.1757e-02, -1.1720e-02, -5.4186e-02,  3.0515e-02,  7.0739e-03,\n",
       "                       5.0341e-02, -7.2662e-02, -7.6594e-02,  6.7025e-02, -2.6775e-02,\n",
       "                       5.7611e-02,  3.0057e-02,  2.3211e-02,  1.3145e-02, -2.0198e-02,\n",
       "                      -3.7940e-04, -6.9446e-02, -3.9740e-03, -2.8366e-02, -3.6420e-02,\n",
       "                       3.3775e-03, -8.0136e-03,  9.9619e-02,  3.8034e-02,  8.8878e-02,\n",
       "                       4.0058e-02, -5.8290e-02,  2.6476e-02,  3.8429e-02,  5.0951e-02,\n",
       "                      -4.4076e-02,  6.6140e-02,  7.4558e-02,  3.6374e-02,  7.7464e-02,\n",
       "                       1.0542e-04, -5.2705e-02,  1.2849e-01,  1.2032e-03, -6.1865e-02,\n",
       "                       2.9349e-02, -1.1937e-02, -7.4064e-02, -4.2483e-02,  1.4241e-03,\n",
       "                       4.2611e-02, -2.8536e-02, -2.6676e-02, -2.3427e-02, -1.2112e-02,\n",
       "                      -3.3510e-02,  4.2002e-03,  7.4917e-02, -1.4983e-02, -5.0431e-03,\n",
       "                      -4.4470e-03, -3.4043e-02,  8.4878e-02,  6.5803e-02,  3.1570e-02,\n",
       "                       7.2226e-02,  5.0284e-02, -2.6492e-02, -1.3662e-02, -2.4432e-03,\n",
       "                       9.8892e-04,  4.0667e-02, -2.2221e-02,  5.6907e-02, -1.5052e-02,\n",
       "                       3.8968e-02, -3.1896e-03,  1.5906e-02, -7.9368e-03, -6.3441e-04,\n",
       "                      -1.9363e-02, -7.9381e-02,  2.8513e-02, -2.6767e-02,  3.4545e-02,\n",
       "                       4.1924e-02, -2.3526e-02, -9.5552e-02, -2.5875e-02, -7.1294e-02,\n",
       "                       3.2136e-02,  2.2369e-02])),\n",
       "             ('conv_block4.1.running_var',\n",
       "              tensor([0.9303, 0.9296, 0.9457, 0.9422, 0.9446, 0.9312, 0.9382, 0.9383, 0.9398,\n",
       "                      0.9363, 0.9279, 0.9396, 0.9240, 0.9512, 0.9344, 0.9238, 0.9477, 0.9507,\n",
       "                      0.9269, 0.9262, 0.9352, 0.9483, 0.9423, 0.9308, 0.9400, 0.9430, 0.9321,\n",
       "                      0.9386, 0.9630, 0.9561, 0.9361, 0.9576, 0.9410, 0.9588, 0.9473, 0.9484,\n",
       "                      0.9321, 0.9353, 0.9409, 0.9505, 0.9334, 0.9344, 0.9601, 0.9240, 0.9579,\n",
       "                      0.9309, 0.9250, 0.9286, 0.9335, 0.9272, 0.9428, 0.9424, 0.9381, 0.9352,\n",
       "                      0.9340, 0.9456, 0.9462, 0.9907, 0.9250, 0.9474, 0.9291, 0.9320, 0.9389,\n",
       "                      0.9211, 0.9470, 0.9271, 0.9247, 0.9341, 0.9314, 0.9484, 0.9303, 0.9685,\n",
       "                      0.9295, 0.9382, 0.9573, 0.9300, 0.9727, 0.9316, 0.9265, 0.9323, 0.9336,\n",
       "                      0.9339, 0.9361, 0.9337, 0.9317, 0.9323, 0.9449, 0.9215, 0.9352, 0.9258,\n",
       "                      0.9223, 0.9343, 0.9522, 0.9299, 0.9354, 0.9290, 0.9376, 0.9475, 0.9599,\n",
       "                      0.9309, 0.9632, 0.9537, 0.9357, 0.9403, 0.9570, 0.9590, 0.9458, 0.9413,\n",
       "                      0.9350, 0.9279, 0.9351, 0.9403, 0.9515, 0.9467, 0.9219, 0.9402, 0.9359,\n",
       "                      0.9330, 0.9332, 0.9485, 0.9405, 0.9418, 0.9530, 0.9279, 0.9868, 0.9320,\n",
       "                      0.9471, 0.9321, 0.9687, 0.9366, 0.9327, 0.9588, 0.9418, 0.9260, 0.9571,\n",
       "                      0.9328, 0.9298, 0.9870, 0.9271, 0.9497, 0.9287, 0.9362, 0.9505, 0.9346,\n",
       "                      0.9437, 0.9424, 0.9248, 0.9222, 0.9371, 0.9417, 0.9303, 0.9375, 0.9331,\n",
       "                      0.9286, 0.9345, 0.9359, 0.9343, 0.9329, 0.9231, 0.9478, 0.9662, 0.9390,\n",
       "                      0.9640, 0.9389, 0.9298, 0.9322, 0.9478, 0.9411, 0.9354, 0.9307, 0.9348,\n",
       "                      0.9403, 0.9652, 0.9297, 0.9343, 0.9533, 0.9433, 0.9350, 0.9460, 0.9393,\n",
       "                      0.9370, 0.9380, 0.9322, 0.9295, 0.9369, 0.9266, 0.9282, 0.9388, 0.9322,\n",
       "                      0.9318, 0.9304, 0.9273, 0.9518, 0.9447, 0.9407, 0.9409, 0.9410, 0.9283,\n",
       "                      0.9339, 0.9564, 0.9505, 0.9546, 0.9457, 0.9344, 0.9269, 0.9293, 0.9268,\n",
       "                      0.9404, 0.9335, 0.9386, 0.9526, 0.9524, 0.9315, 0.9256, 0.9521, 0.9304,\n",
       "                      0.9293, 0.9254, 0.9372, 0.9290, 0.9393, 0.9500, 0.9396, 0.9367, 0.9451,\n",
       "                      0.9297, 0.9255, 0.9588, 0.9388, 0.9512, 0.9579, 0.9387, 0.9482, 0.9324,\n",
       "                      0.9382, 0.9241, 0.9749, 0.9260, 0.9365, 0.9696, 0.9375, 0.9519, 0.9593,\n",
       "                      0.9339, 0.9395, 0.9457, 0.9338, 0.9425, 0.9575, 0.9250, 0.9423, 0.9363,\n",
       "                      0.9480, 0.9365, 0.9228, 0.9277, 0.9321, 0.9341, 0.9310, 0.9487, 0.9533,\n",
       "                      0.9272, 0.9479, 0.9309, 0.9395, 0.9646, 0.9678, 0.9466, 0.9299, 0.9527,\n",
       "                      0.9617, 0.9418, 0.9311, 0.9431, 0.9338, 0.9299, 0.9299, 0.9416, 0.9446,\n",
       "                      0.9268, 0.9353, 0.9413, 0.9324, 0.9372, 0.9683, 0.9405, 0.9430, 0.9349,\n",
       "                      0.9316, 0.9344, 0.9298, 0.9312, 0.9263, 0.9296, 0.9369, 0.9602, 0.9307,\n",
       "                      0.9311, 0.9257, 0.9502, 0.9347, 0.9537, 0.9444, 0.9319, 0.9495, 0.9276,\n",
       "                      0.9526, 0.9226, 0.9363, 0.9217, 0.9521, 0.9495, 0.9420, 0.9417, 0.9340,\n",
       "                      0.9279, 0.9618, 0.9336, 0.9516, 0.9328, 0.9259, 0.9347, 0.9463, 0.9587,\n",
       "                      0.9348, 0.9472, 0.9260, 0.9341, 0.9286, 0.9502, 0.9529, 0.9346, 0.9373,\n",
       "                      0.9339, 0.9291, 0.9347, 0.9369, 0.9399, 0.9287, 0.9382, 0.9386, 0.9340,\n",
       "                      0.9291, 0.9372, 0.9506, 0.9309, 0.9354, 0.9313, 0.9221, 0.9217, 0.9413,\n",
       "                      0.9370, 0.9422, 0.9464, 0.9282, 0.9319, 0.9456, 0.9426, 0.9391, 0.9387,\n",
       "                      0.9296, 0.9330, 0.9294, 0.9543, 0.9366, 0.9773, 0.9461, 0.9406, 0.9283,\n",
       "                      0.9376, 0.9313, 0.9331, 0.9269, 0.9427, 0.9267, 0.9476, 0.9733, 0.9285,\n",
       "                      0.9265, 0.9364, 0.9907, 0.9368, 0.9265, 0.9262, 0.9356, 0.9521, 0.9463,\n",
       "                      0.9207, 0.9395, 0.9357, 0.9291, 0.9440, 0.9414, 0.9229, 0.9373, 0.9349,\n",
       "                      0.9254, 0.9368, 0.9359, 0.9649, 0.9329, 0.9278, 0.9459, 0.9598, 0.9377,\n",
       "                      0.9464, 0.9290, 0.9347, 0.9344, 0.9251, 0.9375, 0.9248, 0.9527, 0.9400,\n",
       "                      0.9314, 0.9299, 0.9480, 0.9376, 0.9283, 0.9339, 0.9440, 0.9623, 0.9418,\n",
       "                      0.9401, 0.9326, 0.9286, 0.9426, 0.9346, 0.9329, 0.9295, 0.9366, 0.9464,\n",
       "                      0.9375, 0.9316, 0.9293, 0.9478, 0.9305, 0.9265, 0.9318, 0.9282, 0.9358,\n",
       "                      0.9335, 0.9385, 1.0081, 0.9344, 0.9241, 0.9550, 0.9692, 0.9395, 0.9251,\n",
       "                      0.9355, 0.9271, 0.9296, 0.9331, 0.9448, 0.9307, 0.9325, 0.9838, 0.9402,\n",
       "                      0.9451, 0.9417, 0.9362, 0.9765, 0.9289, 0.9381, 0.9446, 0.9262, 0.9449,\n",
       "                      0.9305, 0.9356, 0.9390, 0.9265, 0.9249, 0.9400, 0.9282, 0.9318, 0.9194,\n",
       "                      0.9290, 0.9484, 0.9195, 0.9315, 0.9577, 0.9463, 0.9320, 0.9295, 0.9804,\n",
       "                      0.9389, 0.9351, 0.9395, 0.9354, 0.9652, 0.9299, 0.9286, 0.9745, 0.9385,\n",
       "                      0.9402, 0.9356, 0.9295, 0.9308, 0.9257, 0.9339, 0.9475, 0.9417, 0.9363,\n",
       "                      0.9307, 0.9469, 0.9315, 0.9474, 0.9264, 0.9475, 0.9279, 0.9370])),\n",
       "             ('conv_block4.1.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block4.3.weight',\n",
       "              tensor([[[[ 3.2462e-03,  2.4163e-02,  1.4182e-02],\n",
       "                        [ 2.4232e-02,  8.3902e-03,  2.0048e-02],\n",
       "                        [-1.0011e-02,  2.2811e-02,  1.5998e-02]],\n",
       "              \n",
       "                       [[ 4.6347e-03,  1.8403e-03,  1.2474e-02],\n",
       "                        [ 2.5687e-04, -8.3032e-03,  3.8114e-03],\n",
       "                        [-1.8760e-02, -1.1432e-02,  2.5204e-02]],\n",
       "              \n",
       "                       [[-2.2196e-02, -1.3981e-02, -1.5023e-02],\n",
       "                        [ 6.2935e-03, -1.4327e-02,  1.3185e-02],\n",
       "                        [-5.0610e-03, -1.7278e-02,  2.3544e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.1413e-03, -8.8067e-04, -9.8958e-03],\n",
       "                        [ 1.8938e-02,  1.6536e-02, -1.1947e-02],\n",
       "                        [-2.1851e-02,  2.0981e-02,  2.8600e-04]],\n",
       "              \n",
       "                       [[-7.9727e-03,  1.2532e-02, -6.5621e-03],\n",
       "                        [ 6.1129e-03,  2.4518e-02, -1.5282e-02],\n",
       "                        [-2.2818e-02, -2.3746e-02,  6.6057e-03]],\n",
       "              \n",
       "                       [[ 1.2708e-02, -1.2979e-02,  1.8097e-02],\n",
       "                        [ 7.0159e-03, -1.0831e-02, -9.8020e-03],\n",
       "                        [-2.0847e-02,  9.9250e-04, -2.2665e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0222e-02,  2.2171e-02, -1.2926e-02],\n",
       "                        [ 9.4616e-03,  5.5542e-03,  3.9473e-03],\n",
       "                        [-2.2859e-02, -4.0360e-03,  2.5050e-02]],\n",
       "              \n",
       "                       [[-1.6316e-02,  2.5463e-02,  3.1731e-03],\n",
       "                        [-7.7566e-03, -2.1550e-02, -1.1094e-03],\n",
       "                        [ 1.1832e-02,  2.6773e-03, -7.3006e-04]],\n",
       "              \n",
       "                       [[ 1.9014e-03, -1.0772e-03, -4.8065e-03],\n",
       "                        [-2.4816e-03,  8.0980e-03, -4.0801e-04],\n",
       "                        [ 6.2005e-03,  2.1614e-02,  3.2854e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.7746e-03, -1.7390e-02, -1.5703e-02],\n",
       "                        [ 2.4404e-03, -1.9347e-02,  2.0836e-02],\n",
       "                        [-1.0819e-02,  1.4709e-02,  1.9389e-02]],\n",
       "              \n",
       "                       [[-1.8896e-04,  4.6012e-03,  1.0555e-02],\n",
       "                        [ 2.0015e-02,  2.3892e-02, -1.3290e-02],\n",
       "                        [ 1.0613e-02, -1.6225e-02,  1.7415e-02]],\n",
       "              \n",
       "                       [[-2.1806e-03,  1.7026e-03,  1.9058e-02],\n",
       "                        [ 1.9648e-02, -2.2265e-02,  1.8060e-02],\n",
       "                        [-1.4889e-02,  1.9699e-02, -3.1325e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0383e-02,  1.4612e-02,  2.9694e-03],\n",
       "                        [-1.5653e-02, -2.1122e-02, -1.5773e-02],\n",
       "                        [-2.4544e-02, -1.1979e-02, -2.4346e-02]],\n",
       "              \n",
       "                       [[ 1.2497e-02, -4.0129e-03,  1.8847e-02],\n",
       "                        [-5.3953e-03,  2.1302e-02,  1.8731e-02],\n",
       "                        [ 5.0421e-03,  1.9164e-02,  2.1313e-03]],\n",
       "              \n",
       "                       [[-2.2929e-02, -1.2534e-02, -2.3778e-02],\n",
       "                        [-1.9579e-02,  9.2182e-03,  4.2240e-03],\n",
       "                        [ 2.4370e-02,  2.4666e-02,  1.7125e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2090e-02, -2.2636e-02, -1.2987e-02],\n",
       "                        [ 1.9642e-02,  7.4934e-03, -8.5354e-03],\n",
       "                        [-2.6804e-03, -2.2091e-02,  2.3279e-02]],\n",
       "              \n",
       "                       [[ 2.3029e-02,  9.4661e-03,  1.2355e-02],\n",
       "                        [-1.7096e-02, -7.2750e-03,  2.1147e-02],\n",
       "                        [ 1.0612e-02,  2.0259e-02, -8.9307e-03]],\n",
       "              \n",
       "                       [[ 1.7593e-02,  5.3668e-03,  2.3504e-02],\n",
       "                        [-2.6204e-03,  2.6697e-03, -1.0992e-02],\n",
       "                        [ 1.1865e-02, -2.1418e-02, -9.1411e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.5096e-02,  1.3281e-03, -6.5026e-03],\n",
       "                        [-1.5050e-02, -8.7327e-03, -2.1297e-02],\n",
       "                        [-1.0468e-02, -1.4406e-02,  1.0200e-02]],\n",
       "              \n",
       "                       [[ 5.6270e-03, -2.3861e-02, -9.9517e-03],\n",
       "                        [-9.8632e-04,  1.3036e-02, -1.4210e-02],\n",
       "                        [ 5.3133e-03,  2.1492e-02, -1.8254e-02]],\n",
       "              \n",
       "                       [[-1.2573e-02, -9.8462e-03, -1.2600e-02],\n",
       "                        [ 2.1515e-02, -2.2795e-02, -1.7700e-03],\n",
       "                        [ 1.7320e-02, -1.9297e-02,  8.6982e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.8121e-03, -2.4003e-02, -4.5764e-03],\n",
       "                        [ 1.1518e-02,  1.9107e-02,  1.6956e-02],\n",
       "                        [ 5.7425e-03,  6.8331e-03,  4.4694e-03]],\n",
       "              \n",
       "                       [[-2.1622e-02,  1.3684e-02,  2.2977e-02],\n",
       "                        [ 6.6262e-03, -1.6180e-02,  2.3557e-02],\n",
       "                        [-2.2152e-03,  1.7039e-03, -5.9182e-03]],\n",
       "              \n",
       "                       [[ 2.3160e-02, -1.2524e-03,  2.5154e-02],\n",
       "                        [ 2.4452e-02,  8.1636e-03, -2.4850e-02],\n",
       "                        [-1.6885e-02, -2.1072e-02, -1.0673e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3706e-02,  1.0014e-02, -3.8133e-03],\n",
       "                        [-1.0895e-02, -1.3174e-02,  2.5058e-02],\n",
       "                        [-2.0612e-02, -1.4334e-03, -1.5401e-02]],\n",
       "              \n",
       "                       [[ 1.8162e-02, -1.8017e-02,  2.3999e-02],\n",
       "                        [ 2.2321e-02, -1.3487e-02,  1.5135e-02],\n",
       "                        [ 3.9088e-03, -6.9469e-03, -1.2755e-02]],\n",
       "              \n",
       "                       [[-2.2790e-02,  2.2376e-02,  1.4513e-02],\n",
       "                        [-1.9844e-03,  3.6220e-04,  1.1619e-02],\n",
       "                        [ 8.8695e-03,  1.6262e-02, -9.7354e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3236e-03,  5.2518e-03,  4.4584e-03],\n",
       "                        [ 1.4926e-02, -1.5667e-02, -7.0010e-03],\n",
       "                        [ 1.8695e-02,  2.1235e-02, -3.2299e-03]],\n",
       "              \n",
       "                       [[-1.0957e-02,  1.4209e-02,  2.9776e-03],\n",
       "                        [-1.8387e-02,  2.0214e-02, -1.5488e-02],\n",
       "                        [ 1.1661e-02,  5.3792e-04, -2.3379e-02]],\n",
       "              \n",
       "                       [[-2.2117e-02, -1.8560e-02,  1.2159e-02],\n",
       "                        [ 1.7119e-02,  1.6959e-02, -5.1247e-03],\n",
       "                        [ 2.1880e-02,  1.3480e-02,  3.7176e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0507e-02, -4.8126e-03,  1.9990e-02],\n",
       "                        [-1.1498e-02,  1.2612e-02,  1.5469e-02],\n",
       "                        [ 2.0750e-02, -1.7729e-02,  1.8257e-02]],\n",
       "              \n",
       "                       [[ 1.0769e-02,  2.4430e-02,  9.2803e-04],\n",
       "                        [ 1.4152e-02, -1.7414e-02, -2.7616e-03],\n",
       "                        [ 6.4677e-03,  8.4170e-03, -6.9110e-03]],\n",
       "              \n",
       "                       [[-1.0611e-02,  2.3899e-02, -2.4061e-02],\n",
       "                        [ 5.8722e-03, -1.2908e-02, -1.9558e-02],\n",
       "                        [-4.2782e-04, -1.2732e-02, -1.6425e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0130e-02,  1.0112e-02, -1.4839e-02],\n",
       "                        [ 2.1602e-02, -1.4945e-02, -1.1437e-02],\n",
       "                        [ 3.4067e-03, -1.1948e-02, -2.0633e-02]],\n",
       "              \n",
       "                       [[ 6.6067e-04, -3.6396e-03,  1.7530e-02],\n",
       "                        [ 1.5211e-02,  5.9099e-03,  6.7624e-03],\n",
       "                        [ 1.7795e-02, -3.5610e-03,  1.8079e-03]],\n",
       "              \n",
       "                       [[-5.4722e-03,  1.8069e-02,  5.4704e-03],\n",
       "                        [-1.2041e-02, -3.3231e-03, -1.7182e-02],\n",
       "                        [ 2.2352e-02, -2.9757e-03,  6.5518e-05]]]])),\n",
       "             ('conv_block4.3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block4.4.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('conv_block4.4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block4.4.running_mean',\n",
       "              tensor([ 7.0643e-03,  5.0142e-02,  8.1358e-03, -1.5867e-02,  1.8882e-02,\n",
       "                       2.0534e-02,  8.1213e-02, -8.8309e-03, -1.9249e-02,  5.4067e-03,\n",
       "                       3.9956e-02, -1.2223e-02, -5.6019e-02,  2.2063e-02,  2.8405e-02,\n",
       "                       4.4989e-03, -1.2045e-03,  1.1300e-02, -4.3476e-04, -2.4519e-02,\n",
       "                       3.5028e-02,  8.6995e-03, -2.6502e-02, -1.4314e-02,  1.3899e-04,\n",
       "                      -1.4167e-02, -4.3673e-03,  2.3569e-02,  6.6236e-02, -5.0404e-02,\n",
       "                      -6.5884e-03, -3.6191e-03, -3.5298e-02, -2.5496e-02,  3.3686e-02,\n",
       "                      -2.6973e-02, -8.1873e-03,  7.8652e-03, -2.3775e-02, -2.2191e-02,\n",
       "                      -1.1705e-02, -3.4498e-02, -3.8258e-02,  1.5485e-02,  6.7482e-03,\n",
       "                      -1.4063e-02,  2.9503e-02,  2.3027e-02, -1.3652e-02,  2.3333e-02,\n",
       "                       7.9328e-03,  6.0836e-03, -2.7458e-02,  6.3389e-02, -4.7841e-03,\n",
       "                      -4.3017e-02,  2.2550e-02,  1.7139e-02,  2.8143e-03,  5.9792e-03,\n",
       "                      -1.8366e-02,  1.5687e-03,  4.4141e-02,  3.8420e-02, -3.9402e-03,\n",
       "                       4.5899e-02,  2.0093e-02, -4.4918e-02,  4.9211e-02, -4.4740e-02,\n",
       "                       6.0705e-03, -1.9122e-02,  3.3202e-02, -1.9198e-02,  3.6036e-02,\n",
       "                       2.4916e-02,  3.0946e-02,  2.3339e-02, -1.0520e-02, -4.5959e-03,\n",
       "                       7.9093e-02, -1.0510e-02,  5.0037e-02, -3.4576e-02, -5.9545e-02,\n",
       "                       1.5238e-02,  3.5154e-03, -5.5182e-04,  1.6655e-03, -3.5740e-02,\n",
       "                       1.7481e-03, -1.1256e-02, -2.8778e-02, -5.8158e-03,  2.7058e-02,\n",
       "                      -3.5691e-02,  1.8058e-02,  1.3328e-02, -5.2513e-03, -4.8527e-03,\n",
       "                       3.5426e-02,  5.2094e-02, -4.4327e-02, -1.3274e-02,  3.7999e-04,\n",
       "                      -2.4541e-02,  2.4169e-02, -7.3479e-03, -8.8405e-03,  2.5252e-02,\n",
       "                      -7.3009e-03,  1.9176e-02,  5.2728e-02, -4.0816e-02,  3.2345e-02,\n",
       "                       4.4630e-02, -1.2809e-02,  3.7276e-02,  2.2923e-02,  2.0245e-02,\n",
       "                       2.7978e-02, -1.5689e-02,  1.7456e-02, -2.1700e-02, -2.8626e-02,\n",
       "                      -2.4025e-02,  5.0653e-03,  9.9848e-03,  2.1089e-02,  2.6189e-02,\n",
       "                      -1.9302e-02,  2.0991e-02, -1.5961e-02,  2.2637e-02,  4.8902e-02,\n",
       "                      -7.0370e-02, -9.1916e-03, -2.6522e-02,  3.8179e-02,  7.5938e-02,\n",
       "                       1.3133e-02,  2.9446e-02, -1.1320e-02,  6.5323e-03, -1.0244e-02,\n",
       "                      -4.6202e-03,  4.4348e-02, -7.9829e-03, -6.3582e-02,  3.2692e-03,\n",
       "                      -1.0670e-02, -4.3456e-02,  4.6976e-02, -2.1101e-02, -3.3768e-02,\n",
       "                       4.1759e-02,  1.0546e-02,  1.1983e-02, -3.2205e-02, -5.5519e-03,\n",
       "                       5.1804e-03, -4.7320e-02,  3.6658e-02, -1.1913e-02, -6.0745e-03,\n",
       "                       3.9770e-02,  2.2542e-02,  2.4075e-02,  1.8111e-02,  2.4538e-02,\n",
       "                      -3.4076e-02,  4.3605e-02, -1.2926e-02,  9.7477e-03,  2.7036e-02,\n",
       "                       8.5426e-03,  4.7798e-02,  3.4477e-02,  9.2118e-03, -6.6486e-03,\n",
       "                      -8.6466e-02,  8.6877e-03,  1.6036e-02,  3.7420e-03,  4.8077e-02,\n",
       "                      -1.7953e-02, -5.4426e-03,  3.7961e-02, -2.0087e-02, -3.3880e-03,\n",
       "                       8.0601e-03, -1.5857e-02, -1.1853e-02, -1.0971e-02,  7.8262e-03,\n",
       "                      -3.9200e-02,  1.2079e-02, -4.9560e-02, -3.3665e-02,  5.4909e-03,\n",
       "                      -1.5407e-02,  6.1140e-02,  1.4694e-02, -1.6117e-02,  5.9685e-04,\n",
       "                      -5.7819e-03, -1.2735e-02,  2.0107e-02, -3.9022e-02, -2.6985e-02,\n",
       "                      -2.9809e-02, -1.1290e-02,  2.9347e-02,  6.0046e-02,  4.2868e-02,\n",
       "                       4.2857e-02,  2.9134e-02,  1.8845e-02, -8.5165e-03,  1.0330e-02,\n",
       "                       1.5397e-02,  4.8123e-02, -4.6324e-02, -7.5313e-03,  2.6139e-02,\n",
       "                      -4.2587e-03, -1.0916e-03, -3.1704e-02, -6.4585e-03, -1.1091e-02,\n",
       "                       5.2770e-02, -4.7869e-02,  2.8598e-02, -3.9399e-02, -1.4578e-02,\n",
       "                      -1.9675e-02, -1.5882e-05,  3.9282e-02,  2.1281e-02, -2.1942e-02,\n",
       "                       7.3118e-02, -1.5056e-02,  2.0142e-03,  3.1511e-02, -2.4118e-02,\n",
       "                      -2.6481e-02, -1.8949e-02, -2.9824e-02,  3.3716e-04, -1.5204e-02,\n",
       "                      -4.2880e-02, -5.6167e-03,  3.0003e-02,  5.6213e-04, -1.0309e-02,\n",
       "                       3.5886e-02,  3.5498e-02,  3.2353e-04,  3.0745e-02,  8.1913e-03,\n",
       "                       1.7413e-02, -3.4492e-02,  4.9908e-02, -3.5993e-02,  2.3660e-02,\n",
       "                       1.2449e-02, -4.2475e-02, -9.0604e-03,  5.0193e-05, -6.3834e-02,\n",
       "                      -2.1533e-03, -5.5306e-03,  4.1408e-02,  1.1652e-02,  3.1093e-02,\n",
       "                       1.6189e-02,  1.0736e-02,  2.9236e-02,  2.5465e-02, -2.9014e-02,\n",
       "                      -1.3219e-03, -2.6945e-03, -2.2456e-02, -1.7532e-03, -8.1228e-02,\n",
       "                      -3.7989e-02,  2.1236e-02, -4.4424e-02, -3.3852e-03,  2.8883e-02,\n",
       "                      -3.0768e-02, -1.2519e-02, -3.4565e-02,  2.1228e-02, -1.5054e-02,\n",
       "                       4.9448e-02,  2.5574e-02,  6.3431e-02, -1.7645e-02,  4.6518e-02,\n",
       "                       6.3221e-03, -1.0688e-02, -4.0235e-02, -1.0067e-02, -5.0446e-03,\n",
       "                      -9.7232e-03,  2.2296e-02,  3.5804e-02, -1.6522e-02, -1.0461e-02,\n",
       "                       2.3715e-02,  6.5339e-02,  1.1898e-02, -2.7259e-03,  1.7608e-02,\n",
       "                       8.2560e-03,  2.5463e-02,  4.5449e-02, -1.5630e-02, -3.2826e-03,\n",
       "                      -8.3298e-03,  3.3615e-04, -5.5961e-03,  1.9578e-03, -6.8091e-04,\n",
       "                      -9.6203e-03, -1.9227e-02,  1.1463e-02, -1.4951e-02, -2.5164e-02,\n",
       "                       1.5999e-02, -1.4649e-02, -3.4586e-02,  4.5038e-03, -4.2173e-02,\n",
       "                       7.8489e-03,  1.4254e-02, -2.4891e-02,  1.0644e-02,  4.9233e-03,\n",
       "                      -3.5464e-02, -5.0820e-02, -9.1903e-03,  1.0842e-02,  1.5963e-03,\n",
       "                       1.9138e-02, -9.0438e-03, -2.2065e-02,  1.1408e-02,  2.6602e-02,\n",
       "                       1.7193e-02,  3.6498e-03, -1.2740e-02, -3.2644e-02, -1.6200e-02,\n",
       "                       2.1053e-02,  1.2351e-03,  6.9869e-04, -3.3802e-02, -2.9055e-02,\n",
       "                      -3.3523e-03,  3.9223e-02,  4.3908e-02,  6.0128e-02,  2.1713e-02,\n",
       "                      -9.2959e-02, -5.6547e-02,  2.5608e-02,  1.0358e-02, -1.7278e-02,\n",
       "                      -9.4864e-03, -2.5635e-03,  2.7818e-02, -3.4723e-03, -3.3006e-02,\n",
       "                       2.5296e-02, -4.5792e-03,  1.1629e-02,  1.9093e-02, -3.0455e-02,\n",
       "                       2.8208e-02, -5.1089e-02,  4.7024e-02,  4.4948e-02,  3.4343e-02,\n",
       "                      -1.2706e-03, -5.0869e-02,  1.3693e-02,  1.1576e-02,  1.0311e-03,\n",
       "                      -2.0194e-02,  4.2282e-02, -3.1813e-03,  2.4794e-02, -5.2396e-02,\n",
       "                      -4.8796e-02,  2.8061e-02, -2.5807e-02,  2.1041e-02, -7.0884e-03,\n",
       "                      -4.9799e-02,  3.1115e-02,  2.5117e-02, -3.6119e-02, -2.1566e-02,\n",
       "                      -9.8408e-03, -1.3317e-02,  1.7825e-02, -2.2877e-02, -1.3133e-02,\n",
       "                       8.2194e-03,  1.0805e-02, -1.2120e-02,  1.2113e-02,  1.7898e-02,\n",
       "                       2.1486e-03,  5.9232e-04, -1.0844e-02, -1.8310e-02, -7.3198e-02,\n",
       "                      -3.5169e-05,  4.5639e-02, -2.8998e-03,  1.7733e-02, -1.1175e-02,\n",
       "                       1.1339e-03, -2.8461e-02,  9.0770e-02,  3.0625e-02,  4.5482e-02,\n",
       "                      -1.0153e-02, -4.9395e-03, -2.0640e-02, -8.3517e-03, -1.8294e-02,\n",
       "                       3.8982e-02,  1.8473e-03, -1.7708e-02, -4.5766e-02,  7.8800e-03,\n",
       "                       1.9541e-02,  3.9960e-02,  6.2312e-03, -1.1492e-02,  6.3325e-03,\n",
       "                       4.1275e-03,  3.5820e-02, -2.0015e-02,  4.0938e-03, -4.1884e-02,\n",
       "                       1.9409e-02, -4.0677e-02, -3.8957e-02,  5.4382e-02, -7.4463e-03,\n",
       "                       9.7935e-03,  2.1039e-02, -5.8014e-02, -3.1648e-02, -6.0107e-03,\n",
       "                      -1.6750e-03,  3.9108e-02, -2.0897e-02, -2.0134e-02, -1.5299e-02,\n",
       "                      -1.1301e-02, -1.9716e-02, -1.2869e-02, -4.2255e-02,  2.9423e-02,\n",
       "                       1.3269e-03,  5.1661e-02, -2.4233e-02, -3.3754e-02, -1.6789e-02,\n",
       "                      -1.4148e-02,  1.8335e-02, -2.8305e-02, -3.6317e-03, -3.6781e-02,\n",
       "                      -8.9012e-03, -4.3702e-03,  9.6088e-03,  1.6561e-02,  2.0825e-02,\n",
       "                      -2.8932e-02,  2.5585e-03, -1.0047e-02,  5.5589e-03,  3.0835e-02,\n",
       "                       4.2879e-02, -6.6470e-03, -6.9553e-03,  1.9250e-02,  1.2590e-02,\n",
       "                       1.4467e-02, -3.0961e-02, -5.0642e-02,  2.5395e-02, -1.6936e-02,\n",
       "                      -4.1358e-03, -2.6310e-02, -3.2532e-02, -5.0671e-03, -4.4227e-03,\n",
       "                       3.6458e-02, -1.8504e-02, -7.5031e-03, -5.1241e-02, -5.1645e-03,\n",
       "                       3.3097e-02,  2.0196e-02])),\n",
       "             ('conv_block4.4.running_var',\n",
       "              tensor([0.9293, 0.9263, 0.9215, 0.9244, 0.9276, 0.9206, 0.9397, 0.9247, 0.9290,\n",
       "                      0.9248, 0.9299, 0.9240, 0.9245, 0.9184, 0.9229, 0.9341, 0.9264, 0.9228,\n",
       "                      0.9247, 0.9288, 0.9340, 0.9308, 0.9233, 0.9324, 0.9270, 0.9272, 0.9279,\n",
       "                      0.9282, 0.9423, 0.9333, 0.9200, 0.9256, 0.9224, 0.9217, 0.9248, 0.9289,\n",
       "                      0.9263, 0.9329, 0.9232, 0.9247, 0.9200, 0.9307, 0.9317, 0.9259, 0.9272,\n",
       "                      0.9438, 0.9361, 0.9311, 0.9272, 0.9417, 0.9217, 0.9214, 0.9280, 0.9297,\n",
       "                      0.9199, 0.9247, 0.9211, 0.9301, 0.9243, 0.9226, 0.9218, 0.9364, 0.9430,\n",
       "                      0.9347, 0.9252, 0.9317, 0.9270, 0.9322, 0.9283, 0.9248, 0.9276, 0.9290,\n",
       "                      0.9197, 0.9309, 0.9292, 0.9238, 0.9245, 0.9222, 0.9310, 0.9401, 0.9396,\n",
       "                      0.9208, 0.9272, 0.9353, 0.9287, 0.9381, 0.9389, 0.9227, 0.9301, 0.9200,\n",
       "                      0.9283, 0.9284, 0.9319, 0.9274, 0.9236, 0.9357, 0.9257, 0.9367, 0.9257,\n",
       "                      0.9212, 0.9219, 0.9369, 0.9310, 0.9183, 0.9225, 0.9285, 0.9176, 0.9268,\n",
       "                      0.9207, 0.9307, 0.9273, 0.9211, 0.9246, 0.9209, 0.9390, 0.9263, 0.9237,\n",
       "                      0.9296, 0.9343, 0.9251, 0.9266, 0.9213, 0.9233, 0.9217, 0.9346, 0.9266,\n",
       "                      0.9255, 0.9307, 0.9221, 0.9382, 0.9266, 0.9328, 0.9260, 0.9206, 0.9456,\n",
       "                      0.9267, 0.9188, 0.9269, 0.9208, 0.9488, 0.9298, 0.9355, 0.9360, 0.9263,\n",
       "                      0.9229, 0.9227, 0.9215, 0.9229, 0.9268, 0.9269, 0.9249, 0.9330, 0.9299,\n",
       "                      0.9421, 0.9233, 0.9240, 0.9293, 0.9300, 0.9364, 0.9252, 0.9273, 0.9244,\n",
       "                      0.9333, 0.9254, 0.9259, 0.9226, 0.9441, 0.9263, 0.9236, 0.9284, 0.9292,\n",
       "                      0.9206, 0.9390, 0.9162, 0.9279, 0.9235, 0.9257, 0.9296, 0.9259, 0.9188,\n",
       "                      0.9488, 0.9319, 0.9282, 0.9305, 0.9312, 0.9249, 0.9320, 0.9244, 0.9218,\n",
       "                      0.9221, 0.9335, 0.9300, 0.9211, 0.9329, 0.9285, 0.9378, 0.9273, 0.9261,\n",
       "                      0.9275, 0.9298, 0.9235, 0.9321, 0.9337, 0.9252, 0.9286, 0.9209, 0.9205,\n",
       "                      0.9259, 0.9267, 0.9249, 0.9302, 0.9352, 0.9216, 0.9333, 0.9348, 0.9319,\n",
       "                      0.9282, 0.9371, 0.9415, 0.9374, 0.9246, 0.9386, 0.9254, 0.9314, 0.9201,\n",
       "                      0.9259, 0.9304, 0.9216, 0.9176, 0.9232, 0.9300, 0.9312, 0.9230, 0.9248,\n",
       "                      0.9381, 0.9201, 0.9268, 0.9254, 0.9317, 0.9211, 0.9475, 0.9257, 0.9297,\n",
       "                      0.9276, 0.9363, 0.9247, 0.9288, 0.9289, 0.9245, 0.9228, 0.9258, 0.9307,\n",
       "                      0.9271, 0.9203, 0.9249, 0.9246, 0.9270, 0.9239, 0.9272, 0.9248, 0.9276,\n",
       "                      0.9314, 0.9261, 0.9263, 0.9204, 0.9495, 0.9215, 0.9310, 0.9247, 0.9303,\n",
       "                      0.9252, 0.9244, 0.9292, 0.9260, 0.9368, 0.9236, 0.9397, 0.9396, 0.9199,\n",
       "                      0.9312, 0.9332, 0.9243, 0.9256, 0.9278, 0.9496, 0.9398, 0.9294, 0.9257,\n",
       "                      0.9282, 0.9219, 0.9219, 0.9293, 0.9239, 0.9235, 0.9228, 0.9278, 0.9292,\n",
       "                      0.9247, 0.9289, 0.9223, 0.9222, 0.9268, 0.9260, 0.9271, 0.9366, 0.9222,\n",
       "                      0.9259, 0.9249, 0.9199, 0.9239, 0.9228, 0.9531, 0.9204, 0.9277, 0.9266,\n",
       "                      0.9226, 0.9243, 0.9268, 0.9208, 0.9237, 0.9260, 0.9236, 0.9204, 0.9234,\n",
       "                      0.9447, 0.9316, 0.9229, 0.9220, 0.9256, 0.9293, 0.9208, 0.9332, 0.9200,\n",
       "                      0.9325, 0.9303, 0.9422, 0.9306, 0.9233, 0.9448, 0.9340, 0.9220, 0.9273,\n",
       "                      0.9222, 0.9275, 0.9217, 0.9341, 0.9291, 0.9416, 0.9346, 0.9258, 0.9308,\n",
       "                      0.9312, 0.9246, 0.9253, 0.9223, 0.9266, 0.9264, 0.9265, 0.9224, 0.9286,\n",
       "                      0.9220, 0.9246, 0.9295, 0.9244, 0.9207, 0.9387, 0.9326, 0.9232, 0.9250,\n",
       "                      0.9253, 0.9225, 0.9253, 0.9244, 0.9199, 0.9397, 0.9347, 0.9294, 0.9283,\n",
       "                      0.9235, 0.9230, 0.9277, 0.9456, 0.9230, 0.9213, 0.9296, 0.9284, 0.9324,\n",
       "                      0.9210, 0.9288, 0.9417, 0.9227, 0.9301, 0.9266, 0.9264, 0.9247, 0.9231,\n",
       "                      0.9242, 0.9273, 0.9401, 0.9313, 0.9383, 0.9292, 0.9307, 0.9343, 0.9229,\n",
       "                      0.9258, 0.9301, 0.9295, 0.9290, 0.9271, 0.9267, 0.9275, 0.9467, 0.9358,\n",
       "                      0.9289, 0.9403, 0.9213, 0.9205, 0.9181, 0.9256, 0.9234, 0.9418, 0.9307,\n",
       "                      0.9357, 0.9208, 0.9388, 0.9372, 0.9526, 0.9255, 0.9252, 0.9232, 0.9263,\n",
       "                      0.9467, 0.9335, 0.9289, 0.9287, 0.9180, 0.9244, 0.9339, 0.9270, 0.9276,\n",
       "                      0.9289, 0.9301, 0.9305, 0.9227, 0.9228, 0.9473, 0.9308, 0.9385, 0.9259,\n",
       "                      0.9213, 0.9211, 0.9265, 0.9238, 0.9322, 0.9334, 0.9276, 0.9276, 0.9302,\n",
       "                      0.9253, 0.9220, 0.9375, 0.9394, 0.9243, 0.9221, 0.9324, 0.9226, 0.9258,\n",
       "                      0.9332, 0.9323, 0.9222, 0.9414, 0.9187, 0.9232, 0.9230, 0.9269, 0.9206,\n",
       "                      0.9238, 0.9232, 0.9245, 0.9244, 0.9293, 0.9261, 0.9218, 0.9247, 0.9223,\n",
       "                      0.9324, 0.9218, 0.9234, 0.9296, 0.9248, 0.9285, 0.9256, 0.9292, 0.9296,\n",
       "                      0.9287, 0.9321, 0.9246, 0.9223, 0.9269, 0.9334, 0.9226, 0.9229, 0.9211,\n",
       "                      0.9209, 0.9326, 0.9211, 0.9211, 0.9241, 0.9283, 0.9362, 0.9234])),\n",
       "             ('conv_block4.4.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block5.0.weight',\n",
       "              tensor([[[[-1.4313e-02, -1.5710e-02, -2.2602e-03],\n",
       "                        [ 9.4248e-03,  7.4231e-03,  1.9020e-02],\n",
       "                        [ 9.2327e-03, -1.5061e-02,  1.0187e-02]],\n",
       "              \n",
       "                       [[-1.4966e-02, -4.9236e-03, -2.4359e-02],\n",
       "                        [ 2.4717e-05,  1.2461e-02,  4.8189e-03],\n",
       "                        [-1.2173e-02,  9.7800e-03, -7.5651e-03]],\n",
       "              \n",
       "                       [[ 1.3677e-02, -8.6292e-03,  1.9113e-02],\n",
       "                        [ 1.0244e-02,  9.2043e-03, -2.3845e-02],\n",
       "                        [-1.1676e-02,  8.5848e-03,  8.3809e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0785e-02,  1.5269e-02, -2.3732e-03],\n",
       "                        [ 2.3416e-02,  3.6689e-03,  2.1294e-02],\n",
       "                        [ 9.9740e-03, -1.5583e-02, -8.8268e-03]],\n",
       "              \n",
       "                       [[-6.9846e-03,  2.1962e-02, -1.4836e-02],\n",
       "                        [ 1.4647e-02, -1.6000e-02,  1.3725e-02],\n",
       "                        [-1.1128e-02,  2.1775e-03,  1.8595e-02]],\n",
       "              \n",
       "                       [[ 1.1041e-02,  7.8203e-03,  4.6574e-03],\n",
       "                        [-9.5874e-05, -1.1196e-02,  1.5579e-02],\n",
       "                        [ 9.5229e-04,  1.0474e-02,  2.0087e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.7342e-03,  1.2342e-02, -1.1007e-02],\n",
       "                        [ 2.1776e-02, -1.8462e-02,  6.2691e-03],\n",
       "                        [-2.2490e-02, -1.7362e-02,  2.3416e-02]],\n",
       "              \n",
       "                       [[ 4.5694e-03, -2.5801e-04, -2.1788e-03],\n",
       "                        [ 8.3336e-03, -1.0127e-03,  8.1500e-03],\n",
       "                        [-2.0001e-02,  1.8712e-02, -1.4207e-02]],\n",
       "              \n",
       "                       [[-2.1392e-02, -5.4260e-03, -5.3203e-03],\n",
       "                        [-1.6897e-02, -1.2675e-02,  1.9163e-03],\n",
       "                        [ 2.4979e-02,  1.2414e-03, -1.9559e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0563e-03, -5.0482e-03,  2.4511e-02],\n",
       "                        [ 4.7075e-03,  2.3007e-02,  2.2417e-02],\n",
       "                        [ 1.0552e-02, -6.5635e-03,  4.3071e-03]],\n",
       "              \n",
       "                       [[-1.7470e-02,  1.1340e-02, -1.0203e-02],\n",
       "                        [ 2.3057e-02, -1.3878e-02, -4.0763e-03],\n",
       "                        [ 4.3880e-03, -8.0578e-03,  1.1001e-02]],\n",
       "              \n",
       "                       [[-4.0584e-04,  1.6103e-02, -1.8604e-02],\n",
       "                        [-1.6784e-02, -1.4108e-03, -1.7870e-02],\n",
       "                        [-1.3490e-02,  1.3323e-02,  1.4158e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1060e-02,  1.7874e-03,  1.8922e-02],\n",
       "                        [ 8.6089e-03,  5.3084e-03,  1.0136e-02],\n",
       "                        [-1.4757e-02, -2.3198e-02, -1.0943e-02]],\n",
       "              \n",
       "                       [[-1.3048e-02,  1.5770e-02, -2.1080e-02],\n",
       "                        [-1.5740e-02, -1.0574e-02, -1.5225e-02],\n",
       "                        [ 1.8447e-02, -7.7963e-03,  2.3627e-02]],\n",
       "              \n",
       "                       [[-2.1946e-02, -4.6710e-04,  2.0265e-02],\n",
       "                        [ 2.1758e-02,  1.4542e-02, -7.6053e-04],\n",
       "                        [-1.1457e-02,  1.6426e-02,  1.0202e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.8352e-02, -1.5396e-02, -1.8732e-02],\n",
       "                        [-1.9934e-02,  2.2998e-03, -1.4637e-03],\n",
       "                        [ 1.6757e-02, -2.3847e-02,  2.8158e-03]],\n",
       "              \n",
       "                       [[ 1.8137e-02,  9.6924e-03,  2.4358e-03],\n",
       "                        [ 4.3213e-03, -2.4231e-02,  2.0680e-02],\n",
       "                        [ 1.4416e-02,  2.0058e-02,  3.4301e-03]],\n",
       "              \n",
       "                       [[-9.7258e-03,  3.2188e-03,  2.0609e-03],\n",
       "                        [-3.9870e-03,  1.1566e-02,  1.0940e-02],\n",
       "                        [ 4.1351e-03,  6.7752e-03, -1.8239e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-7.5012e-03, -2.3056e-02, -2.4309e-02],\n",
       "                        [-1.6041e-02, -9.0133e-03,  1.5045e-02],\n",
       "                        [-2.2265e-02,  1.2307e-02, -1.6209e-02]],\n",
       "              \n",
       "                       [[-2.4785e-02,  2.1954e-02,  1.8881e-02],\n",
       "                        [ 1.5294e-02,  2.1116e-03,  5.6844e-03],\n",
       "                        [ 1.8752e-02, -1.1943e-02,  1.4972e-02]],\n",
       "              \n",
       "                       [[ 1.8780e-02, -2.5999e-03, -7.0594e-03],\n",
       "                        [-8.4693e-03, -4.9910e-03, -1.6731e-02],\n",
       "                        [-2.5062e-02, -2.9401e-03, -8.1456e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5089e-02,  4.7784e-03, -2.3952e-02],\n",
       "                        [-7.1838e-03,  8.3780e-03, -1.2349e-02],\n",
       "                        [ 2.1167e-02,  1.4482e-02, -3.2112e-03]],\n",
       "              \n",
       "                       [[ 2.1443e-02, -3.0656e-03, -8.6685e-03],\n",
       "                        [-9.2687e-03, -5.7487e-03, -2.3140e-02],\n",
       "                        [-2.0320e-02, -1.9812e-02,  7.9771e-03]],\n",
       "              \n",
       "                       [[ 9.3154e-03,  5.7575e-03,  1.1932e-02],\n",
       "                        [ 9.2087e-03,  1.0991e-02, -5.2922e-03],\n",
       "                        [-7.3712e-03, -3.5590e-03, -1.8189e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.9185e-03,  2.0239e-02,  2.0633e-02],\n",
       "                        [-3.0860e-03, -1.6736e-02, -4.5753e-03],\n",
       "                        [ 1.1613e-02, -8.1731e-03,  1.5252e-02]],\n",
       "              \n",
       "                       [[ 1.5355e-02, -1.2400e-02,  1.6217e-02],\n",
       "                        [ 2.2102e-02,  2.4120e-03,  6.7604e-04],\n",
       "                        [-1.5943e-02, -2.0309e-02, -1.2351e-02]],\n",
       "              \n",
       "                       [[ 7.9969e-03, -4.6921e-03,  1.6511e-02],\n",
       "                        [ 1.8578e-02,  2.2964e-02,  2.1150e-02],\n",
       "                        [ 1.7864e-02,  2.2813e-02,  5.5863e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0558e-02, -2.7427e-03,  1.5101e-02],\n",
       "                        [ 1.8129e-02,  1.3719e-02, -1.6611e-02],\n",
       "                        [-1.1395e-02,  2.2445e-02,  1.6511e-02]],\n",
       "              \n",
       "                       [[ 1.1494e-02,  2.4438e-02,  2.3339e-03],\n",
       "                        [-1.6403e-02,  6.7798e-03, -5.2941e-03],\n",
       "                        [ 1.8283e-02,  3.5785e-03, -9.5957e-03]],\n",
       "              \n",
       "                       [[ 1.1496e-02, -8.0350e-04,  1.4988e-02],\n",
       "                        [-2.4283e-02, -7.6770e-03, -1.8056e-02],\n",
       "                        [-1.6176e-02, -2.4530e-02,  2.4461e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9496e-02,  1.5639e-02, -2.1435e-02],\n",
       "                        [-2.4641e-02, -2.1304e-02, -5.8369e-03],\n",
       "                        [-8.6849e-03, -1.1059e-02,  6.1871e-03]],\n",
       "              \n",
       "                       [[-2.5446e-02,  1.7172e-02, -2.0624e-02],\n",
       "                        [-2.2953e-02,  2.2954e-02,  3.6141e-03],\n",
       "                        [ 4.6550e-03,  2.2396e-02,  1.2517e-02]],\n",
       "              \n",
       "                       [[-7.3393e-03,  2.4529e-02,  1.8557e-02],\n",
       "                        [-2.4209e-02, -1.4674e-02,  3.9379e-03],\n",
       "                        [ 4.3602e-03,  1.2811e-03,  1.5956e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4300e-02,  2.3484e-02, -1.4564e-02],\n",
       "                        [-1.3865e-02, -1.9524e-02, -1.7999e-02],\n",
       "                        [ 2.1055e-03, -9.4217e-03, -3.3040e-03]],\n",
       "              \n",
       "                       [[-1.4061e-02, -1.6496e-02,  1.8124e-02],\n",
       "                        [-5.7721e-03,  1.5923e-03,  8.0902e-03],\n",
       "                        [ 1.2808e-02, -1.0233e-02, -1.7941e-02]],\n",
       "              \n",
       "                       [[ 1.1742e-02,  7.0785e-03, -1.7974e-02],\n",
       "                        [ 1.6647e-02, -2.2264e-02, -1.7335e-02],\n",
       "                        [-1.0274e-02,  2.1635e-02, -7.1489e-03]]]])),\n",
       "             ('conv_block5.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block5.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('conv_block5.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block5.1.running_mean',\n",
       "              tensor([-6.7386e-02,  2.6090e-02, -5.7956e-02, -4.8947e-02,  4.0010e-02,\n",
       "                       4.4257e-02,  9.3580e-02,  4.1285e-02,  5.2212e-03, -1.2275e-02,\n",
       "                      -3.7866e-02, -8.9524e-02,  4.9123e-02, -3.9429e-02,  9.3244e-03,\n",
       "                      -2.3153e-02,  4.3418e-03, -1.0651e-02,  3.9919e-02,  4.9058e-02,\n",
       "                      -3.0748e-02, -1.5465e-02, -1.9360e-02,  6.3567e-02,  2.5651e-02,\n",
       "                       6.2964e-02,  3.3858e-02,  1.5063e-02, -1.2384e-01,  4.2087e-02,\n",
       "                       3.1622e-02, -5.6586e-02,  7.3190e-03,  1.0173e-01, -3.2444e-04,\n",
       "                      -3.2085e-03,  1.9859e-02,  7.3887e-02,  2.3895e-02, -1.6291e-02,\n",
       "                      -1.3166e-02,  7.0934e-02, -6.2498e-02,  2.2029e-02,  1.3779e-03,\n",
       "                       5.8118e-02,  2.2056e-02,  8.7822e-02,  3.4362e-02, -3.8145e-02,\n",
       "                       7.7671e-02, -7.6946e-02, -2.2644e-02, -1.3033e-01, -6.9043e-02,\n",
       "                       5.6366e-02,  1.7232e-02,  3.1745e-02, -1.1554e-02,  2.9430e-02,\n",
       "                      -2.8060e-02,  6.3490e-02,  2.1422e-03, -5.8167e-02,  4.6955e-02,\n",
       "                      -2.8100e-02, -8.3834e-03, -1.3307e-02, -1.7039e-02,  4.9639e-02,\n",
       "                       1.6342e-02,  1.1916e-02,  5.2060e-02, -6.8104e-02, -4.7267e-02,\n",
       "                       2.4456e-02,  6.4827e-02, -3.7795e-02, -2.9060e-02,  1.2584e-02,\n",
       "                       1.7136e-02,  3.2114e-02,  3.9405e-02, -7.6836e-03, -9.6125e-03,\n",
       "                       3.4320e-02, -7.2283e-02,  4.5751e-02, -7.1500e-03,  2.7941e-02,\n",
       "                      -3.3102e-02,  6.2665e-02, -3.7033e-02, -2.2874e-02, -3.7184e-02,\n",
       "                       5.8823e-02, -6.2215e-02, -9.6764e-02, -4.1246e-02,  9.8532e-03,\n",
       "                       2.0899e-02,  9.3667e-03, -1.2669e-02,  7.5224e-02,  3.1102e-02,\n",
       "                       6.8493e-02,  1.5481e-02,  6.1805e-02,  2.6149e-02, -1.4464e-02,\n",
       "                      -2.5784e-02,  1.1017e-02,  2.2039e-02, -6.3623e-02,  4.2131e-02,\n",
       "                       3.8508e-02, -2.5218e-02, -2.7184e-02,  6.8716e-02, -2.0896e-02,\n",
       "                       6.6572e-02, -3.4877e-02, -1.6684e-02, -1.9035e-02,  8.6547e-03,\n",
       "                      -8.1294e-03, -6.0136e-02,  1.4736e-02,  1.5985e-02, -4.0401e-02,\n",
       "                      -1.3420e-02, -9.0907e-02, -3.2080e-02,  4.1780e-02, -3.3128e-02,\n",
       "                      -6.3792e-02, -1.0037e-02, -3.0182e-02,  3.5903e-02, -8.7262e-02,\n",
       "                      -1.9063e-02, -5.1439e-02, -1.2042e-01,  2.5345e-02,  1.4356e-02,\n",
       "                      -4.4544e-02, -5.0127e-02,  6.4518e-02, -2.3940e-02, -4.3389e-02,\n",
       "                      -3.7687e-02, -2.4274e-02, -4.3814e-03, -5.8656e-02,  1.6869e-02,\n",
       "                       3.6152e-02,  2.4153e-02, -4.5980e-02, -4.9849e-02, -1.4550e-03,\n",
       "                       5.5219e-04, -3.2373e-02,  5.8903e-02,  1.9748e-02,  1.0088e-01,\n",
       "                       2.3661e-02,  1.6261e-02,  3.2441e-02,  3.2963e-02,  3.7769e-02,\n",
       "                       9.0764e-02,  8.8998e-02, -3.0027e-02, -1.7830e-02,  4.2563e-02,\n",
       "                      -2.7112e-02,  3.3054e-02, -8.3664e-02, -5.5447e-02,  3.3959e-02,\n",
       "                       1.2046e-01, -2.8135e-02,  5.0102e-02,  5.7809e-02, -7.6740e-02,\n",
       "                       3.5918e-02,  8.5921e-02,  1.0166e-01,  6.3182e-02, -3.8487e-02,\n",
       "                       2.4718e-02,  3.4687e-02,  2.2816e-02, -1.0647e-02, -2.4459e-02,\n",
       "                       5.3154e-02, -6.5462e-02, -1.7323e-03,  8.7662e-04,  1.7893e-01,\n",
       "                       1.2467e-01,  4.1578e-02, -1.7778e-03,  3.6711e-02,  2.1558e-02,\n",
       "                       1.6730e-02, -3.4078e-02,  3.5904e-02,  8.3521e-03, -2.9987e-02,\n",
       "                      -9.1060e-04,  1.0430e-02,  5.6170e-02, -2.5806e-02, -8.5204e-03,\n",
       "                      -1.0569e-01,  1.2117e-04, -6.9675e-02, -4.4422e-02, -8.5918e-02,\n",
       "                       1.4615e-02,  3.5476e-02,  2.3065e-03, -7.2093e-02, -5.6366e-02,\n",
       "                      -2.0959e-02, -6.2352e-02,  8.2968e-02, -2.2299e-02,  3.3022e-02,\n",
       "                      -1.0945e-02,  1.9600e-02, -7.5537e-02, -5.8554e-02,  7.8049e-02,\n",
       "                      -4.9704e-02, -3.3698e-02, -5.0586e-02, -1.8997e-02,  2.6351e-02,\n",
       "                       3.0041e-02, -9.6817e-03, -8.3754e-02,  7.3148e-03,  2.0467e-02,\n",
       "                       3.7313e-02,  3.6443e-02,  5.8123e-02, -4.9042e-02, -5.0385e-02,\n",
       "                      -6.1003e-02, -2.2328e-02,  1.8279e-02,  5.5886e-02, -3.4161e-02,\n",
       "                      -6.4155e-02, -3.3247e-03,  2.2897e-02, -5.9077e-02,  6.3742e-02,\n",
       "                      -1.2477e-02,  1.0613e-02, -1.9100e-02,  1.0081e-02, -3.2644e-02,\n",
       "                       1.1499e-01,  1.1088e-01,  4.2324e-02, -1.7155e-02,  1.1830e-02,\n",
       "                      -9.7092e-03,  2.1712e-02,  4.0650e-02,  9.3442e-03, -6.5407e-03,\n",
       "                       4.6512e-03, -8.1036e-03, -3.3774e-02, -5.8847e-02,  1.6366e-02,\n",
       "                       2.5248e-02,  1.9593e-02, -5.5419e-02,  2.8527e-03, -7.1931e-02,\n",
       "                      -4.0578e-02,  2.7249e-02,  6.3543e-02,  4.9212e-03, -7.2557e-02,\n",
       "                      -2.2968e-02, -2.4123e-03,  1.5219e-02, -1.0937e-02, -1.0429e-02,\n",
       "                      -1.2295e-02, -3.2457e-02, -2.5814e-02,  6.8254e-02, -1.6830e-03,\n",
       "                       4.7274e-02, -1.6868e-02, -4.4000e-02, -4.9128e-02,  7.5780e-03,\n",
       "                       6.9774e-02,  5.8717e-02, -7.9460e-02, -1.6048e-03,  8.9471e-02,\n",
       "                      -3.1358e-02,  3.2501e-02, -7.6022e-02, -5.5011e-03, -1.8586e-03,\n",
       "                      -2.6649e-02, -6.5183e-02, -5.1323e-02,  6.4180e-02,  8.8067e-02,\n",
       "                       6.5291e-02, -5.5989e-04, -7.4433e-03, -2.0365e-02,  8.4838e-03,\n",
       "                       1.5745e-02,  9.6753e-02, -3.1988e-02, -5.8593e-02,  2.1480e-02,\n",
       "                      -8.4007e-02, -5.4797e-02, -1.5475e-02,  7.9502e-03, -1.0594e-02,\n",
       "                      -1.2788e-02, -1.5170e-02,  4.5215e-02, -1.5491e-02,  2.1601e-02,\n",
       "                      -1.4114e-02,  1.0752e-01,  1.2686e-02,  4.5608e-02,  1.0607e-02,\n",
       "                       9.8862e-02,  2.9755e-02, -4.2065e-02,  1.6440e-02,  5.7634e-02,\n",
       "                      -4.6537e-02, -6.0584e-02,  2.8868e-02, -1.1276e-02,  4.1685e-02,\n",
       "                      -7.1512e-03,  7.8672e-02, -1.3630e-02, -1.0406e-02, -4.0813e-02,\n",
       "                       2.3441e-02,  2.1688e-02, -2.3593e-02,  2.3041e-02, -2.7948e-02,\n",
       "                       1.0774e-02, -2.3735e-02, -2.4638e-02, -7.5371e-02,  1.5709e-02,\n",
       "                      -2.3538e-02, -3.4918e-02, -3.4527e-02,  2.8263e-02,  5.9874e-03,\n",
       "                       7.4132e-02,  8.1018e-02, -4.5502e-02, -3.8921e-02, -2.4183e-02,\n",
       "                      -2.4471e-02, -5.4526e-02, -1.1863e-01, -2.3633e-02,  4.8506e-03,\n",
       "                       6.3807e-02,  6.4848e-02,  1.8433e-02,  9.2858e-02,  1.4093e-02,\n",
       "                      -6.8405e-02,  3.4643e-02,  6.4940e-03, -3.0479e-02,  5.9455e-02,\n",
       "                      -5.8218e-02,  6.2733e-02,  1.1218e-02, -6.1553e-03,  3.8450e-02,\n",
       "                       8.0272e-02,  1.8342e-02,  2.3161e-02, -6.2455e-02, -4.0675e-02,\n",
       "                       5.3731e-02,  2.2131e-02,  3.1739e-02,  8.0092e-03,  6.8208e-02,\n",
       "                      -1.2734e-02,  6.6448e-02,  6.9138e-02,  8.9730e-02, -4.5460e-02,\n",
       "                      -4.5455e-02,  2.1417e-02,  6.7768e-02,  8.3390e-02, -2.2277e-02,\n",
       "                      -4.7666e-02,  1.9013e-03, -1.8411e-03, -2.9610e-03, -1.2726e-02,\n",
       "                       5.4416e-02,  1.7658e-02, -3.2302e-02,  1.0292e-01,  2.5548e-02,\n",
       "                       3.8483e-02,  2.7926e-02, -1.0093e-02, -5.0738e-02,  1.6962e-02,\n",
       "                      -3.6439e-02,  3.7973e-02,  7.1594e-03, -5.3178e-02, -7.3031e-02,\n",
       "                       9.6307e-02, -1.7829e-03,  6.2089e-02, -4.0036e-03,  1.6724e-02,\n",
       "                      -1.0579e-01,  6.6340e-02,  1.9163e-02,  2.3324e-03,  2.8143e-02,\n",
       "                      -3.8540e-02, -1.1817e-02,  5.3498e-03, -1.1538e-01,  1.7615e-02,\n",
       "                      -5.0187e-02, -1.1217e-01, -3.7627e-03,  6.9406e-02, -4.3081e-02,\n",
       "                      -8.4806e-03,  4.0530e-02, -5.7045e-02, -1.2362e-02,  2.6433e-02,\n",
       "                       1.3336e-01,  8.4049e-02,  5.1008e-02,  2.9346e-02,  3.1308e-02,\n",
       "                       4.1782e-03,  6.6189e-02,  4.1336e-02, -6.1198e-02, -1.5915e-01,\n",
       "                       4.2449e-02,  3.1815e-02,  7.0730e-03,  8.9072e-03,  3.7803e-02,\n",
       "                      -2.1065e-02, -7.6722e-02, -2.4635e-03, -1.3253e-02,  3.3226e-02,\n",
       "                      -7.6226e-02, -5.8745e-02,  1.2254e-02, -1.1022e-02,  1.3225e-02,\n",
       "                       1.0274e-01,  6.5864e-02, -6.7874e-03,  2.6609e-02,  2.9488e-02,\n",
       "                       7.4499e-03, -8.1363e-02,  4.8630e-02,  4.1433e-02,  1.6162e-02,\n",
       "                      -4.0005e-03, -1.1295e-01, -6.1788e-02, -1.4272e-02, -2.3795e-02,\n",
       "                       4.6395e-02,  3.6326e-03,  4.6730e-02, -3.8756e-02,  3.1804e-02,\n",
       "                       3.4232e-02,  9.8423e-03])),\n",
       "             ('conv_block5.1.running_var',\n",
       "              tensor([0.9497, 0.9358, 0.9407, 0.9240, 0.9428, 0.9272, 0.9224, 0.9186, 0.9768,\n",
       "                      0.9285, 0.9443, 0.9260, 0.9281, 0.9272, 0.9247, 0.9339, 0.9380, 0.9327,\n",
       "                      0.9383, 0.9441, 0.9382, 0.9831, 0.9345, 0.9191, 0.9232, 0.9645, 0.9375,\n",
       "                      0.9782, 0.9320, 0.9231, 0.9325, 0.9208, 0.9295, 0.9282, 0.9268, 0.9266,\n",
       "                      0.9292, 0.9429, 0.9399, 0.9344, 1.0113, 0.9307, 0.9252, 0.9367, 0.9212,\n",
       "                      0.9290, 0.9232, 0.9420, 0.9203, 0.9705, 0.9259, 0.9268, 0.9216, 0.9657,\n",
       "                      0.9267, 0.9276, 0.9286, 0.9235, 0.9257, 0.9336, 0.9227, 0.9589, 0.9492,\n",
       "                      0.9362, 0.9200, 0.9229, 0.9297, 0.9260, 0.9319, 0.9278, 0.9517, 0.9297,\n",
       "                      0.9252, 0.9394, 0.9338, 0.9245, 0.9400, 0.9292, 0.9227, 0.9268, 0.9450,\n",
       "                      0.9381, 0.9641, 0.9612, 0.9580, 0.9381, 0.9438, 0.9260, 0.9685, 0.9431,\n",
       "                      0.9999, 0.9268, 0.9488, 0.9202, 0.9174, 0.9723, 0.9247, 0.9301, 0.9513,\n",
       "                      0.9395, 0.9380, 0.9302, 1.0272, 0.9218, 0.9499, 0.9385, 0.9207, 0.9169,\n",
       "                      0.9212, 0.9551, 0.9552, 0.9418, 0.9502, 0.9205, 0.9260, 0.9334, 0.9355,\n",
       "                      0.9585, 0.9976, 0.9867, 0.9218, 0.9443, 0.9624, 0.9377, 0.9695, 0.9381,\n",
       "                      0.9500, 0.9383, 0.9186, 0.9207, 0.9350, 0.9326, 0.9477, 0.9283, 0.9505,\n",
       "                      0.9520, 0.9489, 0.9319, 0.9569, 0.9422, 0.9387, 0.9514, 0.9569, 0.9274,\n",
       "                      0.9235, 0.9215, 0.9245, 0.9763, 0.9290, 0.9276, 0.9368, 0.9433, 0.9257,\n",
       "                      0.9200, 0.9284, 0.9537, 0.9196, 0.9468, 0.9329, 0.9430, 0.9303, 0.9525,\n",
       "                      0.9423, 0.9683, 0.9385, 0.9265, 0.9269, 0.9799, 0.9255, 0.9275, 0.9324,\n",
       "                      0.9282, 0.9496, 0.9852, 0.9816, 0.9191, 0.9244, 0.9283, 0.9306, 0.9845,\n",
       "                      0.9267, 0.9238, 0.9348, 0.9468, 0.9354, 0.9615, 0.9232, 0.9165, 0.9213,\n",
       "                      0.9758, 0.9851, 0.9260, 0.9317, 0.9749, 0.9450, 0.9635, 0.9198, 0.9227,\n",
       "                      0.9411, 0.9591, 0.9735, 0.9798, 0.9429, 0.9220, 0.9259, 0.9656, 0.9462,\n",
       "                      0.9639, 0.9246, 0.9212, 0.9541, 0.9284, 0.9335, 0.9266, 0.9286, 0.9416,\n",
       "                      0.9257, 0.9308, 0.9679, 0.9341, 0.9196, 0.9475, 0.9164, 0.9268, 0.9447,\n",
       "                      0.9251, 0.9453, 0.9365, 0.9379, 0.9198, 0.9569, 0.9532, 0.9268, 0.9234,\n",
       "                      0.9288, 0.9265, 0.9780, 0.9390, 0.9336, 0.9170, 0.9442, 0.9610, 0.9425,\n",
       "                      0.9273, 1.0199, 0.9422, 0.9391, 0.9439, 0.9541, 0.9302, 1.0147, 0.9800,\n",
       "                      0.9502, 0.9229, 0.9582, 0.9563, 0.9319, 0.9793, 0.9203, 1.0235, 0.9361,\n",
       "                      0.9232, 0.9689, 0.9310, 0.9458, 0.9608, 0.9711, 1.0194, 0.9268, 0.9230,\n",
       "                      0.9380, 0.9288, 0.9181, 0.9333, 0.9204, 0.9555, 0.9399, 0.9194, 0.9558,\n",
       "                      0.9188, 0.9236, 0.9381, 0.9637, 0.9311, 0.9262, 0.9927, 0.9521, 0.9966,\n",
       "                      0.9237, 0.9269, 0.9221, 0.9205, 0.9292, 0.9399, 0.9166, 0.9309, 0.9298,\n",
       "                      0.9319, 0.9237, 0.9576, 0.9295, 0.9216, 0.9603, 0.9426, 0.9303, 0.9479,\n",
       "                      0.9758, 0.9241, 0.9176, 0.9340, 0.9288, 0.9631, 0.9240, 0.9347, 0.9993,\n",
       "                      0.9365, 0.9373, 0.9250, 0.9243, 0.9520, 0.9572, 0.9449, 0.9614, 0.9247,\n",
       "                      0.9166, 0.9360, 0.9503, 0.9272, 0.9311, 0.9228, 0.9230, 0.9209, 0.9206,\n",
       "                      0.9257, 0.9238, 0.9514, 0.9371, 0.9367, 0.9711, 0.9197, 0.9607, 0.9367,\n",
       "                      0.9219, 0.9163, 0.9349, 0.9345, 0.9250, 0.9642, 0.9795, 0.9276, 0.9415,\n",
       "                      0.9407, 0.9543, 0.9510, 0.9205, 0.9603, 0.9298, 0.9246, 0.9807, 0.9369,\n",
       "                      0.9243, 0.9360, 0.9333, 0.9731, 0.9725, 0.9192, 0.9468, 0.9270, 0.9326,\n",
       "                      0.9380, 0.9250, 0.9164, 0.9447, 0.9289, 0.9604, 0.9709, 0.9389, 0.9477,\n",
       "                      0.9216, 0.9377, 0.9331, 0.9503, 0.9196, 0.9431, 0.9375, 0.9825, 0.9371,\n",
       "                      0.9677, 0.9174, 0.9275, 0.9543, 0.9804, 0.9371, 0.9196, 0.9539, 0.9264,\n",
       "                      0.9490, 0.9290, 0.9384, 0.9207, 0.9223, 0.9266, 0.9421, 0.9220, 0.9227,\n",
       "                      0.9282, 0.9400, 0.9449, 0.9253, 0.9396, 0.9572, 0.9250, 0.9444, 0.9236,\n",
       "                      0.9175, 0.9287, 0.9878, 0.9391, 0.9454, 0.9245, 0.9623, 0.9316, 0.9320,\n",
       "                      0.9443, 0.9383, 0.9489, 0.9241, 0.9349, 0.9297, 0.9378, 0.9185, 0.9244,\n",
       "                      0.9302, 0.9412, 0.9255, 0.9344, 0.9233, 0.9592, 0.9633, 0.9470, 0.9585,\n",
       "                      0.9438, 0.9636, 0.9438, 0.9586, 0.9622, 0.9487, 0.9290, 0.9218, 0.9477,\n",
       "                      0.9270, 0.9831, 0.9326, 0.9422, 0.9594, 0.9488, 0.9464, 0.9808, 0.9493,\n",
       "                      0.9270, 0.9463, 0.9477, 0.9233, 0.9507, 0.9212, 0.9353, 0.9281, 0.9322,\n",
       "                      0.9869, 0.9215, 0.9376, 0.9224, 0.9527, 0.9468, 0.9333, 0.9469, 0.9246,\n",
       "                      0.9484, 0.9215, 0.9421, 0.9248, 0.9341, 0.9171, 0.9520, 0.9235, 0.9227,\n",
       "                      0.9305, 0.9438, 0.9380, 0.9259, 0.9276, 0.9202, 0.9376, 0.9390, 0.9266,\n",
       "                      0.9268, 0.9264, 0.9234, 0.9209, 0.9300, 0.9196, 0.9671, 0.9358, 0.9478,\n",
       "                      0.9488, 0.9370, 0.9292, 0.9302, 0.9252, 0.9324, 0.9496, 0.9527])),\n",
       "             ('conv_block5.1.num_batches_tracked', tensor(1)),\n",
       "             ('conv_block5.3.weight',\n",
       "              tensor([[[[ 0.0127,  0.0182, -0.0095],\n",
       "                        [ 0.0132, -0.0208, -0.0230],\n",
       "                        [-0.0021,  0.0162,  0.0217]],\n",
       "              \n",
       "                       [[-0.0168,  0.0177,  0.0173],\n",
       "                        [ 0.0016,  0.0250,  0.0044],\n",
       "                        [-0.0223,  0.0066,  0.0119]],\n",
       "              \n",
       "                       [[-0.0008,  0.0020,  0.0034],\n",
       "                        [-0.0100,  0.0046, -0.0185],\n",
       "                        [ 0.0206, -0.0186, -0.0236]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0250,  0.0067,  0.0025],\n",
       "                        [-0.0177, -0.0062,  0.0058],\n",
       "                        [ 0.0069,  0.0174, -0.0076]],\n",
       "              \n",
       "                       [[-0.0062, -0.0088, -0.0050],\n",
       "                        [-0.0114, -0.0120, -0.0176],\n",
       "                        [ 0.0220,  0.0187,  0.0077]],\n",
       "              \n",
       "                       [[-0.0200, -0.0045,  0.0125],\n",
       "                        [-0.0030,  0.0091, -0.0180],\n",
       "                        [ 0.0170,  0.0162,  0.0244]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0188, -0.0005,  0.0056],\n",
       "                        [ 0.0212,  0.0017, -0.0026],\n",
       "                        [-0.0099, -0.0227,  0.0066]],\n",
       "              \n",
       "                       [[ 0.0036, -0.0059, -0.0004],\n",
       "                        [-0.0152, -0.0179, -0.0119],\n",
       "                        [ 0.0168,  0.0207, -0.0171]],\n",
       "              \n",
       "                       [[ 0.0130, -0.0086,  0.0074],\n",
       "                        [ 0.0010,  0.0008,  0.0024],\n",
       "                        [-0.0129, -0.0008, -0.0185]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0168, -0.0207, -0.0054],\n",
       "                        [ 0.0198,  0.0021, -0.0090],\n",
       "                        [ 0.0174,  0.0187, -0.0209]],\n",
       "              \n",
       "                       [[-0.0026, -0.0101, -0.0060],\n",
       "                        [ 0.0079, -0.0052,  0.0247],\n",
       "                        [ 0.0026, -0.0069,  0.0034]],\n",
       "              \n",
       "                       [[-0.0209,  0.0016, -0.0018],\n",
       "                        [ 0.0085, -0.0148, -0.0192],\n",
       "                        [-0.0156, -0.0052, -0.0195]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0219,  0.0226,  0.0092],\n",
       "                        [ 0.0202, -0.0032,  0.0144],\n",
       "                        [-0.0080,  0.0244,  0.0160]],\n",
       "              \n",
       "                       [[-0.0084, -0.0153, -0.0015],\n",
       "                        [-0.0018, -0.0047, -0.0208],\n",
       "                        [ 0.0216,  0.0184,  0.0184]],\n",
       "              \n",
       "                       [[ 0.0167,  0.0189,  0.0014],\n",
       "                        [ 0.0227, -0.0115,  0.0082],\n",
       "                        [-0.0039, -0.0186,  0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0252, -0.0072, -0.0032],\n",
       "                        [-0.0221,  0.0176,  0.0002],\n",
       "                        [ 0.0031, -0.0109,  0.0017]],\n",
       "              \n",
       "                       [[ 0.0024,  0.0141,  0.0030],\n",
       "                        [-0.0118,  0.0146,  0.0137],\n",
       "                        [-0.0091, -0.0102,  0.0117]],\n",
       "              \n",
       "                       [[-0.0164,  0.0122,  0.0009],\n",
       "                        [-0.0146, -0.0125, -0.0039],\n",
       "                        [-0.0078,  0.0193, -0.0224]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0019, -0.0058, -0.0057],\n",
       "                        [-0.0065,  0.0036,  0.0139],\n",
       "                        [ 0.0120,  0.0201, -0.0143]],\n",
       "              \n",
       "                       [[-0.0206,  0.0095, -0.0100],\n",
       "                        [-0.0228, -0.0178, -0.0082],\n",
       "                        [ 0.0119,  0.0141,  0.0041]],\n",
       "              \n",
       "                       [[-0.0007, -0.0155,  0.0043],\n",
       "                        [-0.0027,  0.0209,  0.0166],\n",
       "                        [-0.0055, -0.0205, -0.0035]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0196,  0.0224, -0.0156],\n",
       "                        [-0.0150,  0.0244, -0.0058],\n",
       "                        [-0.0147, -0.0036, -0.0135]],\n",
       "              \n",
       "                       [[-0.0239, -0.0109, -0.0199],\n",
       "                        [-0.0214,  0.0234,  0.0216],\n",
       "                        [ 0.0056, -0.0227, -0.0168]],\n",
       "              \n",
       "                       [[-0.0068,  0.0100,  0.0155],\n",
       "                        [-0.0048,  0.0135, -0.0068],\n",
       "                        [ 0.0088, -0.0069,  0.0227]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0151,  0.0171, -0.0248],\n",
       "                        [ 0.0161,  0.0029,  0.0144],\n",
       "                        [ 0.0084,  0.0165, -0.0150]],\n",
       "              \n",
       "                       [[-0.0100,  0.0220,  0.0036],\n",
       "                        [-0.0204, -0.0066,  0.0204],\n",
       "                        [ 0.0157,  0.0103,  0.0228]],\n",
       "              \n",
       "                       [[-0.0185,  0.0071,  0.0157],\n",
       "                        [ 0.0115, -0.0090, -0.0231],\n",
       "                        [ 0.0222,  0.0162, -0.0191]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0192, -0.0185, -0.0023],\n",
       "                        [ 0.0163, -0.0105, -0.0022],\n",
       "                        [-0.0101, -0.0193, -0.0202]],\n",
       "              \n",
       "                       [[-0.0037,  0.0116,  0.0119],\n",
       "                        [-0.0105, -0.0173, -0.0213],\n",
       "                        [-0.0156, -0.0089,  0.0042]],\n",
       "              \n",
       "                       [[-0.0181,  0.0187,  0.0009],\n",
       "                        [ 0.0117, -0.0239, -0.0186],\n",
       "                        [-0.0205,  0.0210, -0.0134]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0062,  0.0215,  0.0080],\n",
       "                        [ 0.0232,  0.0233,  0.0156],\n",
       "                        [-0.0217, -0.0233, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0185,  0.0040,  0.0138],\n",
       "                        [-0.0253,  0.0055, -0.0190],\n",
       "                        [ 0.0043,  0.0113,  0.0205]],\n",
       "              \n",
       "                       [[-0.0044, -0.0231, -0.0097],\n",
       "                        [ 0.0108, -0.0196,  0.0011],\n",
       "                        [-0.0111,  0.0218, -0.0220]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0217, -0.0047, -0.0203],\n",
       "                        [-0.0233, -0.0123, -0.0003],\n",
       "                        [ 0.0096, -0.0054,  0.0045]],\n",
       "              \n",
       "                       [[-0.0235,  0.0171, -0.0163],\n",
       "                        [ 0.0223, -0.0076, -0.0225],\n",
       "                        [-0.0246,  0.0040,  0.0246]],\n",
       "              \n",
       "                       [[-0.0019, -0.0245, -0.0231],\n",
       "                        [ 0.0024, -0.0181, -0.0008],\n",
       "                        [-0.0072, -0.0085, -0.0184]]]])),\n",
       "             ('conv_block5.3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block5.4.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('conv_block5.4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv_block5.4.running_mean',\n",
       "              tensor([-3.7608e-02, -7.5397e-05,  5.8632e-02,  2.9802e-02, -4.0759e-02,\n",
       "                       3.8070e-02, -1.6849e-02,  1.8294e-03, -3.5077e-02,  4.0467e-02,\n",
       "                       2.3261e-02,  2.8625e-03, -9.4648e-03, -1.2439e-02, -7.6058e-03,\n",
       "                       4.8671e-02, -5.5607e-03,  5.0997e-02,  1.9721e-02, -2.2968e-02,\n",
       "                       1.5463e-02, -1.3267e-03,  3.4903e-02, -1.6357e-02,  1.3782e-02,\n",
       "                      -2.0114e-02, -2.6766e-02, -5.4607e-03,  4.0915e-03,  2.6923e-02,\n",
       "                       3.4924e-02, -2.3733e-02,  2.4713e-02,  7.1064e-03, -2.6571e-02,\n",
       "                      -7.5716e-03,  1.9276e-02, -2.5009e-02,  1.3555e-02, -1.4264e-02,\n",
       "                       3.2773e-03,  4.3946e-03,  3.9209e-03, -1.1158e-02,  3.8418e-02,\n",
       "                      -2.0889e-02,  3.5959e-02, -1.9128e-02,  1.5893e-02,  4.4738e-02,\n",
       "                       9.4675e-03,  2.3041e-02, -3.0643e-02,  2.4010e-02,  2.7700e-02,\n",
       "                      -7.2592e-03,  9.6051e-03,  2.2855e-02, -4.1720e-02, -3.4109e-02,\n",
       "                      -3.0543e-02,  1.0468e-02, -9.9670e-03, -4.0944e-03, -2.0881e-03,\n",
       "                      -5.8792e-04, -5.5933e-03, -2.5284e-02, -4.2233e-03,  3.2431e-03,\n",
       "                      -8.8703e-03,  7.8784e-03,  2.0759e-02,  2.8727e-02, -2.8183e-02,\n",
       "                      -1.7092e-02, -1.4405e-02, -4.4877e-03, -9.5525e-03, -2.4862e-02,\n",
       "                      -7.2276e-03, -1.2126e-02, -1.3987e-02,  2.4187e-02,  4.7728e-02,\n",
       "                      -2.6365e-02, -3.0960e-02,  1.6005e-02, -2.4843e-02, -1.9209e-02,\n",
       "                       1.0885e-02, -9.1434e-03, -2.4000e-02, -1.9607e-02,  1.5793e-02,\n",
       "                       3.4317e-02,  3.0353e-02, -5.2147e-02, -1.5872e-02, -3.2783e-02,\n",
       "                       3.6484e-03,  5.9168e-03,  2.6688e-02,  2.4325e-03, -6.0267e-03,\n",
       "                       1.5157e-02, -3.4100e-02, -1.0768e-02,  2.0966e-02, -1.9630e-02,\n",
       "                       1.1312e-02,  1.5702e-02, -1.7651e-02, -3.7628e-02,  3.1121e-02,\n",
       "                      -8.8314e-03,  1.5321e-02,  7.8388e-03,  2.0288e-03,  1.4720e-02,\n",
       "                       5.8010e-03,  1.1032e-02, -1.3751e-02,  2.5644e-02,  5.7268e-03,\n",
       "                       1.2904e-02, -1.1437e-02,  5.5741e-03,  3.2487e-02, -7.2521e-03,\n",
       "                       3.0235e-02, -1.7762e-02,  2.6400e-03, -1.7907e-02,  1.0685e-02,\n",
       "                      -2.3196e-02,  8.8464e-03,  2.4771e-02,  1.1630e-02,  7.3401e-03,\n",
       "                       2.6982e-02,  1.5988e-02,  4.0410e-02, -2.6213e-02,  1.6491e-02,\n",
       "                       7.4523e-03, -2.0641e-02,  9.7454e-03,  2.0292e-02,  2.7742e-02,\n",
       "                       4.1484e-03,  1.0471e-02,  1.7440e-02, -2.1726e-02,  2.3671e-02,\n",
       "                       3.2302e-02, -3.2462e-02, -4.6336e-02,  3.1212e-02, -2.4679e-02,\n",
       "                      -1.9554e-02, -1.9659e-02, -1.2748e-02, -3.4386e-02, -1.3394e-02,\n",
       "                       4.9626e-03,  1.2895e-03, -6.6375e-04,  9.2773e-03, -1.3327e-02,\n",
       "                      -1.9941e-02, -5.4403e-03,  1.8341e-02, -4.1863e-03,  1.5441e-03,\n",
       "                      -3.4715e-02,  3.2938e-02,  2.6304e-03, -2.4485e-02, -7.1815e-03,\n",
       "                      -3.0661e-04, -3.1168e-02, -3.5023e-02, -1.7512e-02,  1.3403e-02,\n",
       "                       2.9598e-02,  2.0133e-02,  5.9314e-03, -1.0995e-02, -2.8269e-02,\n",
       "                       3.2287e-02, -1.0788e-03, -4.7560e-04, -4.0375e-03,  3.0489e-02,\n",
       "                      -2.2515e-02, -4.8806e-03, -2.8366e-02,  1.8581e-02,  2.1884e-02,\n",
       "                       1.9035e-02, -1.4913e-02, -2.0122e-02, -1.1819e-02,  1.3214e-02,\n",
       "                      -1.3596e-02, -1.0019e-02,  2.0265e-03, -1.3314e-02, -4.1712e-02,\n",
       "                       8.9422e-03, -6.7139e-03,  2.3661e-03, -1.9157e-02, -5.7203e-03,\n",
       "                       1.3874e-02,  9.4235e-03,  1.4073e-02, -1.0045e-03, -1.0781e-02,\n",
       "                       1.1023e-02, -3.1982e-02, -1.0441e-02,  4.2934e-03,  1.7774e-02,\n",
       "                       9.7834e-03,  6.4457e-03,  7.0820e-03,  7.3993e-03, -5.5535e-03,\n",
       "                      -1.5902e-02,  2.0442e-02,  2.5495e-02,  8.2982e-03, -6.9265e-05,\n",
       "                      -5.7615e-03,  1.3359e-02,  3.3584e-02,  2.5816e-03, -1.1885e-02,\n",
       "                       3.3497e-02, -3.2721e-02,  2.8629e-02,  2.5869e-02, -1.6299e-02,\n",
       "                       3.7483e-02,  1.4549e-02,  2.3700e-02, -4.2155e-02, -1.1442e-02,\n",
       "                      -7.3580e-03, -1.3953e-02,  8.7393e-03,  2.0353e-02, -4.1951e-02,\n",
       "                      -2.2231e-02,  4.1257e-03,  2.4596e-02, -1.2438e-02, -2.4161e-03,\n",
       "                       1.7183e-02,  4.4057e-02, -2.0181e-02,  2.7658e-02,  1.1725e-02,\n",
       "                      -3.9236e-03,  1.5949e-02,  7.7809e-03, -7.1981e-03, -2.8853e-03,\n",
       "                       3.4719e-02, -2.4955e-02, -4.5618e-02,  1.4613e-02,  3.6820e-03,\n",
       "                      -1.4702e-02,  1.0769e-02, -1.6211e-02, -2.8165e-02, -9.0409e-03,\n",
       "                       8.5562e-03,  1.3370e-03, -8.4851e-03,  4.0729e-03, -6.0060e-04,\n",
       "                       2.5061e-02,  9.6954e-03,  3.2545e-02, -2.8431e-02, -5.7002e-03,\n",
       "                      -8.1000e-03,  1.1063e-02, -1.8442e-02, -8.0574e-03, -3.5015e-02,\n",
       "                      -6.4355e-03,  2.3538e-02, -3.2557e-02,  2.4334e-02,  2.7615e-02,\n",
       "                       4.2601e-03,  2.5095e-02,  2.5526e-03,  4.5179e-02, -9.8201e-03,\n",
       "                      -1.4444e-03, -1.4687e-02, -2.1632e-03, -2.2417e-02,  2.0639e-02,\n",
       "                       9.4485e-03, -3.1384e-02, -2.5661e-02,  1.6095e-02,  2.3815e-02,\n",
       "                      -1.7551e-02, -1.8933e-02,  6.2022e-03, -1.3550e-02, -5.9153e-03,\n",
       "                      -9.8197e-03, -6.7901e-03,  7.0709e-03,  1.3988e-02, -8.2902e-03,\n",
       "                      -6.3798e-02, -3.8930e-02,  2.9685e-02,  3.0872e-02, -3.4989e-02,\n",
       "                       1.9558e-02, -1.4918e-02, -1.4135e-03, -2.8679e-02,  2.5363e-02,\n",
       "                      -2.0541e-02, -2.1873e-02, -2.4322e-02, -2.5626e-02, -2.7475e-03,\n",
       "                       7.1819e-03, -1.7588e-02,  4.5982e-02,  2.8894e-02,  8.7051e-03,\n",
       "                      -1.5519e-04, -5.6310e-03, -1.1426e-02, -2.7057e-02,  3.0933e-02,\n",
       "                       1.3874e-02, -3.2625e-02,  8.7762e-03, -2.6140e-02, -6.8621e-03,\n",
       "                       2.2427e-02,  1.3844e-02,  8.2845e-03, -2.8462e-02, -1.6707e-02,\n",
       "                       3.2023e-02,  5.9622e-03,  3.7336e-03,  3.5266e-02, -6.6610e-03,\n",
       "                      -1.7954e-03,  2.4953e-02, -2.5323e-02, -2.5117e-02, -3.1561e-02,\n",
       "                      -3.3506e-03,  1.7620e-03,  1.0391e-02, -1.7165e-02, -3.9665e-02,\n",
       "                       2.8820e-02,  2.1611e-02,  2.4824e-02,  1.5031e-02,  5.1651e-02,\n",
       "                      -2.5134e-02, -3.7899e-02,  2.2872e-02,  1.1202e-03,  1.9690e-02,\n",
       "                      -4.3514e-02, -4.7982e-04, -2.4483e-02, -2.2415e-02,  2.4467e-02,\n",
       "                       9.4777e-03,  5.2452e-03,  1.8599e-02,  6.6124e-03,  1.7485e-02,\n",
       "                       9.7349e-03, -2.2278e-02, -5.5351e-02,  2.5456e-02,  4.2840e-02,\n",
       "                      -3.0691e-03, -1.6743e-02,  1.6031e-02,  6.3012e-03, -1.5451e-02,\n",
       "                       1.9332e-02, -2.4415e-02, -2.0249e-02,  2.5495e-02,  1.9663e-03,\n",
       "                       1.3129e-03,  2.7073e-03, -1.8574e-02, -1.1699e-02, -5.8318e-04,\n",
       "                      -8.8321e-03, -5.2074e-03,  3.1855e-02, -3.8087e-02,  2.4357e-03,\n",
       "                       1.3589e-02, -1.1128e-02, -2.6752e-02, -2.0599e-02, -1.6687e-02,\n",
       "                       3.2020e-02, -2.1787e-02,  2.1219e-02, -1.6045e-02,  2.6517e-02,\n",
       "                       2.1466e-03,  8.1642e-03,  1.8098e-02, -5.5263e-03,  1.4933e-02,\n",
       "                      -3.5428e-02, -3.9287e-02, -8.3259e-03,  1.5583e-02, -3.7982e-02,\n",
       "                      -7.3816e-03, -1.5433e-03, -8.4590e-03,  2.6630e-03, -4.4610e-03,\n",
       "                      -2.3142e-02, -2.9296e-02, -3.6809e-02,  1.0009e-02, -1.6237e-03,\n",
       "                       1.1309e-02, -4.1621e-03, -2.2094e-02, -1.6962e-02, -5.1850e-04,\n",
       "                       2.0608e-02, -1.1367e-02,  4.9458e-03, -3.0945e-02,  6.6623e-03,\n",
       "                      -7.0852e-03,  1.6713e-02,  3.2852e-03,  3.9748e-02,  7.5228e-03,\n",
       "                      -2.7706e-02, -1.5055e-02,  8.2618e-03, -3.5250e-03,  2.8512e-02,\n",
       "                      -2.8373e-02,  2.6081e-02,  1.1161e-03, -5.2753e-02, -1.9716e-02,\n",
       "                       8.0669e-03, -2.1299e-02,  2.4520e-02, -3.3831e-02, -1.1310e-03,\n",
       "                       3.4126e-02, -3.2344e-03,  2.5434e-03,  4.4967e-02,  2.0311e-03,\n",
       "                       3.1839e-02,  2.8957e-02,  2.5171e-02,  2.3116e-02,  1.0331e-02,\n",
       "                       5.1576e-03,  9.8236e-03,  5.0942e-02,  3.7947e-02,  1.7407e-02,\n",
       "                      -2.0472e-02,  2.5566e-03,  1.9790e-02, -6.8368e-03, -2.0698e-02,\n",
       "                      -2.7212e-02, -5.9066e-02,  4.0653e-02, -2.1565e-04,  4.7876e-02,\n",
       "                      -6.8482e-03,  1.3924e-03,  2.7570e-02,  1.8728e-02, -2.4210e-02,\n",
       "                      -2.5790e-02, -4.0975e-02])),\n",
       "             ('conv_block5.4.running_var',\n",
       "              tensor([0.9124, 0.9126, 0.9168, 0.9129, 0.9226, 0.9135, 0.9188, 0.9204, 0.9157,\n",
       "                      0.9150, 0.9181, 0.9258, 0.9146, 0.9199, 0.9359, 0.9123, 0.9214, 0.9108,\n",
       "                      0.9181, 0.9116, 0.9103, 0.9195, 0.9136, 0.9160, 0.9135, 0.9171, 0.9174,\n",
       "                      0.9104, 0.9215, 0.9132, 0.9147, 0.9129, 0.9146, 0.9143, 0.9172, 0.9263,\n",
       "                      0.9163, 0.9188, 0.9266, 0.9090, 0.9102, 0.9136, 0.9242, 0.9101, 0.9129,\n",
       "                      0.9215, 0.9155, 0.9204, 0.9182, 0.9129, 0.9133, 0.9112, 0.9166, 0.9129,\n",
       "                      0.9221, 0.9132, 0.9134, 0.9204, 0.9116, 0.9115, 0.9233, 0.9125, 0.9153,\n",
       "                      0.9124, 0.9207, 0.9167, 0.9211, 0.9208, 0.9131, 0.9281, 0.9230, 0.9133,\n",
       "                      0.9123, 0.9195, 0.9175, 0.9162, 0.9173, 0.9138, 0.9169, 0.9159, 0.9355,\n",
       "                      0.9151, 0.9145, 0.9128, 0.9155, 0.9327, 0.9165, 0.9175, 0.9152, 0.9141,\n",
       "                      0.9169, 0.9130, 0.9194, 0.9122, 0.9150, 0.9085, 0.9216, 0.9141, 0.9104,\n",
       "                      0.9174, 0.9176, 0.9156, 0.9241, 0.9126, 0.9139, 0.9163, 0.9115, 0.9136,\n",
       "                      0.9102, 0.9148, 0.9317, 0.9134, 0.9158, 0.9116, 0.9096, 0.9269, 0.9132,\n",
       "                      0.9110, 0.9155, 0.9212, 0.9180, 0.9111, 0.9265, 0.9120, 0.9119, 0.9159,\n",
       "                      0.9147, 0.9208, 0.9094, 0.9229, 0.9148, 0.9158, 0.9169, 0.9234, 0.9112,\n",
       "                      0.9129, 0.9267, 0.9209, 0.9171, 0.9182, 0.9142, 0.9154, 0.9204, 0.9116,\n",
       "                      0.9153, 0.9317, 0.9143, 0.9133, 0.9126, 0.9155, 0.9159, 0.9126, 0.9279,\n",
       "                      0.9139, 0.9197, 0.9372, 0.9118, 0.9233, 0.9171, 0.9089, 0.9297, 0.9166,\n",
       "                      0.9111, 0.9150, 0.9153, 0.9136, 0.9223, 0.9167, 0.9174, 0.9192, 0.9336,\n",
       "                      0.9195, 0.9170, 0.9127, 0.9314, 0.9136, 0.9190, 0.9095, 0.9116, 0.9208,\n",
       "                      0.9173, 0.9138, 0.9128, 0.9189, 0.9263, 0.9171, 0.9104, 0.9087, 0.9087,\n",
       "                      0.9201, 0.9139, 0.9197, 0.9254, 0.9132, 0.9264, 0.9109, 0.9167, 0.9129,\n",
       "                      0.9283, 0.9115, 0.9321, 0.9107, 0.9107, 0.9246, 0.9148, 0.9154, 0.9082,\n",
       "                      0.9136, 0.9146, 0.9137, 0.9074, 0.9145, 0.9163, 0.9172, 0.9164, 0.9150,\n",
       "                      0.9175, 0.9171, 0.9219, 0.9321, 0.9232, 0.9117, 0.9143, 0.9206, 0.9125,\n",
       "                      0.9134, 0.9150, 0.9153, 0.9287, 0.9269, 0.9208, 0.9145, 0.9118, 0.9092,\n",
       "                      0.9238, 0.9300, 0.9163, 0.9283, 0.9167, 0.9143, 0.9225, 0.9272, 0.9172,\n",
       "                      0.9135, 0.9169, 0.9122, 0.9136, 0.9295, 0.9213, 0.9313, 0.9146, 0.9241,\n",
       "                      0.9145, 0.9253, 0.9191, 0.9177, 0.9168, 0.9141, 0.9181, 0.9234, 0.9117,\n",
       "                      0.9111, 0.9122, 0.9149, 0.9172, 0.9137, 0.9244, 0.9215, 0.9149, 0.9143,\n",
       "                      0.9243, 0.9140, 0.9174, 0.9169, 0.9353, 0.9134, 0.9106, 0.9165, 0.9123,\n",
       "                      0.9281, 0.9303, 0.9123, 0.9159, 0.9152, 0.9265, 0.9191, 0.9161, 0.9227,\n",
       "                      0.9189, 0.9216, 0.9163, 0.9311, 0.9181, 0.9237, 0.9209, 0.9183, 0.9140,\n",
       "                      0.9197, 0.9354, 0.9148, 0.9174, 0.9166, 0.9145, 0.9197, 0.9203, 0.9148,\n",
       "                      0.9210, 0.9118, 0.9179, 0.9218, 0.9177, 0.9213, 0.9291, 0.9139, 0.9242,\n",
       "                      0.9147, 0.9128, 0.9104, 0.9229, 0.9299, 0.9139, 0.9367, 0.9152, 0.9264,\n",
       "                      0.9160, 0.9173, 0.9141, 0.9240, 0.9142, 0.9343, 0.9143, 0.9077, 0.9134,\n",
       "                      0.9145, 0.9131, 0.9124, 0.9121, 0.9328, 0.9143, 0.9200, 0.9132, 0.9091,\n",
       "                      0.9091, 0.9104, 0.9279, 0.9183, 0.9175, 0.9125, 0.9132, 0.9232, 0.9223,\n",
       "                      0.9175, 0.9102, 0.9175, 0.9141, 0.9150, 0.9148, 0.9195, 0.9227, 0.9234,\n",
       "                      0.9242, 0.9172, 0.9113, 0.9304, 0.9255, 0.9171, 0.9188, 0.9348, 0.9138,\n",
       "                      0.9145, 0.9199, 0.9125, 0.9245, 0.9185, 0.9127, 0.9124, 0.9257, 0.9191,\n",
       "                      0.9091, 0.9283, 0.9343, 0.9214, 0.9373, 0.9173, 0.9138, 0.9171, 0.9176,\n",
       "                      0.9100, 0.9167, 0.9311, 0.9148, 0.9143, 0.9189, 0.9105, 0.9137, 0.9082,\n",
       "                      0.9207, 0.9277, 0.9115, 0.9221, 0.9111, 0.9140, 0.9086, 0.9173, 0.9140,\n",
       "                      0.9316, 0.9126, 0.9111, 0.9153, 0.9159, 0.9131, 0.9160, 0.9202, 0.9196,\n",
       "                      0.9157, 0.9206, 0.9089, 0.9362, 0.9197, 0.9334, 0.9103, 0.9156, 0.9142,\n",
       "                      0.9207, 0.9224, 0.9174, 0.9187, 0.9145, 0.9114, 0.9207, 0.9269, 0.9180,\n",
       "                      0.9231, 0.9271, 0.9193, 0.9120, 0.9146, 0.9157, 0.9181, 0.9130, 0.9135,\n",
       "                      0.9183, 0.9263, 0.9167, 0.9265, 0.9212, 0.9279, 0.9231, 0.9124, 0.9225,\n",
       "                      0.9103, 0.9119, 0.9141, 0.9139, 0.9137, 0.9229, 0.9200, 0.9109, 0.9096,\n",
       "                      0.9250, 0.9173, 0.9145, 0.9094, 0.9220, 0.9258, 0.9180, 0.9167, 0.9220,\n",
       "                      0.9294, 0.9156, 0.9254, 0.9304, 0.9148, 0.9227, 0.9108, 0.9154, 0.9249,\n",
       "                      0.9152, 0.9150, 0.9199, 0.9109, 0.9211, 0.9086, 0.9178, 0.9139, 0.9194,\n",
       "                      0.9251, 0.9224, 0.9158, 0.9190, 0.9079, 0.9132, 0.9104, 0.9165, 0.9139,\n",
       "                      0.9174, 0.9229, 0.9237, 0.9341, 0.9251, 0.9258, 0.9126, 0.9142, 0.9151,\n",
       "                      0.9321, 0.9188, 0.9247, 0.9164, 0.9218, 0.9147, 0.9123, 0.9139])),\n",
       "             ('conv_block5.4.num_batches_tracked', tensor(1)),\n",
       "             ('classifier.0.weight',\n",
       "              tensor([[ 0.0172,  0.0156, -0.0256,  ...,  0.0295, -0.0070, -0.0160],\n",
       "                      [ 0.0265,  0.0017,  0.0069,  ..., -0.0243,  0.0210,  0.0006],\n",
       "                      [-0.0314, -0.0062,  0.0091,  ..., -0.0068, -0.0171, -0.0229],\n",
       "                      ...,\n",
       "                      [-0.0037,  0.0143, -0.0101,  ..., -0.0044, -0.0068, -0.0111],\n",
       "                      [-0.0109, -0.0070, -0.0231,  ...,  0.0062,  0.0321,  0.0027],\n",
       "                      [-0.0260,  0.0070,  0.0098,  ...,  0.0349,  0.0351,  0.0283]])),\n",
       "             ('classifier.0.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('classifier.3.weight',\n",
       "              tensor([[ 1.8711e-02,  9.5680e-03, -2.3796e-02,  ...,  1.7804e-02,\n",
       "                        2.0139e-02,  2.8861e-02],\n",
       "                      [ 1.9293e-02,  1.6454e-05,  1.9991e-04,  ..., -7.8670e-03,\n",
       "                        3.2975e-02, -2.4140e-02],\n",
       "                      [ 2.3894e-02,  1.3408e-02, -9.0890e-03,  ..., -7.4453e-03,\n",
       "                        2.3821e-02, -2.7666e-02],\n",
       "                      ...,\n",
       "                      [-2.1776e-02, -1.0501e-02,  1.4254e-02,  ..., -6.8980e-03,\n",
       "                       -1.6437e-02, -3.1440e-02],\n",
       "                      [-1.8703e-02, -2.4412e-02,  4.6053e-03,  ...,  4.0376e-03,\n",
       "                       -1.6360e-02, -2.9672e-02],\n",
       "                      [-2.8015e-02,  1.2919e-02,  1.7766e-02,  ..., -1.0790e-02,\n",
       "                       -2.2162e-02,  3.2795e-02]])),\n",
       "             ('classifier.3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('classifier.6.weight',\n",
       "              tensor([[ 0.0324,  0.0081,  0.0587,  ...,  0.0203, -0.0591,  0.0539],\n",
       "                      [ 0.0255,  0.0158,  0.0003,  ..., -0.0378, -0.0647, -0.0028],\n",
       "                      [ 0.0163,  0.0270, -0.0532,  ...,  0.0695, -0.0475, -0.0497],\n",
       "                      ...,\n",
       "                      [ 0.0195, -0.0219, -0.0280,  ...,  0.0196,  0.0738,  0.0651],\n",
       "                      [-0.0714,  0.0597, -0.0244,  ..., -0.0587,  0.0320, -0.0458],\n",
       "                      [ 0.0752,  0.0110,  0.0554,  ...,  0.0085, -0.0733,  0.0465]])),\n",
       "             ('classifier.6.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHD02aNt4pNv"
   },
   "source": [
    "# 设置交叉熵损失函数，SGD优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:40.023837Z",
     "start_time": "2025-06-26T01:43:40.019952Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1dvP3ES4pNv",
    "outputId": "33b3ef26-6882-495f-9178-037f4fa2219c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "损失函数: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "model = VGG11()\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数，适用于多分类问题，里边会做softmax，还有会把0-9标签转换成one-hot编码\n",
    "\n",
    "print(\"损失函数:\", loss_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:40.035848Z",
     "start_time": "2025-06-26T01:43:40.032419Z"
    },
    "id": "qUeLZMIE4pNv"
   },
   "outputs": [],
   "source": [
    "model = VGG11()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD优化器，学习率为0.01，动量为0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.732814Z",
     "start_time": "2025-06-26T01:43:40.035848Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "25bd95d2a82c40cda3330cac74a92867",
      "1a7c80aa96ea47eaaf67d55a1a085633",
      "fa45c725ec844a33aa098bcd2e1032a1",
      "5bd7296677c54aac9d68890f6b76491b",
      "e3018869c1dd4423859a0c00ebfbdcbf",
      "395cc401ad794129be84af9f104988b0",
      "77a32c33ca054b66b6cd5e4fe0f3f911",
      "af5ac60e75804fa099bc9862a3d70075",
      "c72d1baf1bef46178177265f9afe0668",
      "bc45a93013c74b9fa2a29654ccf7f624",
      "cf8c5b248c36412babbbbd0539936d4d"
     ]
    },
    "id": "qI1L-GG94pNv",
    "outputId": "69f0b31f-93f6-4a4f-a19f-7b929303bb75"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "使用设备: cuda:0\n",
      "训练开始，共35200步\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/35200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25bd95d2a82c40cda3330cac74a92867"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "早停触发! 最佳验证准确率(如果是回归，这里是损失): 76.0800\n",
      "早停: 在7500 步\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "model = model.to(device) #将模型移动到GPU\n",
    "early_stopping=EarlyStopping(patience=5, delta=0.001)\n",
    "model_saver=ModelSaver(save_dir='model_weights', save_best_only=True)\n",
    "\n",
    "\n",
    "model, history = train_classification_model(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=50, early_stopping=early_stopping, model_saver=model_saver, tensorboard_logger=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.737721Z",
     "start_time": "2025-06-26T01:45:37.732814Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJWn5FRH4pNv",
    "outputId": "25a92d37-5bf7-4b45-d59c-b20432f64bce"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'loss': 0.1581640988588333, 'acc': 95.3125, 'step': 7401},\n",
       " {'loss': 0.1815609335899353, 'acc': 93.75, 'step': 7402},\n",
       " {'loss': 0.3434261083602905, 'acc': 93.75, 'step': 7403},\n",
       " {'loss': 0.19070330262184143, 'acc': 92.1875, 'step': 7404},\n",
       " {'loss': 0.23076124489307404, 'acc': 90.625, 'step': 7405},\n",
       " {'loss': 0.19382242858409882, 'acc': 93.75, 'step': 7406},\n",
       " {'loss': 0.13341301679611206, 'acc': 95.3125, 'step': 7407},\n",
       " {'loss': 0.05523664131760597, 'acc': 96.875, 'step': 7408},\n",
       " {'loss': 0.0980837345123291, 'acc': 96.875, 'step': 7409},\n",
       " {'loss': 0.1835782378911972, 'acc': 92.1875, 'step': 7410},\n",
       " {'loss': 0.14559414982795715, 'acc': 95.3125, 'step': 7411},\n",
       " {'loss': 0.10001371055841446, 'acc': 93.75, 'step': 7412},\n",
       " {'loss': 0.1001870185136795, 'acc': 95.3125, 'step': 7413},\n",
       " {'loss': 0.21991638839244843, 'acc': 95.3125, 'step': 7414},\n",
       " {'loss': 0.07408258318901062, 'acc': 96.875, 'step': 7415},\n",
       " {'loss': 0.15189488232135773, 'acc': 95.3125, 'step': 7416},\n",
       " {'loss': 0.23960858583450317, 'acc': 90.625, 'step': 7417},\n",
       " {'loss': 0.2038527876138687, 'acc': 95.3125, 'step': 7418},\n",
       " {'loss': 0.11004413664340973, 'acc': 96.875, 'step': 7419},\n",
       " {'loss': 0.12419925630092621, 'acc': 95.3125, 'step': 7420},\n",
       " {'loss': 0.06084173917770386, 'acc': 98.4375, 'step': 7421},\n",
       " {'loss': 0.16544441878795624, 'acc': 93.75, 'step': 7422},\n",
       " {'loss': 0.09975125640630722, 'acc': 96.875, 'step': 7423},\n",
       " {'loss': 0.19716723263263702, 'acc': 93.75, 'step': 7424},\n",
       " {'loss': 0.10651788115501404, 'acc': 95.3125, 'step': 7425},\n",
       " {'loss': 0.16348224878311157, 'acc': 93.75, 'step': 7426},\n",
       " {'loss': 0.1153232529759407, 'acc': 95.3125, 'step': 7427},\n",
       " {'loss': 0.13554981350898743, 'acc': 92.1875, 'step': 7428},\n",
       " {'loss': 0.06754171848297119, 'acc': 98.4375, 'step': 7429},\n",
       " {'loss': 0.17553764581680298, 'acc': 93.75, 'step': 7430},\n",
       " {'loss': 0.2021622210741043, 'acc': 93.75, 'step': 7431},\n",
       " {'loss': 0.07455755025148392, 'acc': 96.875, 'step': 7432},\n",
       " {'loss': 0.05347217619419098, 'acc': 98.4375, 'step': 7433},\n",
       " {'loss': 0.19667908549308777, 'acc': 93.75, 'step': 7434},\n",
       " {'loss': 0.21742641925811768, 'acc': 92.1875, 'step': 7435},\n",
       " {'loss': 0.11329364031553268, 'acc': 95.3125, 'step': 7436},\n",
       " {'loss': 0.07504083961248398, 'acc': 98.4375, 'step': 7437},\n",
       " {'loss': 0.08965212106704712, 'acc': 98.4375, 'step': 7438},\n",
       " {'loss': 0.04615804925560951, 'acc': 98.4375, 'step': 7439},\n",
       " {'loss': 0.05782551318407059, 'acc': 100.0, 'step': 7440},\n",
       " {'loss': 0.09785313159227371, 'acc': 98.4375, 'step': 7441},\n",
       " {'loss': 0.08007577806711197, 'acc': 95.3125, 'step': 7442},\n",
       " {'loss': 0.13216125965118408, 'acc': 95.3125, 'step': 7443},\n",
       " {'loss': 0.19109539687633514, 'acc': 90.625, 'step': 7444},\n",
       " {'loss': 0.11117089539766312, 'acc': 96.875, 'step': 7445},\n",
       " {'loss': 0.07964222878217697, 'acc': 96.875, 'step': 7446},\n",
       " {'loss': 0.19351443648338318, 'acc': 92.1875, 'step': 7447},\n",
       " {'loss': 0.154947891831398, 'acc': 93.75, 'step': 7448},\n",
       " {'loss': 0.10270154476165771, 'acc': 95.3125, 'step': 7449},\n",
       " {'loss': 0.09321065247058868, 'acc': 96.875, 'step': 7450},\n",
       " {'loss': 0.11258413642644882, 'acc': 96.875, 'step': 7451},\n",
       " {'loss': 0.14154818654060364, 'acc': 96.875, 'step': 7452},\n",
       " {'loss': 0.18393205106258392, 'acc': 92.1875, 'step': 7453},\n",
       " {'loss': 0.20973007380962372, 'acc': 95.3125, 'step': 7454},\n",
       " {'loss': 0.06475617736577988, 'acc': 96.875, 'step': 7455},\n",
       " {'loss': 0.22510263323783875, 'acc': 92.1875, 'step': 7456},\n",
       " {'loss': 0.16907110810279846, 'acc': 92.1875, 'step': 7457},\n",
       " {'loss': 0.08582128584384918, 'acc': 98.4375, 'step': 7458},\n",
       " {'loss': 0.15314994752407074, 'acc': 95.3125, 'step': 7459},\n",
       " {'loss': 0.16326551139354706, 'acc': 95.3125, 'step': 7460},\n",
       " {'loss': 0.07548869401216507, 'acc': 96.875, 'step': 7461},\n",
       " {'loss': 0.09366486221551895, 'acc': 96.875, 'step': 7462},\n",
       " {'loss': 0.1343919336795807, 'acc': 93.75, 'step': 7463},\n",
       " {'loss': 0.06220382824540138, 'acc': 98.4375, 'step': 7464},\n",
       " {'loss': 0.05613301694393158, 'acc': 98.4375, 'step': 7465},\n",
       " {'loss': 0.16383786499500275, 'acc': 96.875, 'step': 7466},\n",
       " {'loss': 0.15126027166843414, 'acc': 92.1875, 'step': 7467},\n",
       " {'loss': 0.1100856363773346, 'acc': 95.3125, 'step': 7468},\n",
       " {'loss': 0.23151163756847382, 'acc': 93.75, 'step': 7469},\n",
       " {'loss': 0.14359994232654572, 'acc': 95.3125, 'step': 7470},\n",
       " {'loss': 0.14320674538612366, 'acc': 95.3125, 'step': 7471},\n",
       " {'loss': 0.05076632648706436, 'acc': 98.4375, 'step': 7472},\n",
       " {'loss': 0.09156616032123566, 'acc': 96.875, 'step': 7473},\n",
       " {'loss': 0.28097403049468994, 'acc': 92.1875, 'step': 7474},\n",
       " {'loss': 0.034090764820575714, 'acc': 98.4375, 'step': 7475},\n",
       " {'loss': 0.09425172209739685, 'acc': 98.4375, 'step': 7476},\n",
       " {'loss': 0.22199711203575134, 'acc': 96.875, 'step': 7477},\n",
       " {'loss': 0.14491549134254456, 'acc': 95.3125, 'step': 7478},\n",
       " {'loss': 0.10894811153411865, 'acc': 95.3125, 'step': 7479},\n",
       " {'loss': 0.21340951323509216, 'acc': 92.1875, 'step': 7480},\n",
       " {'loss': 0.09643111377954483, 'acc': 95.3125, 'step': 7481},\n",
       " {'loss': 0.0683811828494072, 'acc': 98.4375, 'step': 7482},\n",
       " {'loss': 0.16555671393871307, 'acc': 92.1875, 'step': 7483},\n",
       " {'loss': 0.14704078435897827, 'acc': 95.3125, 'step': 7484},\n",
       " {'loss': 0.06283339858055115, 'acc': 98.4375, 'step': 7485},\n",
       " {'loss': 0.19488097727298737, 'acc': 90.625, 'step': 7486},\n",
       " {'loss': 0.13065387308597565, 'acc': 96.875, 'step': 7487},\n",
       " {'loss': 0.10647814720869064, 'acc': 95.3125, 'step': 7488},\n",
       " {'loss': 0.08186698704957962, 'acc': 95.3125, 'step': 7489},\n",
       " {'loss': 0.0995498076081276, 'acc': 96.875, 'step': 7490},\n",
       " {'loss': 0.16413481533527374, 'acc': 93.75, 'step': 7491},\n",
       " {'loss': 0.5259186029434204, 'acc': 87.5, 'step': 7492},\n",
       " {'loss': 0.0995110347867012, 'acc': 96.875, 'step': 7493},\n",
       " {'loss': 0.21175606548786163, 'acc': 93.75, 'step': 7494},\n",
       " {'loss': 0.12175413966178894, 'acc': 95.3125, 'step': 7495},\n",
       " {'loss': 0.27960413694381714, 'acc': 95.3125, 'step': 7496},\n",
       " {'loss': 0.15506713092327118, 'acc': 95.3125, 'step': 7497},\n",
       " {'loss': 0.13715092837810516, 'acc': 95.3125, 'step': 7498},\n",
       " {'loss': 0.1494683474302292, 'acc': 96.875, 'step': 7499}]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "history['train'][-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.741226Z",
     "start_time": "2025-06-26T01:45:37.737721Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMjJdQ2l4pNw",
    "outputId": "6491d7d7-7b76-4f66-ab44-17114655a056"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'loss': 2.302569165802002, 'acc': 12.42, 'step': 0},\n",
       " {'loss': 1.240722024822235, 'acc': 54.76, 'step': 500},\n",
       " {'loss': 1.1365008723258971, 'acc': 58.58, 'step': 1000},\n",
       " {'loss': 0.8875749093055725, 'acc': 68.02, 'step': 1500},\n",
       " {'loss': 0.8608326288223267, 'acc': 68.52, 'step': 2000},\n",
       " {'loss': 0.7840539800167083, 'acc': 72.52, 'step': 2500},\n",
       " {'loss': 0.9480287254333496, 'acc': 69.08, 'step': 3000},\n",
       " {'loss': 0.7200562836170197, 'acc': 74.82, 'step': 3500},\n",
       " {'loss': 0.8887430733680725, 'acc': 72.6, 'step': 4000},\n",
       " {'loss': 0.817792481994629, 'acc': 74.34, 'step': 4500},\n",
       " {'loss': 0.7889971607208252, 'acc': 76.08, 'step': 5000},\n",
       " {'loss': 0.8979752167701721, 'acc': 73.82, 'step': 5500},\n",
       " {'loss': 1.0152926279067993, 'acc': 73.68, 'step': 6000},\n",
       " {'loss': 0.9711365780591965, 'acc': 74.82, 'step': 6500},\n",
       " {'loss': 0.9632359601020813, 'acc': 75.08, 'step': 7000}]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "history['val'][-1000:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcujMCRC4pNw"
   },
   "source": [
    "# 绘制损失曲线和准确率曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.816716Z",
     "start_time": "2025-06-26T01:45:37.744941Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "3xZ57j-C4pNw",
    "outputId": "a11ae02e-5abc-4427-e103-c5f0f20e39b8"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "plot_learning_curves(history, sample_step=500)  #横坐标是 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "e0JxP6FE9L8Y"
   },
   "outputs": [],
   "source": [
    "a =py7zr.SevenZipFile(r'./test.7z','r')\n",
    "a.extractall(path=r'./competitions/cifar-10/')\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSDxPyov9i-y",
    "outputId": "205dd4b9-b21c-4948-8d5a-717da434b27b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "!ls competitions/cifar-10/test|wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H39dl-23-cil",
    "outputId": "5e38cd59-5a1c-4a22-ffe3-0a146c76aeb5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "competitions   sample_data\t     trainLabels.csv\n",
      "kaggle.json    sampleSubmission.csv  wangdao_deeplearning_train.py\n",
      "model_weights  test.7z\n",
      "__pycache__    train.7z\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.818553Z",
     "start_time": "2025-06-26T01:45:37.816716Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yvx48aMb4pNw",
    "outputId": "5ee0fb32-2cab-4c1c-a7ce-bb68e551982a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正在预测测试集...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r预测进度:   0%|          | 0/2344 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "预测进度: 100%|██████████| 2344/2344 [01:53<00:00, 20.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id列是否有重复值: False\n",
      "预测完成，结果已保存至 cifar10_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 导入所需库\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import tqdm\n",
    "\n",
    "# 定义测试数据集类\n",
    "class CIFAR10TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化测试数据集\n",
    "\n",
    "        参数:\n",
    "            img_dir: 测试图片目录\n",
    "            transform: 图像预处理变换\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # 提取图像ID（文件名去掉扩展名）\n",
    "        img_id = int(os.path.splitext(self.img_files[idx])[0])\n",
    "\n",
    "        return image, img_id\n",
    "\n",
    "# 定义预测函数\n",
    "def predict_test_set(model, img_dir, labels_file, device, batch_size=64):\n",
    "    \"\"\"\n",
    "    预测测试集并生成提交文件\n",
    "\n",
    "    参数:\n",
    "        model: 训练好的模型\n",
    "        img_dir: 测试图片目录\n",
    "        labels_file: 提交模板文件路径\n",
    "        device: 计算设备\n",
    "        batch_size: 批处理大小\n",
    "    \"\"\"\n",
    "    # 图像预处理变换（与训练集相同）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4917, 0.4823, 0.4467), (0.2024, 0.1995, 0.2010))\n",
    "    ])\n",
    "\n",
    "    # 创建测试数据集和数据加载器\n",
    "    test_dataset = CIFAR10TestDataset(img_dir, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # 设置模型为评估模式\n",
    "    model.eval()\n",
    "\n",
    "    # 读取提交模板\n",
    "    submission_df = pd.read_csv(labels_file)\n",
    "    predictions = {}\n",
    "\n",
    "    # 使用tqdm显示进度条\n",
    "    print(\"正在预测测试集...\")\n",
    "    with torch.no_grad():\n",
    "        for images, img_ids in tqdm.tqdm(test_loader, desc=\"预测进度\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1) #取最大的索引，作为预测结果\n",
    "\n",
    "            # 记录每个图像的预测结果\n",
    "            for i, img_id in enumerate(img_ids):\n",
    "                predictions[img_id.item()] = predicted[i].item() #因为一个批次有多个图像，所以需要predicted[i]\n",
    "\n",
    "    # 定义类别名称\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    # 将数值标签转换为类别名称\n",
    "    labeled_predictions = {img_id: class_names[pred] for img_id, pred in predictions.items()}\n",
    "\n",
    "    # 直接创建DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': list(labeled_predictions.keys()),\n",
    "        'label': list(labeled_predictions.values())\n",
    "    })\n",
    "    # 按id列排序\n",
    "    submission_df = submission_df.sort_values(by='id')\n",
    "\n",
    "    # 检查id列是否有重复值\n",
    "    has_duplicates = submission_df['id'].duplicated().any()\n",
    "    print(f\"id列是否有重复值: {has_duplicates}\")\n",
    "    # 保存预测结果\n",
    "    output_file = 'cifar10_submission.csv'\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"预测完成，结果已保存至 {output_file}\")\n",
    "\n",
    "# 执行测试集预测\n",
    "img_dir = r\"competitions/cifar-10/test\"\n",
    "labels_file = r\"./sampleSubmission.csv\"\n",
    "predict_test_set(model, img_dir, labels_file, device, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f90sLQwP_o3I",
    "outputId": "f8590825-6e24-4f9e-eb4a-1bbfc8814fa8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id,label\n",
      "1,deer\n",
      "2,airplane\n",
      "3,automobile\n",
      "4,ship\n",
      "5,airplane\n",
      "6,cat\n",
      "7,airplane\n",
      "8,truck\n",
      "9,bird\n"
     ]
    }
   ],
   "source": [
    "!head -10 cifar10_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1w9Z1W-AOgY",
    "outputId": "2c30087f-960a-4223-c2ed-b73ad7f800fa"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300001 cifar10_submission.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l cifar10_submission.csv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "25bd95d2a82c40cda3330cac74a92867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a7c80aa96ea47eaaf67d55a1a085633",
       "IPY_MODEL_fa45c725ec844a33aa098bcd2e1032a1",
       "IPY_MODEL_5bd7296677c54aac9d68890f6b76491b"
      ],
      "layout": "IPY_MODEL_e3018869c1dd4423859a0c00ebfbdcbf"
     }
    },
    "1a7c80aa96ea47eaaf67d55a1a085633": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_395cc401ad794129be84af9f104988b0",
      "placeholder": "​",
      "style": "IPY_MODEL_77a32c33ca054b66b6cd5e4fe0f3f911",
      "value": " 21%"
     }
    },
    "fa45c725ec844a33aa098bcd2e1032a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af5ac60e75804fa099bc9862a3d70075",
      "max": 35200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c72d1baf1bef46178177265f9afe0668",
      "value": 7500
     }
    },
    "5bd7296677c54aac9d68890f6b76491b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc45a93013c74b9fa2a29654ccf7f624",
      "placeholder": "​",
      "style": "IPY_MODEL_cf8c5b248c36412babbbbd0539936d4d",
      "value": " 7500/35200 [06:41&lt;21:48, 21.17it/s, epoch=10, loss=0.1495, acc=96.88%]"
     }
    },
    "e3018869c1dd4423859a0c00ebfbdcbf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "395cc401ad794129be84af9f104988b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77a32c33ca054b66b6cd5e4fe0f3f911": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af5ac60e75804fa099bc9862a3d70075": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c72d1baf1bef46178177265f9afe0668": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bc45a93013c74b9fa2a29654ccf7f624": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf8c5b248c36412babbbbd0539936d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
