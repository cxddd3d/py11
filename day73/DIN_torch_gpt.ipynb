{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88827 entries, 0 to 88826\n",
      "Data columns (total 27 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   movieId                88827 non-null  int64  \n",
      " 1   userId                 88827 non-null  int64  \n",
      " 2   rating                 88827 non-null  float64\n",
      " 3   timestamp              88827 non-null  int64  \n",
      " 4   label                  88827 non-null  int64  \n",
      " 5   releaseYear            88827 non-null  int64  \n",
      " 6   movieGenre1            88827 non-null  object \n",
      " 7   movieGenre2            75109 non-null  object \n",
      " 8   movieGenre3            48071 non-null  object \n",
      " 9   movieRatingCount       88827 non-null  int64  \n",
      " 10  movieAvgRating         88827 non-null  float64\n",
      " 11  movieRatingStddev      88827 non-null  float64\n",
      " 12  userRatedMovie1        87600 non-null  float64\n",
      " 13  userRatedMovie2        84810 non-null  float64\n",
      " 14  userRatedMovie3        81027 non-null  float64\n",
      " 15  userRatedMovie4        77590 non-null  float64\n",
      " 16  userRatedMovie5        74372 non-null  float64\n",
      " 17  userRatingCount        88827 non-null  int64  \n",
      " 18  userAvgReleaseYear     88827 non-null  int64  \n",
      " 19  userReleaseYearStddev  88827 non-null  float64\n",
      " 20  userAvgRating          88827 non-null  float64\n",
      " 21  userRatingStddev       88827 non-null  float64\n",
      " 22  userGenre1             87600 non-null  object \n",
      " 23  userGenre2             87218 non-null  object \n",
      " 24  userGenre3             86245 non-null  object \n",
      " 25  userGenre4             84755 non-null  object \n",
      " 26  userGenre5             82524 non-null  object \n",
      "dtypes: float64(11), int64(8), object(8)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = pd.read_csv('./sampledata/trainingSamples.csv')\n",
    "data1.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T01:26:41.413986200Z",
     "start_time": "2024-08-21T01:26:39.961462700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-21T01:26:49.182109200Z",
     "start_time": "2024-08-21T01:26:41.410988300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 配置\n",
    "RECENT_MOVIES = 5  # userRatedMovie{1-5}, 最近看过的5部 喜欢的电影\n",
    "EMBEDDING_SIZE = 10\n",
    "\n",
    "\n",
    "def fill_missing_values(series):\n",
    "    # 如果列的数据类型为浮点型或整型，则填充0\n",
    "    if series.dtype == float or series.dtype == int:\n",
    "        return series.fillna(0)\n",
    "    # 如果列的数据类型为object（字符串），则填充字符串\"0\"\n",
    "    elif series.dtype == object:\n",
    "        return series.fillna(\"0\")\n",
    "    else:\n",
    "        return series\n",
    "\n",
    "\n",
    "# 数据集类\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        self.data = data.apply(fill_missing_values, axis=0)\n",
    "        self.label_encoder = LabelEncoder()  # 标签编码器\n",
    "        genre_cols = ['userGenre1', 'userGenre2', 'userGenre3', 'userGenre4', 'userGenre5',\n",
    "                      'movieGenre1', 'movieGenre2', 'movieGenre3']\n",
    "        for col in genre_cols:\n",
    "            self.data[col] = self.label_encoder.fit_transform(self.data[col].fillna('N/A'))  # 填充空值，并进行标签编码,剧情会转为id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        inputs = {col: torch.tensor(row[col], dtype=torch.float if 'Rating' in col or 'Stddev' in col else torch.long)\n",
    "                  for col in self.data.columns if col != 'label'}  #包含Rating、Stddev的列转为float，其余列转为long\n",
    "        label = torch.tensor(row['label'], dtype=torch.float)\n",
    "        return inputs, label\n",
    "\n",
    "\n",
    "# 数据加载器\n",
    "train_dataset = MovieDataset('./sampledata/trainingSamples.csv')\n",
    "test_dataset = MovieDataset('./sampledata/testSamples.csv')\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=12, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movieId': tensor([500,   5, 588, 153, 223, 799, 908, 353, 356, 350, 429,  21]), 'userId': tensor([16175,   900, 26809, 19044, 29499, 23452,  4801, 13732,  1723, 11254,\n",
      "        27473, 15478]), 'rating': tensor([3, 3, 2, 4, 4, 3, 4, 4, 3, 3, 2, 2]), 'timestamp': tensor([1076899799, 1101207229, 1155062848,  842517126, 1061184798, 1379656294,\n",
      "        1109133312,  884987876,  835521761,  923162819,  846347273, 1097824144]), 'releaseYear': tensor([1993, 1995, 1992, 1995, 1994, 1996, 1959, 1994, 1994, 1994, 1994, 1995]), 'movieGenre1': tensor([4, 4, 1, 0, 4, 4, 0, 0, 4, 7, 4, 4]), 'movieGenre2': tensor([ 7,  0,  2,  1,  0, 10,  1,  5,  7, 13,  0,  5]), 'movieGenre3': tensor([ 0,  0,  2,  3,  0, 13, 10,  6, 11, 13,  0, 13]), 'movieRatingCount': tensor([ 7349.,  2629.,  8980.,  7100.,  5102.,  1358.,  3429.,  3640., 14426.,\n",
      "         3475.,   320.,  5164.]), 'movieAvgRating': tensor([3.3900, 3.0600, 3.6700, 2.8900, 3.8600, 3.3700, 4.2300, 3.5000, 4.0300,\n",
      "        3.4800, 2.3300, 3.5800]), 'movieRatingStddev': tensor([0.9600, 0.9800, 0.9200, 0.9500, 0.9700, 0.9300, 0.7400, 1.0000, 0.9500,\n",
      "        0.8100, 1.1700, 0.9300]), 'userRatedMovie1': tensor([ 25, 357, 527, 150, 778, 898, 432, 531,  73, 292, 603,  45]), 'userRatedMovie2': tensor([661, 329,  50, 592, 147, 610,  16, 965, 314, 282, 849, 232]), 'userRatedMovie3': tensor([627, 588, 597, 380, 229,   0,   0, 380, 306, 371, 920, 904]), 'userRatedMovie4': tensor([705, 364, 504, 296, 194,   0,   0, 596, 308, 537, 648, 193]), 'userRatedMovie5': tensor([357, 780, 321,   0, 933,   0,   0, 955,  58,  46, 788, 154]), 'userRatingCount': tensor([ 70.,  38.,  90.,   6.,  72.,   3.,   3.,  55.,  47., 100., 100., 100.]), 'userAvgReleaseYear': tensor([1989, 1992, 1985, 1992, 1984, 1971, 1995, 1976, 1993, 1994, 1990, 1991]), 'userReleaseYearStddev': tensor([14.3100,  7.8300, 17.0900,  2.5000, 19.8000, 28.1800,  1.0000, 23.8000,\n",
      "         1.1900,  2.2000, 13.5600, 10.9800]), 'userAvgRating': tensor([3.4200, 3.8300, 3.1100, 3.6700, 3.3700, 3.5000, 3.0000, 4.1500, 2.3600,\n",
      "        3.7200, 3.2900, 2.3200]), 'userRatingStddev': tensor([1.0100, 0.7600, 1.1000, 0.5200, 1.1600, 0.5000, 1.3200, 1.0300, 1.1900,\n",
      "        0.8900, 0.6700, 1.0300]), 'userGenre1': tensor([ 8,  2,  8, 17,  8,  1,  2,  8,  8,  8,  5,  8]), 'userGenre2': tensor([17,  5,  5,  1,  5, 16, 19, 17,  5, 15,  8,  5]), 'userGenre3': tensor([ 6,  1, 17,  2,  1, 15,  6,  5, 15,  5, 15, 15]), 'userGenre4': tensor([ 5,  8,  6,  6, 16, 11,  8, 15, 17, 17, 17, 17]), 'userGenre5': tensor([15, 17, 15,  8, 17,  2,  5, 14, 14,  6,  2,  6])}\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for inputs, label in train_loader:\n",
    "    print(inputs)\n",
    "    print(label)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T01:26:49.280205400Z",
     "start_time": "2024-08-21T01:26:49.186108600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'movieId': tensor([500,   5, 588, 153, 223, 799, 908, 353, 356, 350, 429,  21]),\n 'userId': tensor([16175,   900, 26809, 19044, 29499, 23452,  4801, 13732,  1723, 11254,\n         27473, 15478]),\n 'rating': tensor([3, 3, 2, 4, 4, 3, 4, 4, 3, 3, 2, 2]),\n 'timestamp': tensor([1076899799, 1101207229, 1155062848,  842517126, 1061184798, 1379656294,\n         1109133312,  884987876,  835521761,  923162819,  846347273, 1097824144]),\n 'releaseYear': tensor([1993, 1995, 1992, 1995, 1994, 1996, 1959, 1994, 1994, 1994, 1994, 1995]),\n 'movieGenre1': tensor([4, 4, 1, 0, 4, 4, 0, 0, 4, 7, 4, 4]),\n 'movieGenre2': tensor([ 7,  0,  2,  1,  0, 10,  1,  5,  7, 13,  0,  5]),\n 'movieGenre3': tensor([ 0,  0,  2,  3,  0, 13, 10,  6, 11, 13,  0, 13]),\n 'movieRatingCount': tensor([ 7349.,  2629.,  8980.,  7100.,  5102.,  1358.,  3429.,  3640., 14426.,\n          3475.,   320.,  5164.]),\n 'movieAvgRating': tensor([3.3900, 3.0600, 3.6700, 2.8900, 3.8600, 3.3700, 4.2300, 3.5000, 4.0300,\n         3.4800, 2.3300, 3.5800]),\n 'movieRatingStddev': tensor([0.9600, 0.9800, 0.9200, 0.9500, 0.9700, 0.9300, 0.7400, 1.0000, 0.9500,\n         0.8100, 1.1700, 0.9300]),\n 'userRatedMovie1': tensor([ 25, 357, 527, 150, 778, 898, 432, 531,  73, 292, 603,  45]),\n 'userRatedMovie2': tensor([661, 329,  50, 592, 147, 610,  16, 965, 314, 282, 849, 232]),\n 'userRatedMovie3': tensor([627, 588, 597, 380, 229,   0,   0, 380, 306, 371, 920, 904]),\n 'userRatedMovie4': tensor([705, 364, 504, 296, 194,   0,   0, 596, 308, 537, 648, 193]),\n 'userRatedMovie5': tensor([357, 780, 321,   0, 933,   0,   0, 955,  58,  46, 788, 154]),\n 'userRatingCount': tensor([ 70.,  38.,  90.,   6.,  72.,   3.,   3.,  55.,  47., 100., 100., 100.]),\n 'userAvgReleaseYear': tensor([1989, 1992, 1985, 1992, 1984, 1971, 1995, 1976, 1993, 1994, 1990, 1991]),\n 'userReleaseYearStddev': tensor([14.3100,  7.8300, 17.0900,  2.5000, 19.8000, 28.1800,  1.0000, 23.8000,\n          1.1900,  2.2000, 13.5600, 10.9800]),\n 'userAvgRating': tensor([3.4200, 3.8300, 3.1100, 3.6700, 3.3700, 3.5000, 3.0000, 4.1500, 2.3600,\n         3.7200, 3.2900, 2.3200]),\n 'userRatingStddev': tensor([1.0100, 0.7600, 1.1000, 0.5200, 1.1600, 0.5000, 1.3200, 1.0300, 1.1900,\n         0.8900, 0.6700, 1.0300]),\n 'userGenre1': tensor([ 8,  2,  8, 17,  8,  1,  2,  8,  8,  8,  5,  8]),\n 'userGenre2': tensor([17,  5,  5,  1,  5, 16, 19, 17,  5, 15,  8,  5]),\n 'userGenre3': tensor([ 6,  1, 17,  2,  1, 15,  6,  5, 15,  5, 15, 15]),\n 'userGenre4': tensor([ 5,  8,  6,  6, 16, 11,  8, 15, 17, 17, 17, 17]),\n 'userGenre5': tensor([15, 17, 15,  8, 17,  2,  5, 14, 14,  6,  2,  6])}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T01:26:49.372402200Z",
     "start_time": "2024-08-21T01:26:49.279207200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1],\n        [2],\n        [3],\n        [4]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "torch.unsqueeze(x, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T01:26:49.393393Z",
     "start_time": "2024-08-21T01:26:49.302228200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent_items_emb.shape: torch.Size([12, 5, 10])\n",
      "activation_input.shape: torch.Size([12, 5, 40])\n",
      "activation_output.shape: torch.Size([12, 5])\n",
      "activation_output repeated.shape: torch.Size([12, 5, 10])\n",
      "activation_output.shape: torch.Size([12, 5, 10])\n",
      "user_behaviors_pooled.shape: torch.Size([12, 10])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# DIN模型类\n",
    "class DIN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_genres, embedding_dim):\n",
    "        super(DIN, self).__init__()\n",
    "        self.embedding_user = nn.Embedding(num_users, embedding_dim)  #30001*10\n",
    "        self.embedding_item = nn.Embedding(num_items, embedding_dim)  #1001*10\n",
    "        self.embedding_genre = nn.Embedding(num_genres, embedding_dim)  #20*10\n",
    "\n",
    "        self.user_profile = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2 + 3, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(64, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.context_features = nn.Sequential(\n",
    "            nn.Linear(embedding_dim + 4, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(64, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.activation_unit = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 4, 32),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 4, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        user_emb = self.embedding_user(inputs['userId']) #(batch_size, 1)-->(batch_size, embedding_dim)\n",
    "        user_genre_emb = self.embedding_genre(inputs['userGenre1']) # (batch_size, 1)-->(batch_size,embedding_dim)\n",
    "        # inputs['userRatingCount'],inputs['userAvgRating'], inputs['userRatingStddev']原本都是1维的，这里unsqueeze(1)变成2维的\n",
    "        user_profile_emb = torch.cat([user_emb, user_genre_emb, inputs['userRatingCount'].unsqueeze(1),\n",
    "                                      inputs['userAvgRating'].unsqueeze(1), inputs['userRatingStddev'].unsqueeze(1)],\n",
    "                                     axis=1)\n",
    "        # print(f'user_profile_emb.shape: {user_profile_emb.shape}') 值 [12, 23]\n",
    "        user_profile_emb = self.user_profile(user_profile_emb) #做全连接层处理\n",
    "\n",
    "        item_emb = self.embedding_item(inputs['movieId'])\n",
    "        item_genre_emb = self.embedding_genre(inputs['movieGenre1']) # (batch_size, 1)-->(batch_size,embedding_dim)\n",
    "        #context_features_emb输出形状为(batch_size, embedding_dim+4)\n",
    "        context_features_emb = torch.cat([item_genre_emb, inputs['releaseYear'].unsqueeze(1),\n",
    "                                          inputs['movieRatingCount'].unsqueeze(1),\n",
    "                                          inputs['movieAvgRating'].unsqueeze(1),\n",
    "                                          inputs['movieRatingStddev'].unsqueeze(1)], axis=1)\n",
    "        context_features_emb = self.context_features(context_features_emb)\n",
    "\n",
    "        recent_items_emb = torch.stack(\n",
    "            [self.embedding_item(inputs[f'userRatedMovie{i}']) for i in range(1, RECENT_MOVIES + 1)], dim=1)\n",
    "        print(f'recent_items_emb.shape: {recent_items_emb.shape}') #值 [12, 5, 10]\n",
    "        repeated_item_emb = item_emb.unsqueeze(1).repeat(1, RECENT_MOVIES,\n",
    "                                                         1)  #重复item_emb，5次形状为(batch_size, recent_movies, embedding_dim)\n",
    "\n",
    "        activation_sub = recent_items_emb - recent_items_emb\n",
    "        activation_product = recent_items_emb * repeated_item_emb  #每一个评分电影的embedding与最近的5个用户行为的embedding的相乘\n",
    "        activation_input = torch.cat([activation_sub, recent_items_emb, repeated_item_emb, activation_product],\n",
    "                                     dim=-1)  #相减，各自，相乘，进行拼接\n",
    "        print(f'activation_input.shape: {activation_input.shape}')\n",
    "        activation_output = self.activation_unit(activation_input).squeeze(-1)  #激活函数输出，形状为(batch_size, recent_movies)\n",
    "        print(f'activation_output.shape: {activation_output.shape}')\n",
    "        activation_output = activation_output.unsqueeze(-1).repeat(1, 1, EMBEDDING_SIZE)\n",
    "        print(f'activation_output repeated.shape: {activation_output.shape}')\n",
    "        activation_output = activation_output * recent_items_emb\n",
    "        print(f'activation_output.shape: {activation_output.shape}')\n",
    "        user_behaviors_pooled = torch.sum(activation_output, dim=1)\n",
    "        print(f'user_behaviors_pooled.shape: {user_behaviors_pooled.shape}')\n",
    "        #4个分别是 用户属性特征（user_profile_emb）、用户行为特征（user_behaviors_pooled）、候选广告特征（item_emb）和场景特征（context_features_emb）。\n",
    "        concat_input = torch.cat([user_profile_emb, user_behaviors_pooled, item_emb, context_features_emb],\n",
    "                                 axis=-1)  #每一个都是长度为10的密集向量\n",
    "        output = self.output_layer(concat_input)\n",
    "\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "\n",
    "# 定义超参数和设备\n",
    "num_users = 30001\n",
    "num_items = 1001\n",
    "num_genres = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 实例化模型\n",
    "model = DIN(num_users, num_items, num_genres, EMBEDDING_SIZE).to(device)\n",
    "#随机一个输入，测试DIN模型\n",
    "outputs = model(inputs)\n",
    "print(outputs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T01:26:49.554228400Z",
     "start_time": "2024-08-21T01:26:49.316436200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_outputs.extend(predictions.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    auc_roc = roc_auc_score(all_labels, all_outputs)\n",
    "    auc_pr = average_precision_score(all_labels, all_outputs)\n",
    "    return test_loss / len(test_loader), accuracy, auc_roc, auc_pr\n",
    "\n",
    "\n",
    "# 训练和评估函数\n",
    "def train(model, train_loader, test_loader,criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        val_loss, val_acc, val_auc_roc, val_auc_pr = evaluate(model, test_loader, criterion)\n",
    "        print(f\"Epoch: {epoch+1}, train_Loss: {running_loss / len(train_loader)},val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_auc_roc: {val_auc_roc:.4f}, val_auc_pr: {val_auc_pr:.4f}\")\n",
    "        # print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7403 [00:00<?, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11988\\646285715.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  inputs = {col: torch.tensor(row[col], dtype=torch.float if 'Rating' in col or 'Stddev' in col else torch.long) for col in self.data.columns if col != 'label'}\n",
      "  8%|▊         | 563/7403 [00:11<02:16, 49.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[1], line 147\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_loader, criterion, optimizer, epochs)\u001B[0m\n\u001B[0;32m    145\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[0;32m    146\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m--> 147\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    148\u001B[0m     running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrunning_loss\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Envs\\ml\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    383\u001B[0m             )\n\u001B[1;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\Envs\\ml\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32m~\\Envs\\ml\\lib\\site-packages\\torch\\optim\\adam.py:166\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    155\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    157\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    158\u001B[0m         group,\n\u001B[0;32m    159\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    163\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    164\u001B[0m         state_steps)\n\u001B[1;32m--> 166\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\Envs\\ml\\lib\\site-packages\\torch\\optim\\adam.py:316\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    314\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 316\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    323\u001B[0m \u001B[43m     \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    324\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    326\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    327\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Envs\\ml\\lib\\site-packages\\torch\\optim\\adam.py:377\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m    373\u001B[0m         (param\u001B[38;5;241m.\u001B[39mis_cuda \u001B[38;5;129;01mand\u001B[39;00m step_t\u001B[38;5;241m.\u001B[39mis_cuda) \u001B[38;5;129;01mor\u001B[39;00m (param\u001B[38;5;241m.\u001B[39mis_xla \u001B[38;5;129;01mand\u001B[39;00m step_t\u001B[38;5;241m.\u001B[39mis_xla)\n\u001B[0;32m    374\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf capturable=True, params and state_steps must be CUDA or XLA tensors.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;66;03m# update step\u001B[39;00m\n\u001B[1;32m--> 377\u001B[0m step_t \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight_decay \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    380\u001B[0m     grad \u001B[38;5;241m=\u001B[39m grad\u001B[38;5;241m.\u001B[39madd(param, alpha\u001B[38;5;241m=\u001B[39mweight_decay)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "train(model, train_loader,test_loader, criterion, optimizer, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T08:24:26.120566300Z",
     "start_time": "2024-05-22T08:24:13.425031100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# 打印一些预测结果\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        for prediction, label in zip(predictions[:12], labels[:12]):\n",
    "            print(f\"Predicted: {prediction.item():.2f}, Actual: {label.item()}\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
