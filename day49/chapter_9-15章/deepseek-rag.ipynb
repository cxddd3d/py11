{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c1056a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T07:59:52.478202Z",
     "start_time": "2025-07-22T07:59:15.384498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17951ae02cbb446c88cbeb0adce8ac59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HDS\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HDS\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83b90f134654a7d923e5aace148fdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8607f3a9ed145f78e5b00f57ac8f588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e5985c2fb940b59f09597a8b51c16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a60859265844ffb12a0172837b3f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer.json: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce424a938174176ad26074764b5a56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bc640eda4f495fb537754696b3112c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 sentence-transformers 模型: all-MiniLM-L6-v2\n",
      "正在处理 3 个文档...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e9afd860734d6fa33a34e29ed8afba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功添加 3 个文档\n",
      "=== DeepSeek RAG 系统 ===\n",
      "输入问题进行查询，输入 'quit' 退出\n",
      "输入 'clear' 清除对话历史\n",
      "输入 'save' 保存系统状态\n",
      "--------------------------------------------------\n",
      "正在查询...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afb066fbd464087bad632fea463eda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '你是一个专业的AI助手。请根据以下上下文信息回答用户的问题。\\n\\n上下文信息：\\n文档 1:\\n人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\\n        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\\n        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\\n        使用神经网络来模拟人脑的工作方式。\\n\\n文档 2:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 3:\\n自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\\n        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\\n        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\\n\\n文档 4:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 5:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n\\n用户问题：什么是AI\\n\\n请基于提供的上下文信息给出准确、详细的回答。如果上下文信息不足以回答问题，请说明这一点。\\n\\n回答：'}]\n",
      "\n",
      "回答: 根据提供的上下文信息，人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。AI系统具备以下核心能力：\n",
      "\n",
      "1. **基础定义**（文档1）：\n",
      "- 可执行学习、推理、解决问题和理解语言等类人智能任务\n",
      "- 通过机器学习（尤其是深度学习）实现数据驱动的自主优化\n",
      "\n",
      "2. **关键技术分支**：\n",
      "- **计算机视觉**（文档2/4/5）：\n",
      "  - 使计算机能识别和理解视觉数据（图像/视频）\n",
      "  - 典型任务：图像分类、目标检测、人脸识别\n",
      "  - 主要采用卷积神经网络（CNN）\n",
      "\n",
      "- **自然语言处理NLP**（文档3）：\n",
      "  - 实现语言理解、生成与交互\n",
      "  - 应用包括机器翻译、情感分析等\n",
      "  - 依赖Transformer等深度学习架构\n",
      "\n",
      "3. **实现方式**（文档1）：\n",
      "- 机器学习：无需显式编程即可从数据中学习\n",
      "- 深度学习：通过神经网络模拟人脑处理机制\n",
      "\n",
      "注：上下文存在重复内容（文档2/4/5内容完全重复），但已涵盖AI的核心定义、关键子领域及实现方法，信息完整度足以回答该问题。\n",
      "\n",
      "参考了 5 个相关文档\n",
      "正在查询...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c65065a9c04e338145ffbdfda09a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '什么是AI'}, {'role': 'assistant', 'content': '根据提供的上下文信息，人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。AI系统具备以下核心能力：\\n\\n1. **基础定义**（文档1）：\\n- 可执行学习、推理、解决问题和理解语言等类人智能任务\\n- 通过机器学习（尤其是深度学习）实现数据驱动的自主优化\\n\\n2. **关键技术分支**：\\n- **计算机视觉**（文档2/4/5）：\\n  - 使计算机能识别和理解视觉数据（图像/视频）\\n  - 典型任务：图像分类、目标检测、人脸识别\\n  - 主要采用卷积神经网络（CNN）\\n\\n- **自然语言处理NLP**（文档3）：\\n  - 实现语言理解、生成与交互\\n  - 应用包括机器翻译、情感分析等\\n  - 依赖Transformer等深度学习架构\\n\\n3. **实现方式**（文档1）：\\n- 机器学习：无需显式编程即可从数据中学习\\n- 深度学习：通过神经网络模拟人脑处理机制\\n\\n注：上下文存在重复内容（文档2/4/5内容完全重复），但已涵盖AI的核心定义、关键子领域及实现方法，信息完整度足以回答该问题。'}, {'role': 'user', 'content': '你是一个专业的AI助手。请根据以下上下文信息回答用户的问题。\\n\\n上下文信息：\\n文档 1:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 2:\\n人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\\n        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\\n        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\\n        使用神经网络来模拟人脑的工作方式。\\n\\n文档 3:\\n自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\\n        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\\n        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\\n\\n文档 4:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 5:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n\\n用户问题：心情不好怎么办\\n\\n请基于提供的上下文信息给出准确、详细的回答。如果上下文信息不足以回答问题，请说明这一点。\\n\\n回答：'}]\n",
      "\n",
      "回答: 根据提供的上下文信息，所有文档均聚焦于人工智能的技术领域（如计算机视觉、自然语言处理等），并未包含与情绪调节、心理健康相关的任何内容。因此，**当前上下文信息不足以回答“心情不好怎么办”这一问题**。\n",
      "\n",
      "建议：若需要相关帮助，可考虑以下通用建议（非基于当前上下文）：\n",
      "1. 与亲友倾诉\n",
      "2. 进行适度运动\n",
      "3. 尝试正念冥想\n",
      "4. 寻求专业心理咨询\n",
      "\n",
      "（注：作为AI助手，如需心理健康支持，建议优先联系人类专业人士。）\n",
      "\n",
      "参考了 5 个相关文档\n",
      "\n",
      "来源信息:\n",
      "1. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "2. 文档ID: text_0_0\n",
      "   内容预览: 人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\n",
      "        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\n",
      "        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\n",
      "        使用神经网络来模拟人脑的工作方式。\n",
      "3. 文档ID: text_1_0\n",
      "   内容预览: 自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\n",
      "        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\n",
      "        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\n",
      "4. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "5. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "正在查询...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dad03a40a64b50a5f0577381b88f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '什么是AI'}, {'role': 'assistant', 'content': '根据提供的上下文信息，人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。AI系统具备以下核心能力：\\n\\n1. **基础定义**（文档1）：\\n- 可执行学习、推理、解决问题和理解语言等类人智能任务\\n- 通过机器学习（尤其是深度学习）实现数据驱动的自主优化\\n\\n2. **关键技术分支**：\\n- **计算机视觉**（文档2/4/5）：\\n  - 使计算机能识别和理解视觉数据（图像/视频）\\n  - 典型任务：图像分类、目标检测、人脸识别\\n  - 主要采用卷积神经网络（CNN）\\n\\n- **自然语言处理NLP**（文档3）：\\n  - 实现语言理解、生成与交互\\n  - 应用包括机器翻译、情感分析等\\n  - 依赖Transformer等深度学习架构\\n\\n3. **实现方式**（文档1）：\\n- 机器学习：无需显式编程即可从数据中学习\\n- 深度学习：通过神经网络模拟人脑处理机制\\n\\n注：上下文存在重复内容（文档2/4/5内容完全重复），但已涵盖AI的核心定义、关键子领域及实现方法，信息完整度足以回答该问题。'}, {'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于人工智能的技术领域（如计算机视觉、自然语言处理等），并未包含与情绪调节、心理健康相关的任何内容。因此，**当前上下文信息不足以回答“心情不好怎么办”这一问题**。\\n\\n建议：若需要相关帮助，可考虑以下通用建议（非基于当前上下文）：\\n1. 与亲友倾诉\\n2. 进行适度运动\\n3. 尝试正念冥想\\n4. 寻求专业心理咨询\\n\\n（注：作为AI助手，如需心理健康支持，建议优先联系人类专业人士。）'}, {'role': 'user', 'content': '你是一个专业的AI助手。请根据以下上下文信息回答用户的问题。\\n\\n上下文信息：\\n文档 1:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 2:\\n人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\\n        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\\n        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\\n        使用神经网络来模拟人脑的工作方式。\\n\\n文档 3:\\n自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\\n        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\\n        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\\n\\n文档 4:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 5:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n\\n用户问题：心情不好怎么办\\n\\n请基于提供的上下文信息给出准确、详细的回答。如果上下文信息不足以回答问题，请说明这一点。\\n\\n回答：'}]\n",
      "\n",
      "回答: 根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（如计算机视觉、自然语言处理、机器学习等），**未包含任何与情绪调节、心理健康或生活建议相关的内容**。因此，**基于当前上下文无法给出与“心情不好怎么办”相关的专业回答**。  \n",
      "\n",
      "（注：作为AI助手，若您需要心理健康支持，建议参考可靠的心理学资源或联系专业心理咨询师。当前技术文档库仅涵盖AI技术定义及实现方法，不涉及人文关怀类内容。）\n",
      "\n",
      "参考了 5 个相关文档\n",
      "\n",
      "来源信息:\n",
      "1. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "2. 文档ID: text_0_0\n",
      "   内容预览: 人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\n",
      "        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\n",
      "        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\n",
      "        使用神经网络来模拟人脑的工作方式。\n",
      "3. 文档ID: text_1_0\n",
      "   内容预览: 自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\n",
      "        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\n",
      "        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\n",
      "4. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "5. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "正在查询...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1916aa91c0b84c4ba984e4603d9f3742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '什么是AI'}, {'role': 'assistant', 'content': '根据提供的上下文信息，人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。AI系统具备以下核心能力：\\n\\n1. **基础定义**（文档1）：\\n- 可执行学习、推理、解决问题和理解语言等类人智能任务\\n- 通过机器学习（尤其是深度学习）实现数据驱动的自主优化\\n\\n2. **关键技术分支**：\\n- **计算机视觉**（文档2/4/5）：\\n  - 使计算机能识别和理解视觉数据（图像/视频）\\n  - 典型任务：图像分类、目标检测、人脸识别\\n  - 主要采用卷积神经网络（CNN）\\n\\n- **自然语言处理NLP**（文档3）：\\n  - 实现语言理解、生成与交互\\n  - 应用包括机器翻译、情感分析等\\n  - 依赖Transformer等深度学习架构\\n\\n3. **实现方式**（文档1）：\\n- 机器学习：无需显式编程即可从数据中学习\\n- 深度学习：通过神经网络模拟人脑处理机制\\n\\n注：上下文存在重复内容（文档2/4/5内容完全重复），但已涵盖AI的核心定义、关键子领域及实现方法，信息完整度足以回答该问题。'}, {'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于人工智能的技术领域（如计算机视觉、自然语言处理等），并未包含与情绪调节、心理健康相关的任何内容。因此，**当前上下文信息不足以回答“心情不好怎么办”这一问题**。\\n\\n建议：若需要相关帮助，可考虑以下通用建议（非基于当前上下文）：\\n1. 与亲友倾诉\\n2. 进行适度运动\\n3. 尝试正念冥想\\n4. 寻求专业心理咨询\\n\\n（注：作为AI助手，如需心理健康支持，建议优先联系人类专业人士。）'}, {'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（如计算机视觉、自然语言处理、机器学习等），**未包含任何与情绪调节、心理健康或生活建议相关的内容**。因此，**基于当前上下文无法给出与“心情不好怎么办”相关的专业回答**。  \\n\\n（注：作为AI助手，若您需要心理健康支持，建议参考可靠的心理学资源或联系专业心理咨询师。当前技术文档库仅涵盖AI技术定义及实现方法，不涉及人文关怀类内容。）'}, {'role': 'user', 'content': '你是一个专业的AI助手。请根据以下上下文信息回答用户的问题。\\n\\n上下文信息：\\n文档 1:\\n人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\\n        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\\n        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\\n        使用神经网络来模拟人脑的工作方式。\\n\\n文档 2:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 3:\\n自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\\n        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\\n        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\\n\\n文档 4:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 5:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n\\n用户问题：AI发展前景\\n\\n请基于提供的上下文信息给出准确、详细的回答。如果上下文信息不足以回答问题，请说明这一点。\\n\\n回答：'}]\n",
      "\n",
      "回答: 基于提供的上下文信息，AI的发展前景主要体现在以下技术领域和应用方向：\n",
      "\n",
      "### 1. **核心技术持续突破**\n",
      "- **机器学习与深度学习**（文档1）：  \n",
      "  作为AI的核心驱动力，无需显式编程的自主学习能力将持续增强，神经网络架构（尤其是模拟人脑的深度学习模型）将向更高效、更可解释的方向演进。\n",
      "- **计算机视觉**（文档2/4/5）：  \n",
      "  以CNN为代表的模型已在图像/视频理解领域成熟应用，未来可能在实时性（如自动驾驶）、细粒度识别（如医疗影像分析）及多模态融合（结合语音、文本等）方向突破。\n",
      "- **自然语言处理（NLP）**（文档3）：  \n",
      "  Transformer架构推动的生成式AI（如大语言模型）将进一步提升语言理解与生成的拟人化水平，扩展至更复杂的交互场景（如个性化教育、跨语言实时翻译）。\n",
      "\n",
      "### 2. **应用场景深度拓展**\n",
      "- **垂直领域渗透**：  \n",
      "  现有技术（如计算机视觉的工业质检、NLP的智能客服）将向更多行业（农业、能源等）下沉，结合领域知识形成专业化解决方案。\n",
      "- **技术融合创新**：  \n",
      "  多模态AI（视觉+语言+推理）可能催生新应用，例如具身智能（机器人结合环境感知与决策）、沉浸式虚拟交互等。\n",
      "\n",
      "### 3. **当前上下文的局限性**\n",
      "- **未覆盖方向**：  \n",
      "  文档未提及AI伦理、政策监管、算力需求等关键挑战，亦未涉及具体商业前景（如市场规模预测），因此无法评估社会影响或经济潜力。\n",
      "- **技术细节缺失**：  \n",
      "  对新兴技术（如强化学习、AI生成内容/AIGC）无描述，难以全面展望技术边界。\n",
      "\n",
      "### 结论\n",
      "上下文表明AI在**技术迭代**和**应用落地**层面前景明确，但需结合更广泛的社会经济信息才能完整评估其发展潜力。\n",
      "\n",
      "参考了 5 个相关文档\n",
      "\n",
      "来源信息:\n",
      "1. 文档ID: text_0_0\n",
      "   内容预览: 人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\n",
      "        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\n",
      "        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\n",
      "        使用神经网络来模拟人脑的工作方式。\n",
      "2. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "3. 文档ID: text_1_0\n",
      "   内容预览: 自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\n",
      "        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\n",
      "        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\n",
      "4. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "5. 文档ID: text_2_0\n",
      "   内容预览: 计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
      "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
      "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
      "正在查询...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc75def10e54e3e8bad8c870c066962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '什么是AI'}, {'role': 'assistant', 'content': '根据提供的上下文信息，人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。AI系统具备以下核心能力：\\n\\n1. **基础定义**（文档1）：\\n- 可执行学习、推理、解决问题和理解语言等类人智能任务\\n- 通过机器学习（尤其是深度学习）实现数据驱动的自主优化\\n\\n2. **关键技术分支**：\\n- **计算机视觉**（文档2/4/5）：\\n  - 使计算机能识别和理解视觉数据（图像/视频）\\n  - 典型任务：图像分类、目标检测、人脸识别\\n  - 主要采用卷积神经网络（CNN）\\n\\n- **自然语言处理NLP**（文档3）：\\n  - 实现语言理解、生成与交互\\n  - 应用包括机器翻译、情感分析等\\n  - 依赖Transformer等深度学习架构\\n\\n3. **实现方式**（文档1）：\\n- 机器学习：无需显式编程即可从数据中学习\\n- 深度学习：通过神经网络模拟人脑处理机制\\n\\n注：上下文存在重复内容（文档2/4/5内容完全重复），但已涵盖AI的核心定义、关键子领域及实现方法，信息完整度足以回答该问题。'}, {'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于人工智能的技术领域（如计算机视觉、自然语言处理等），并未包含与情绪调节、心理健康相关的任何内容。因此，**当前上下文信息不足以回答“心情不好怎么办”这一问题**。\\n\\n建议：若需要相关帮助，可考虑以下通用建议（非基于当前上下文）：\\n1. 与亲友倾诉\\n2. 进行适度运动\\n3. 尝试正念冥想\\n4. 寻求专业心理咨询\\n\\n（注：作为AI助手，如需心理健康支持，建议优先联系人类专业人士。）'}, {'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（如计算机视觉、自然语言处理、机器学习等），**未包含任何与情绪调节、心理健康或生活建议相关的内容**。因此，**基于当前上下文无法给出与“心情不好怎么办”相关的专业回答**。  \\n\\n（注：作为AI助手，若您需要心理健康支持，建议参考可靠的心理学资源或联系专业心理咨询师。当前技术文档库仅涵盖AI技术定义及实现方法，不涉及人文关怀类内容。）'}, {'role': 'user', 'content': 'AI发展前景'}, {'role': 'assistant', 'content': '基于提供的上下文信息，AI的发展前景主要体现在以下技术领域和应用方向：\\n\\n### 1. **核心技术持续突破**\\n- **机器学习与深度学习**（文档1）：  \\n  作为AI的核心驱动力，无需显式编程的自主学习能力将持续增强，神经网络架构（尤其是模拟人脑的深度学习模型）将向更高效、更可解释的方向演进。\\n- **计算机视觉**（文档2/4/5）：  \\n  以CNN为代表的模型已在图像/视频理解领域成熟应用，未来可能在实时性（如自动驾驶）、细粒度识别（如医疗影像分析）及多模态融合（结合语音、文本等）方向突破。\\n- **自然语言处理（NLP）**（文档3）：  \\n  Transformer架构推动的生成式AI（如大语言模型）将进一步提升语言理解与生成的拟人化水平，扩展至更复杂的交互场景（如个性化教育、跨语言实时翻译）。\\n\\n### 2. **应用场景深度拓展**\\n- **垂直领域渗透**：  \\n  现有技术（如计算机视觉的工业质检、NLP的智能客服）将向更多行业（农业、能源等）下沉，结合领域知识形成专业化解决方案。\\n- **技术融合创新**：  \\n  多模态AI（视觉+语言+推理）可能催生新应用，例如具身智能（机器人结合环境感知与决策）、沉浸式虚拟交互等。\\n\\n### 3. **当前上下文的局限性**\\n- **未覆盖方向**：  \\n  文档未提及AI伦理、政策监管、算力需求等关键挑战，亦未涉及具体商业前景（如市场规模预测），因此无法评估社会影响或经济潜力。\\n- **技术细节缺失**：  \\n  对新兴技术（如强化学习、AI生成内容/AIGC）无描述，难以全面展望技术边界。\\n\\n### 结论\\n上下文表明AI在**技术迭代**和**应用落地**层面前景明确，但需结合更广泛的社会经济信息才能完整评估其发展潜力。'}, {'role': 'user', 'content': '你是一个专业的AI助手。请根据以下上下文信息回答用户的问题。\\n\\n上下文信息：\\n文档 1:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 2:\\n人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\\n        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\\n        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\\n        使用神经网络来模拟人脑的工作方式。\\n\\n文档 3:\\n自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\\n        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\\n        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\\n\\n文档 4:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 5:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n\\n用户问题：如何提升自己\\n\\n请基于提供的上下文信息给出准确、详细的回答。如果上下文信息不足以回答问题，请说明这一点。\\n\\n回答：'}]\n",
      "\n",
      "回答: 根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（如计算机视觉、自然语言处理、机器学习等），**未包含任何与个人成长、技能提升或自我发展相关的内容**。因此，**基于当前上下文无法直接回答“如何提升自己”这一问题**。  \n",
      "\n",
      "### 补充说明（非基于上下文）：\n",
      "若您希望结合AI技术领域的知识提升自身能力，可参考以下通用方向（需自行扩展学习）：\n",
      "1. **技术学习**：  \n",
      "   - 掌握机器学习/深度学习基础（如Python、TensorFlow/PyTorch框架）  \n",
      "   - 深入研究计算机视觉（CNN、目标检测模型）或NLP（Transformer、大语言模型）  \n",
      "2. **实践应用**：  \n",
      "   - 参与开源项目或Kaggle竞赛积累实战经验  \n",
      "   - 尝试复现论文中的AI模型  \n",
      "3. **跨领域结合**：  \n",
      "   - 将AI技术应用于自身专业领域（如医疗、金融等）  \n",
      "\n",
      "（注：以上建议未在提供的上下文中体现，仅为AI技术相关的延伸思考。）\n",
      "\n",
      "参考了 5 个相关文档\n",
      "正在查询...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7156b2fdac44a3b274ca330322c829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '什么是AI'}, {'role': 'assistant', 'content': '根据提供的上下文信息，人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。AI系统具备以下核心能力：\\n\\n1. **基础定义**（文档1）：\\n- 可执行学习、推理、解决问题和理解语言等类人智能任务\\n- 通过机器学习（尤其是深度学习）实现数据驱动的自主优化\\n\\n2. **关键技术分支**：\\n- **计算机视觉**（文档2/4/5）：\\n  - 使计算机能识别和理解视觉数据（图像/视频）\\n  - 典型任务：图像分类、目标检测、人脸识别\\n  - 主要采用卷积神经网络（CNN）\\n\\n- **自然语言处理NLP**（文档3）：\\n  - 实现语言理解、生成与交互\\n  - 应用包括机器翻译、情感分析等\\n  - 依赖Transformer等深度学习架构\\n\\n3. **实现方式**（文档1）：\\n- 机器学习：无需显式编程即可从数据中学习\\n- 深度学习：通过神经网络模拟人脑处理机制\\n\\n注：上下文存在重复内容（文档2/4/5内容完全重复），但已涵盖AI的核心定义、关键子领域及实现方法，信息完整度足以回答该问题。'}, {'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于人工智能的技术领域（如计算机视觉、自然语言处理等），并未包含与情绪调节、心理健康相关的任何内容。因此，**当前上下文信息不足以回答“心情不好怎么办”这一问题**。\\n\\n建议：若需要相关帮助，可考虑以下通用建议（非基于当前上下文）：\\n1. 与亲友倾诉\\n2. 进行适度运动\\n3. 尝试正念冥想\\n4. 寻求专业心理咨询\\n\\n（注：作为AI助手，如需心理健康支持，建议优先联系人类专业人士。）'}, {'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（如计算机视觉、自然语言处理、机器学习等），**未包含任何与情绪调节、心理健康或生活建议相关的内容**。因此，**基于当前上下文无法给出与“心情不好怎么办”相关的专业回答**。  \\n\\n（注：作为AI助手，若您需要心理健康支持，建议参考可靠的心理学资源或联系专业心理咨询师。当前技术文档库仅涵盖AI技术定义及实现方法，不涉及人文关怀类内容。）'}, {'role': 'user', 'content': 'AI发展前景'}, {'role': 'assistant', 'content': '基于提供的上下文信息，AI的发展前景主要体现在以下技术领域和应用方向：\\n\\n### 1. **核心技术持续突破**\\n- **机器学习与深度学习**（文档1）：  \\n  作为AI的核心驱动力，无需显式编程的自主学习能力将持续增强，神经网络架构（尤其是模拟人脑的深度学习模型）将向更高效、更可解释的方向演进。\\n- **计算机视觉**（文档2/4/5）：  \\n  以CNN为代表的模型已在图像/视频理解领域成熟应用，未来可能在实时性（如自动驾驶）、细粒度识别（如医疗影像分析）及多模态融合（结合语音、文本等）方向突破。\\n- **自然语言处理（NLP）**（文档3）：  \\n  Transformer架构推动的生成式AI（如大语言模型）将进一步提升语言理解与生成的拟人化水平，扩展至更复杂的交互场景（如个性化教育、跨语言实时翻译）。\\n\\n### 2. **应用场景深度拓展**\\n- **垂直领域渗透**：  \\n  现有技术（如计算机视觉的工业质检、NLP的智能客服）将向更多行业（农业、能源等）下沉，结合领域知识形成专业化解决方案。\\n- **技术融合创新**：  \\n  多模态AI（视觉+语言+推理）可能催生新应用，例如具身智能（机器人结合环境感知与决策）、沉浸式虚拟交互等。\\n\\n### 3. **当前上下文的局限性**\\n- **未覆盖方向**：  \\n  文档未提及AI伦理、政策监管、算力需求等关键挑战，亦未涉及具体商业前景（如市场规模预测），因此无法评估社会影响或经济潜力。\\n- **技术细节缺失**：  \\n  对新兴技术（如强化学习、AI生成内容/AIGC）无描述，难以全面展望技术边界。\\n\\n### 结论\\n上下文表明AI在**技术迭代**和**应用落地**层面前景明确，但需结合更广泛的社会经济信息才能完整评估其发展潜力。'}, {'role': 'user', 'content': '如何提升自己'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（如计算机视觉、自然语言处理、机器学习等），**未包含任何与个人成长、技能提升或自我发展相关的内容**。因此，**基于当前上下文无法直接回答“如何提升自己”这一问题**。  \\n\\n### 补充说明（非基于上下文）：\\n若您希望结合AI技术领域的知识提升自身能力，可参考以下通用方向（需自行扩展学习）：\\n1. **技术学习**：  \\n   - 掌握机器学习/深度学习基础（如Python、TensorFlow/PyTorch框架）  \\n   - 深入研究计算机视觉（CNN、目标检测模型）或NLP（Transformer、大语言模型）  \\n2. **实践应用**：  \\n   - 参与开源项目或Kaggle竞赛积累实战经验  \\n   - 尝试复现论文中的AI模型  \\n3. **跨领域结合**：  \\n   - 将AI技术应用于自身专业领域（如医疗、金融等）  \\n\\n（注：以上建议未在提供的上下文中体现，仅为AI技术相关的延伸思考。）'}, {'role': 'user', 'content': '你是一个专业的AI助手。请根据以下上下文信息回答用户的问题。\\n\\n上下文信息：\\n文档 1:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 2:\\n自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\\n        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\\n        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\\n\\n文档 3:\\n人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\\n        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\\n        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\\n        使用神经网络来模拟人脑的工作方式。\\n\\n文档 4:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 5:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n\\n用户问题：中国在哪里\\n\\n请基于提供的上下文信息给出准确、详细的回答。如果上下文信息不足以回答问题，请说明这一点。\\n\\n回答：'}]\n",
      "\n",
      "回答: 根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（包括计算机视觉、自然语言处理和机器学习等），**未包含任何与地理、国家位置或人文知识相关的内容**。因此，**基于当前上下文无法回答“中国在哪里”这一问题**。  \n",
      "\n",
      "（注：作为AI助手，若您需要地理信息，建议参考地图服务或地理资料库。当前技术文档库仅涵盖AI技术定义及实现方法。）\n",
      "\n",
      "参考了 5 个相关文档\n",
      "正在查询...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff72cab29b4439f8449c94a530f6a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于人工智能的技术领域（如计算机视觉、自然语言处理等），并未包含与情绪调节、心理健康相关的任何内容。因此，**当前上下文信息不足以回答“心情不好怎么办”这一问题**。\\n\\n建议：若需要相关帮助，可考虑以下通用建议（非基于当前上下文）：\\n1. 与亲友倾诉\\n2. 进行适度运动\\n3. 尝试正念冥想\\n4. 寻求专业心理咨询\\n\\n（注：作为AI助手，如需心理健康支持，建议优先联系人类专业人士。）'}, {'role': 'user', 'content': '心情不好怎么办'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（如计算机视觉、自然语言处理、机器学习等），**未包含任何与情绪调节、心理健康或生活建议相关的内容**。因此，**基于当前上下文无法给出与“心情不好怎么办”相关的专业回答**。  \\n\\n（注：作为AI助手，若您需要心理健康支持，建议参考可靠的心理学资源或联系专业心理咨询师。当前技术文档库仅涵盖AI技术定义及实现方法，不涉及人文关怀类内容。）'}, {'role': 'user', 'content': 'AI发展前景'}, {'role': 'assistant', 'content': '基于提供的上下文信息，AI的发展前景主要体现在以下技术领域和应用方向：\\n\\n### 1. **核心技术持续突破**\\n- **机器学习与深度学习**（文档1）：  \\n  作为AI的核心驱动力，无需显式编程的自主学习能力将持续增强，神经网络架构（尤其是模拟人脑的深度学习模型）将向更高效、更可解释的方向演进。\\n- **计算机视觉**（文档2/4/5）：  \\n  以CNN为代表的模型已在图像/视频理解领域成熟应用，未来可能在实时性（如自动驾驶）、细粒度识别（如医疗影像分析）及多模态融合（结合语音、文本等）方向突破。\\n- **自然语言处理（NLP）**（文档3）：  \\n  Transformer架构推动的生成式AI（如大语言模型）将进一步提升语言理解与生成的拟人化水平，扩展至更复杂的交互场景（如个性化教育、跨语言实时翻译）。\\n\\n### 2. **应用场景深度拓展**\\n- **垂直领域渗透**：  \\n  现有技术（如计算机视觉的工业质检、NLP的智能客服）将向更多行业（农业、能源等）下沉，结合领域知识形成专业化解决方案。\\n- **技术融合创新**：  \\n  多模态AI（视觉+语言+推理）可能催生新应用，例如具身智能（机器人结合环境感知与决策）、沉浸式虚拟交互等。\\n\\n### 3. **当前上下文的局限性**\\n- **未覆盖方向**：  \\n  文档未提及AI伦理、政策监管、算力需求等关键挑战，亦未涉及具体商业前景（如市场规模预测），因此无法评估社会影响或经济潜力。\\n- **技术细节缺失**：  \\n  对新兴技术（如强化学习、AI生成内容/AIGC）无描述，难以全面展望技术边界。\\n\\n### 结论\\n上下文表明AI在**技术迭代**和**应用落地**层面前景明确，但需结合更广泛的社会经济信息才能完整评估其发展潜力。'}, {'role': 'user', 'content': '如何提升自己'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（如计算机视觉、自然语言处理、机器学习等），**未包含任何与个人成长、技能提升或自我发展相关的内容**。因此，**基于当前上下文无法直接回答“如何提升自己”这一问题**。  \\n\\n### 补充说明（非基于上下文）：\\n若您希望结合AI技术领域的知识提升自身能力，可参考以下通用方向（需自行扩展学习）：\\n1. **技术学习**：  \\n   - 掌握机器学习/深度学习基础（如Python、TensorFlow/PyTorch框架）  \\n   - 深入研究计算机视觉（CNN、目标检测模型）或NLP（Transformer、大语言模型）  \\n2. **实践应用**：  \\n   - 参与开源项目或Kaggle竞赛积累实战经验  \\n   - 尝试复现论文中的AI模型  \\n3. **跨领域结合**：  \\n   - 将AI技术应用于自身专业领域（如医疗、金融等）  \\n\\n（注：以上建议未在提供的上下文中体现，仅为AI技术相关的延伸思考。）'}, {'role': 'user', 'content': '中国在哪里'}, {'role': 'assistant', 'content': '根据提供的上下文信息，所有文档均聚焦于**人工智能的技术领域**（包括计算机视觉、自然语言处理和机器学习等），**未包含任何与地理、国家位置或人文知识相关的内容**。因此，**基于当前上下文无法回答“中国在哪里”这一问题**。  \\n\\n（注：作为AI助手，若您需要地理信息，建议参考地图服务或地理资料库。当前技术文档库仅涵盖AI技术定义及实现方法。）'}, {'role': 'user', 'content': '你是一个专业的AI助手。请根据以下上下文信息回答用户的问题。\\n\\n上下文信息：\\n文档 1:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 2:\\n人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\\n        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\\n        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\\n        使用神经网络来模拟人脑的工作方式。\\n\\n文档 3:\\n自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\\n        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\\n        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\\n\\n文档 4:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n文档 5:\\n计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\\n        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\\n        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\\n\\n\\n用户问题：可以结束了吗\\n\\n请基于提供的上下文信息给出准确、详细的回答。如果上下文信息不足以回答问题，请说明这一点。\\n\\n回答：'}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 539\u001b[39m\n\u001b[32m    534\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 517\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# 查询\u001b[39;00m\n\u001b[32m    516\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m正在查询...\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# 打印查询状态\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m result = \u001b[43mrag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_history\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 执行查询\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# 显示结果\u001b[39;00m\n\u001b[32m    520\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m回答: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# 打印回答\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 410\u001b[39m, in \u001b[36mRAGSystem.query\u001b[39m\u001b[34m(self, question, top_k, use_history)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28mprint\u001b[39m(messages)\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# 调用DeepSeek API\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeepseek_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 获取回答\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;66;03m# 更新对话历史\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_history:  \u001b[38;5;66;03m# 如果使用历史\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mDeepSeekClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, max_tokens, temperature)\u001b[39m\n\u001b[32m     53\u001b[39m payload = {  \u001b[38;5;66;03m# 构建请求负载\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,  \u001b[38;5;66;03m# 指定模型\u001b[39;00m\n\u001b[32m     55\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,  \u001b[38;5;66;03m# 设置消息列表\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# 不使用流式响应\u001b[39;00m\n\u001b[32m     59\u001b[39m }\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 发送POST请求\u001b[39;00m\n\u001b[32m     63\u001b[39m     response.raise_for_status()  \u001b[38;5;66;03m# 检查HTTP响应状态\u001b[39;00m\n\u001b[32m     65\u001b[39m     result = response.json()  \u001b[38;5;66;03m# 解析JSON响应\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\urllib3\\response.py:1063\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1060\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\urllib3\\response.py:1219\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1216\u001b[39m     amt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1219\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1221\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\urllib3\\response.py:1138\u001b[39m, in \u001b[36mHTTPResponse._update_chunk_length\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1139\u001b[39m line = line.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os  # 导入操作系统模块，用于文件路径操作\n",
    "import json  # 导入JSON模块，用于处理JSON数据\n",
    "import requests  # 导入HTTP请求库，用于API调用\n",
    "import numpy as np  # 导入NumPy库，用于数值计算\n",
    "from typing import List, Dict, Any, Optional  # 导入类型提示\n",
    "from dataclasses import dataclass  # 导入数据类装饰器\n",
    "import pickle  # 导入pickle模块，用于序列化对象\n",
    "import re  # 导入正则表达式模块\n",
    "from pathlib import Path  # 导入Path类，用于路径操作\n",
    "\n",
    "# 使用 OpenAI embeddings 或 Hugging Face transformers 作为替代\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer  # 尝试导入sentence_transformers库\n",
    "    USE_SENTENCE_TRANSFORMERS = True  # 设置标志表示可以使用sentence_transformers\n",
    "except ImportError:\n",
    "    USE_SENTENCE_TRANSFORMERS = False  # 设置标志表示不能使用sentence_transformers\n",
    "    # 备用方案：使用 Hugging Face transformers\n",
    "    try:\n",
    "        from transformers import AutoTokenizer, AutoModel  # 尝试导入transformers库\n",
    "        import torch  # 导入PyTorch库\n",
    "        USE_TRANSFORMERS = True  # 设置标志表示可以使用transformers\n",
    "    except ImportError:\n",
    "        USE_TRANSFORMERS = False  # 设置标志表示不能使用transformers\n",
    "\n",
    "import faiss  # 导入FAISS库，用于向量检索\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    \"\"\"文档数据结构\"\"\"\n",
    "    id: str  # 文档唯一标识符\n",
    "    content: str  # 文档内容\n",
    "    metadata: Dict[str, Any] = None  # 文档元数据，默认为None\n",
    "    embedding: Optional[np.ndarray] = None  # 文档的嵌入向量，默认为None\n",
    "\n",
    "class DeepSeekClient:\n",
    "    \"\"\"DeepSeek API客户端,向DeepSeek API发送请求\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, base_url: str = \"https://api.deepseek.com\"):\n",
    "        self.api_key = api_key  # 存储API密钥\n",
    "        self.base_url = base_url  # 存储API基础URL\n",
    "        self.headers = {  # 设置HTTP请求头\n",
    "            \"Authorization\": f\"Bearer {api_key}\",  # 添加认证信息\n",
    "            \"Content-Type\": \"application/json\"  # 设置内容类型\n",
    "        }\n",
    "    \n",
    "    def chat_completion(self, messages: List[Dict[str, str]], \n",
    "                       model: str = \"deepseek-chat\", \n",
    "                       max_tokens: int = 2048,\n",
    "                       temperature: float = 0.7) -> str:\n",
    "        \"\"\"调用DeepSeek聊天完成API\"\"\"\n",
    "        url = f\"{self.base_url}/chat/completions\"  # 构建API端点URL\n",
    "        \n",
    "        payload = {  # 构建请求负载\n",
    "            \"model\": model,  # 指定模型\n",
    "            \"messages\": messages,  # 设置消息列表\n",
    "            \"max_tokens\": max_tokens,  # 设置最大生成token数\n",
    "            \"temperature\": temperature,  # 设置温度参数\n",
    "            \"stream\": False  # 不使用流式响应\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(url, headers=self.headers, json=payload)  # 发送POST请求\n",
    "            response.raise_for_status()  # 检查HTTP响应状态\n",
    "            \n",
    "            result = response.json()  # 解析JSON响应\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"]  # 返回生成的内容\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API请求错误: {e}\")  # 打印API请求错误\n",
    "            return \"\"  # 返回空字符串\n",
    "        except KeyError as e:\n",
    "            print(f\"响应解析错误: {e}\")  # 打印响应解析错误\n",
    "            return \"\"  # 返回空字符串\n",
    "\n",
    "class DocumentProcessor:\n",
    "    \"\"\"文档处理器,将文档分割成块\"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 512, chunk_overlap: int = 50):\n",
    "        self.chunk_size = chunk_size  # 设置文本块大小\n",
    "        self.chunk_overlap = chunk_overlap  # 设置文本块重叠大小\n",
    "    \n",
    "    def load_text_file(self, file_path: str) -> str:\n",
    "        \"\"\"加载文本文件\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:  # 打开文件\n",
    "            return f.read()  # 读取文件内容\n",
    "    \n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        \"\"\"将文本分割成块\"\"\"\n",
    "        # 按段落分割\n",
    "        paragraphs = re.split(r'\\n\\s*\\n', text)  # 使用正则表达式按段落分割文本\n",
    "        \n",
    "        chunks = []  # 初始化文本块列表\n",
    "        current_chunk = \"\"  # 初始化当前文本块\n",
    "        \n",
    "        for paragraph in paragraphs:  # 遍历每个段落\n",
    "            # 如果当前块加上新段落超过限制，保存当前块\n",
    "            if len(current_chunk) + len(paragraph) > self.chunk_size:  # 检查是否超过块大小限制\n",
    "                if current_chunk:  # 如果当前块不为空\n",
    "                    chunks.append(current_chunk.strip())  # 添加当前块到列表\n",
    "                current_chunk = paragraph  # 开始新的块\n",
    "            else:\n",
    "                current_chunk += \"\\n\\n\" + paragraph if current_chunk else paragraph  # 将段落添加到当前块\n",
    "        \n",
    "        # 添加最后一块\n",
    "        if current_chunk:  # 如果最后一块不为空\n",
    "            chunks.append(current_chunk.strip())  # 添加到列表\n",
    "        \n",
    "        return chunks  # 返回文本块列表\n",
    "    \n",
    "    def process_file(self, file_path: str) -> List[Document]:\n",
    "        \"\"\"处理单个文件\"\"\"\n",
    "        text = self.load_text_file(file_path)  # 加载文件内容\n",
    "        chunks = self.split_text(text)  # 分割文本\n",
    "        \n",
    "        documents = []  # 初始化文档列表\n",
    "        filename = Path(file_path).name  # 获取文件名\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):  # 遍历每个文本块\n",
    "            doc = Document(  # 创建文档对象\n",
    "                id=f\"{filename}_{i}\",  # 设置文档ID\n",
    "                content=chunk,  # 设置文档内容\n",
    "                metadata={  # 设置文档元数据\n",
    "                    \"source\": filename,  # 源文件名\n",
    "                    \"chunk_id\": i,  # 块ID\n",
    "                    \"file_path\": file_path  # 文件路径\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)  # 添加文档到列表\n",
    "        \n",
    "        return documents  # 返回文档列表\n",
    "\n",
    "class EmbeddingModel:\n",
    "    \"\"\"嵌入模型包装器，主要作用是把文本变为稠密向量\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        all-MiniLM-L6-v2模型尺寸\n",
    "        \"\"\"\n",
    "        self.model_name = model_name  # 存储模型名称\n",
    "        self.model = None  # 初始化模型为None\n",
    "        self.tokenizer = None  # 初始化分词器为None\n",
    "        self._initialize_model()  # 初始化模型\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        \"\"\"初始化嵌入模型\"\"\"\n",
    "        if USE_SENTENCE_TRANSFORMERS:  # 如果可以使用sentence_transformers\n",
    "            try:\n",
    "                self.model = SentenceTransformer(self.model_name)  # 加载sentence_transformers模型\n",
    "                self.model_type = \"sentence_transformers\"  # 设置模型类型\n",
    "                print(f\"使用 sentence-transformers 模型: {self.model_name}\")  # 打印使用的模型\n",
    "            except Exception as e:\n",
    "                print(f\"sentence-transformers 初始化失败: {e}\")  # 打印初始化失败信息\n",
    "                self._fallback_to_transformers()  # 回退到transformers\n",
    "        else:\n",
    "            self._fallback_to_transformers()  # 回退到transformers\n",
    "    \n",
    "    def _fallback_to_transformers(self):\n",
    "        \"\"\"回退到 transformers 库\"\"\"\n",
    "        if USE_TRANSFORMERS:  # 如果可以使用transformers\n",
    "            try:\n",
    "                # 使用更简单的模型\n",
    "                model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # 设置模型名称\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name)  # 加载分词器\n",
    "                self.model = AutoModel.from_pretrained(model_name)  # 加载模型\n",
    "                self.model_type = \"transformers\"  # 设置模型类型\n",
    "                print(f\"使用 transformers 模型: {model_name}\")  # 打印使用的模型\n",
    "            except Exception as e:\n",
    "                print(f\"transformers 初始化失败: {e}\")  # 打印初始化失败信息\n",
    "                self._fallback_to_simple()  # 回退到简单方法\n",
    "        else:\n",
    "            self._fallback_to_simple()  # 回退到简单方法\n",
    "    \n",
    "    def _fallback_to_simple(self):\n",
    "        \"\"\"回退到简单的嵌入方法\"\"\"\n",
    "        print(\"回退到简单的 TF-IDF 嵌入方法\")  # 打印回退信息\n",
    "        self.model_type = \"tfidf\"  # 设置模型类型\n",
    "        try:\n",
    "            from sklearn.feature_extraction.text import TfidfVectorizer  # 导入TF-IDF向量化器\n",
    "            self.model = TfidfVectorizer(max_features=384, stop_words='english')  # 创建TF-IDF向量化器\n",
    "            self.fitted = False  # 设置未拟合标志\n",
    "        except ImportError:\n",
    "            print(\"警告: sklearn 未安装，使用随机嵌入\")  # 打印警告\n",
    "            self.model_type = \"random\"  # 设置模型类型为随机\n",
    "    \n",
    "    def encode(self, texts: List[str], show_progress_bar: bool = True) -> np.ndarray:\n",
    "        \"\"\"编码文本为嵌入向量\"\"\"\n",
    "        if self.model_type == \"sentence_transformers\":  # 如果使用sentence_transformers\n",
    "            return self.model.encode(texts, show_progress_bar=show_progress_bar)  # 使用模型编码文本\n",
    "        \n",
    "        elif self.model_type == \"transformers\":  # 如果使用transformers\n",
    "            return self._encode_with_transformers(texts)  # 使用transformers编码\n",
    "        \n",
    "        elif self.model_type == \"tfidf\":  # 如果使用TF-IDF\n",
    "            return self._encode_with_tfidf(texts)  # 使用TF-IDF编码\n",
    "        \n",
    "        else:  # random\n",
    "            return self._encode_random(texts)  # 使用随机编码\n",
    "    \n",
    "    def _encode_with_transformers(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"使用 transformers 编码\"\"\"\n",
    "        embeddings = []  # 初始化嵌入列表\n",
    "        \n",
    "        for text in texts:  # 遍历每个文本\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)  # 对文本进行分词\n",
    "            \n",
    "            with torch.no_grad():  # 不计算梯度\n",
    "                outputs = self.model(**inputs)  # 获取模型输出\n",
    "                # 使用 [CLS] token 的嵌入或平均池化\n",
    "                embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # 计算嵌入向量\n",
    "                embeddings.append(embedding)  # 添加到列表\n",
    "        \n",
    "        return np.array(embeddings)  # 返回嵌入向量数组\n",
    "    \n",
    "    def _encode_with_tfidf(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"使用 TF-IDF 编码\"\"\"\n",
    "        if not self.fitted:  # 如果模型未拟合\n",
    "            self.model.fit(texts)  # 拟合模型\n",
    "            self.fitted = True  # 设置已拟合标志\n",
    "        \n",
    "        return self.model.transform(texts).toarray()  # 转换文本并返回数组\n",
    "    \n",
    "    def _encode_random(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"随机嵌入（仅用于测试）\"\"\"\n",
    "        print(\"警告: 使用随机嵌入，结果可能不准确\")  # 打印警告\n",
    "        return np.random.randn(len(texts), 384)  # 返回随机嵌入向量\n",
    "\n",
    "class VectorStore:\n",
    "    \"\"\"向量存储和检索，主要作用是存储和检索文本的向量表示\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        初始化向量存储\n",
    "        \"\"\"\n",
    "        self.embedding_model = EmbeddingModel(embedding_model_name)  # 创建嵌入模型\n",
    "        self.documents: List[Document] = []  # 初始化文档列表\n",
    "        self.index = None  # 初始化索引为None\n",
    "        self.dimension = None  # 初始化维度为None\n",
    "    \n",
    "    def add_documents(self, documents: List[Document]):\n",
    "        \"\"\"添加文档到向量存储\"\"\"\n",
    "        print(f\"正在处理 {len(documents)} 个文档...\")  # 打印处理信息\n",
    "        \n",
    "        # 生成嵌入向量\n",
    "        contents = [doc.content for doc in documents]  # 提取文档内容\n",
    "        embeddings = self.embedding_model.encode(contents, show_progress_bar=True)  # 编码文档内容\n",
    "        \n",
    "        # 添加嵌入向量到文档\n",
    "        for doc, embedding in zip(documents, embeddings):  # 遍历文档和嵌入向量\n",
    "            doc.embedding = embedding  # 设置文档的嵌入向量\n",
    "        \n",
    "        self.documents.extend(documents)  # 将文档添加到列表\n",
    "        \n",
    "        # 构建FAISS索引\n",
    "        self._build_index()  # 构建索引\n",
    "        \n",
    "        print(f\"成功添加 {len(documents)} 个文档\")  # 打印成功信息\n",
    "    \n",
    "    def _build_index(self):\n",
    "        \"\"\"构建FAISS索引\"\"\"\n",
    "        if not self.documents:  # 如果没有文档\n",
    "            return  # 直接返回\n",
    "        \n",
    "        embeddings = np.array([doc.embedding for doc in self.documents])  # 获取所有嵌入向量\n",
    "        self.dimension = embeddings.shape[1]  # 设置维度\n",
    "        \n",
    "        # 创建FAISS索引\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)  # 内积相似度\n",
    "        \n",
    "        # 标准化向量（用于余弦相似度）\n",
    "        faiss.normalize_L2(embeddings)  # L2标准化\n",
    "        self.index.add(embeddings.astype(np.float32))  # 添加向量到索引\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 5) -> List[Document]:\n",
    "        \"\"\"搜索相关文档\"\"\"\n",
    "        if not self.index:  # 如果索引不存在\n",
    "            return []  # 返回空列表\n",
    "        \n",
    "        # 生成查询向量\n",
    "        query_embedding = self.embedding_model.encode([query])  # 编码查询\n",
    "        faiss.normalize_L2(query_embedding)  # L2标准化\n",
    "        \n",
    "        # 搜索\n",
    "        scores, indices = self.index.search(query_embedding.astype(np.float32), top_k)  # 执行搜索\n",
    "        \n",
    "        # 返回相关文档\n",
    "        results = []  # 初始化结果列表\n",
    "        for score, idx in zip(scores[0], indices[0]):  # 遍历分数和索引\n",
    "            if idx < len(self.documents):  # 如果索引有效\n",
    "                doc = self.documents[idx]  # 获取文档\n",
    "                results.append(doc)  # 添加到结果\n",
    "        \n",
    "        return results  # 返回结果\n",
    "    \n",
    "    def save(self, file_path: str):\n",
    "        \"\"\"保存向量存储\"\"\"\n",
    "        data = {  # 创建数据字典\n",
    "            'documents': self.documents,  # 存储文档\n",
    "            'dimension': self.dimension  # 存储维度\n",
    "        }\n",
    "        \n",
    "        with open(file_path, 'wb') as f:  # 打开文件\n",
    "            pickle.dump(data, f)  # 序列化数据\n",
    "        \n",
    "        # 保存FAISS索引\n",
    "        if self.index:  # 如果索引存在\n",
    "            faiss.write_index(self.index, file_path + \".faiss\")  # 写入索引\n",
    "    \n",
    "    def load(self, file_path: str):\n",
    "        \"\"\"加载向量存储\"\"\"\n",
    "        with open(file_path, 'rb') as f:  # 打开文件\n",
    "            data = pickle.load(f)  # 加载数据\n",
    "        \n",
    "        self.documents = data['documents']  # 设置文档\n",
    "        self.dimension = data['dimension']  # 设置维度\n",
    "        \n",
    "        # 加载FAISS索引\n",
    "        if os.path.exists(file_path + \".faiss\"):  # 如果索引文件存在\n",
    "            self.index = faiss.read_index(file_path + \".faiss\")  # 读取索引\n",
    "\n",
    "class RAGSystem:\n",
    "    \"\"\"RAG系统主类，主要作用是提供RAG系统的核心功能\"\"\"\n",
    "    \n",
    "    def __init__(self, deepseek_api_key: str, embedding_model: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.deepseek_client = DeepSeekClient(deepseek_api_key)  # 创建DeepSeek客户端\n",
    "        self.document_processor = DocumentProcessor()  # 创建文档处理器\n",
    "        self.vector_store = VectorStore(embedding_model)  # 创建向量存储\n",
    "        self.conversation_history = []  # 初始化对话历史\n",
    "    \n",
    "    def add_documents_from_files(self, file_paths: List[str]):\n",
    "        \"\"\"从文件添加文档\"\"\"\n",
    "        all_documents = []  # 初始化文档列表\n",
    "        \n",
    "        for file_path in file_paths:  # 遍历文件路径\n",
    "            print(f\"处理文件: {file_path}\")  # 打印处理信息\n",
    "            documents = self.document_processor.process_file(file_path)  # 处理文件\n",
    "            all_documents.extend(documents)  # 添加文档到列表\n",
    "        \n",
    "        self.vector_store.add_documents(all_documents)  # 将文档添加到向量存储\n",
    "    \n",
    "    def add_documents_from_text(self, texts: List[str], metadata_list: List[Dict] = None):\n",
    "        \"\"\"从文本添加文档\"\"\"\n",
    "        documents = []  # 初始化文档列表\n",
    "        \n",
    "        for i, text in enumerate(texts):  # 遍历文本\n",
    "            chunks = self.document_processor.split_text(text)  # 分割文本\n",
    "            \n",
    "            for j, chunk in enumerate(chunks):  # 遍历文本块\n",
    "                doc = Document(  # 创建文档\n",
    "                    id=f\"text_{i}_{j}\",  # 设置ID\n",
    "                    content=chunk,  # 设置内容\n",
    "                    metadata=metadata_list[i] if metadata_list else {\"source\": f\"text_{i}\"}  # 设置元数据\n",
    "                )\n",
    "                documents.append(doc)  # 添加文档到列表\n",
    "        \n",
    "        self.vector_store.add_documents(documents)  # 将文档添加到向量存储\n",
    "    \n",
    "    def _build_context(self, relevant_docs: List[Document]) -> str:\n",
    "        \"\"\"构建上下文\"\"\"\n",
    "        context_parts = []  # 初始化上下文部分列表\n",
    "        \n",
    "        for i, doc in enumerate(relevant_docs):  # 遍历相关文档\n",
    "            context_parts.append(f\"文档 {i+1}:\")  # 添加文档标题\n",
    "            context_parts.append(doc.content)  # 添加文档内容\n",
    "            context_parts.append(\"\")  # 空行分隔\n",
    "        \n",
    "        return \"\\n\".join(context_parts)  # 连接上下文部分\n",
    "    \n",
    "    def _build_prompt(self, query: str, context: str) -> str:\n",
    "        \"\"\"构建提示词\"\"\"\n",
    "        prompt = f\"\"\"你是一个专业的AI助手。请根据以下上下文信息回答用户的问题。\n",
    "\n",
    "上下文信息：\n",
    "{context}\n",
    "\n",
    "用户问题：{query}\n",
    "\n",
    "请基于提供的上下文信息给出准确、详细的回答。如果上下文信息不足以回答问题，请说明这一点。\n",
    "\n",
    "回答：\"\"\"  # 构建提示词模板\n",
    "        \n",
    "        return prompt  # 返回提示词\n",
    "    \n",
    "    def query(self, question: str, top_k: int = 5, use_history: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"查询RAG系统\"\"\"\n",
    "        # 检索相关文档\n",
    "        relevant_docs = self.vector_store.search(question, top_k)  # 搜索相关文档\n",
    "        \n",
    "        if not relevant_docs:  # 如果没有找到相关文档\n",
    "            return {  # 返回错误信息\n",
    "                \"answer\": \"抱歉，我没有找到相关的文档来回答您的问题。\",\n",
    "                \"sources\": [],\n",
    "                \"context\": \"\"\n",
    "            }\n",
    "        \n",
    "        # 构建上下文\n",
    "        context = self._build_context(relevant_docs)  # 构建上下文\n",
    "        \n",
    "        # 构建消息\n",
    "        messages = []  # 初始化消息列表\n",
    "        \n",
    "        # 添加历史对话（如果需要）\n",
    "        if use_history:  # 如果使用历史\n",
    "            messages.extend(self.conversation_history)  # 添加对话历史\n",
    "        \n",
    "        # 添加当前查询\n",
    "        prompt = self._build_prompt(question, context)  # 构建提示词\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})  # 添加用户消息\n",
    "        print(messages)\n",
    "        # 调用DeepSeek API\n",
    "        answer = self.deepseek_client.chat_completion(messages)  # 获取回答\n",
    "        \n",
    "        # 更新对话历史\n",
    "        if use_history:  # 如果使用历史\n",
    "            self.conversation_history.append({\"role\": \"user\", \"content\": question})  # 添加用户问题\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})  # 添加助手回答\n",
    "            \n",
    "            # 限制历史长度\n",
    "            if len(self.conversation_history) > 10:  # 如果历史超过10条\n",
    "                self.conversation_history = self.conversation_history[-10:]  # 保留最近10条\n",
    "        \n",
    "        # 提取来源信息\n",
    "        sources = []  # 初始化来源列表\n",
    "        for doc in relevant_docs:  # 遍历相关文档\n",
    "            source_info = {  # 创建来源信息\n",
    "                \"document_id\": doc.id,  # 文档ID\n",
    "                \"content_preview\": doc.content[:200] + \"...\" if len(doc.content) > 200 else doc.content,  # 内容预览\n",
    "                \"metadata\": doc.metadata  # 元数据\n",
    "            }\n",
    "            sources.append(source_info)  # 添加来源信息\n",
    "        \n",
    "        return {  # 返回结果\n",
    "            \"answer\": answer,  # 回答\n",
    "            \"sources\": sources,  # 来源\n",
    "            \"context\": context,  # 上下文\n",
    "            \"relevant_documents\": len(relevant_docs)  # 相关文档数量\n",
    "        }\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"清除对话历史\"\"\"\n",
    "        self.conversation_history = []  # 重置对话历史\n",
    "    \n",
    "    def save_system(self, file_path: str):\n",
    "        \"\"\"保存RAG系统\"\"\"\n",
    "        self.vector_store.save(file_path)  # 保存向量存储\n",
    "        \n",
    "        # 保存对话历史\n",
    "        history_path = file_path + \".history\"  # 设置历史文件路径\n",
    "        with open(history_path, 'w', encoding='utf-8') as f:  # 打开文件\n",
    "            json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)  # 保存对话历史\n",
    "    \n",
    "    def load_system(self, file_path: str):\n",
    "        \"\"\"加载RAG系统\"\"\"\n",
    "        self.vector_store.load(file_path)  # 加载向量存储\n",
    "        \n",
    "        # 加载对话历史\n",
    "        history_path = file_path + \".history\"  # 设置历史文件路径\n",
    "        if os.path.exists(history_path):  # 如果历史文件存在\n",
    "            with open(history_path, 'r', encoding='utf-8') as f:  # 打开文件\n",
    "                self.conversation_history = json.load(f)  # 加载对话历史\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数示例\"\"\"\n",
    "    # 设置API密钥\n",
    "    DEEPSEEK_API_KEY = \"sk-8d043c487cf04418bbdcf659f052331e\"  # 请替换为你的实际API密钥\n",
    "    \n",
    "    # 创建RAG系统\n",
    "    rag = RAGSystem(DEEPSEEK_API_KEY)  # 初始化RAG系统\n",
    "    \n",
    "    # 示例2: 从文本添加文档\n",
    "    sample_texts = [  # 示例文本列表\n",
    "        \"\"\"\n",
    "        人工智能（AI）是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。\n",
    "        AI系统可以学习、推理、解决问题和理解语言。机器学习是AI的一个重要子领域，\n",
    "        它使计算机能够从数据中学习而无需明确编程。深度学习是机器学习的一个子集，\n",
    "        使用神经网络来模拟人脑的工作方式。\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        自然语言处理（NLP）是人工智能的一个重要分支，专注于让计算机理解、\n",
    "        解释和生成人类语言。NLP的应用包括机器翻译、情感分析、问答系统和\n",
    "        文本摘要。现代NLP系统大多基于深度学习模型，如Transformer架构。\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        计算机视觉是人工智能的另一个重要领域，致力于让计算机能够识别和理解\n",
    "        图像和视频内容。常见的计算机视觉任务包括图像分类、目标检测、\n",
    "        图像分割和人脸识别。卷积神经网络（CNN）是计算机视觉中最常用的模型。\n",
    "        \"\"\"\n",
    "    ]\n",
    "    \n",
    "    # 添加文档到系统\n",
    "    rag.add_documents_from_text(sample_texts)  # 添加示例文本到RAG系统\n",
    "    \n",
    "    # 交互式查询\n",
    "    print(\"=== DeepSeek RAG 系统 ===\")  # 打印系统标题\n",
    "    print(\"输入问题进行查询，输入 'quit' 退出\")  # 打印使用说明\n",
    "    print(\"输入 'clear' 清除对话历史\")  # 打印清除历史说明\n",
    "    print(\"输入 'save' 保存系统状态\")  # 打印保存系统说明\n",
    "    print(\"-\" * 50)  # 打印分隔线\n",
    "    \n",
    "    while True:  # 无限循环\n",
    "        question = input(\"\\n请输入您的问题: \").strip()  # 获取用户输入\n",
    "        \n",
    "        if question.lower() == 'quit':  # 如果输入quit\n",
    "            break  # 退出循环\n",
    "        elif question.lower() == 'clear':  # 如果输入clear\n",
    "            rag.clear_history()  # 清除历史\n",
    "            print(\"对话历史已清除\")  # 打印确认信息\n",
    "            continue  # 继续循环\n",
    "        elif question.lower() == 'save':  # 如果输入save\n",
    "            rag.save_system(\"rag_system.pkl\")  # 保存系统\n",
    "            print(\"系统状态已保存\")  # 打印确认信息\n",
    "            continue  # 继续循环\n",
    "        elif not question:  # 如果输入为空\n",
    "            continue  # 继续循环\n",
    "        \n",
    "        # 查询\n",
    "        print(\"正在查询...\")  # 打印查询状态\n",
    "        result = rag.query(question, use_history=True)  # 执行查询\n",
    "        \n",
    "        # 显示结果\n",
    "        print(f\"\\n回答: {result['answer']}\")  # 打印回答\n",
    "        print(f\"\\n参考了 {result['relevant_documents']} 个相关文档\")  # 打印文档数量\n",
    "        \n",
    "        # 显示来源（可选）\n",
    "        show_sources = input(\"\\n是否显示来源信息? (y/n): \").lower() == 'y'  # 询问是否显示来源\n",
    "        if show_sources:  # 如果用户选择显示\n",
    "            print(\"\\n来源信息:\")  # 打印标题\n",
    "            for i, source in enumerate(result['sources']):  # 遍历来源\n",
    "                print(f\"{i+1}. 文档ID: {source['document_id']}\")  # 打印文档ID\n",
    "                print(f\"   内容预览: {source['content_preview']}\")\n",
    "    print(\"=== DeepSeek RAG 系统 ===\")\n",
    "    print(\"输入问题进行查询，输入 'quit' 退出\")\n",
    "    print(\"输入 'clear' 清除对话历史\")\n",
    "    print(\"输入 'save' 保存系统状态\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb249f61eb4eb10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:50:25.586776Z",
     "start_time": "2025-07-22T08:50:25.582093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4268d1fe9ae3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:51:12.081611Z",
     "start_time": "2025-07-22T08:51:12.078607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.40625"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15+15+12*7.5/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca6ba07a3699aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:51:33.223917Z",
     "start_time": "2025-07-22T08:51:33.220951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.640625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15+14*7.5/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1c5d72d1f9520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:51:58.518993Z",
     "start_time": "2025-07-22T08:51:58.515843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*7.5/64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
