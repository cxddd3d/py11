{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T13:30:01.209926Z",
     "start_time": "2025-07-29T13:29:57.174739Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DETR3D Forward Pass Demo\n",
      "==================================================\n",
      "Input shapes:\n",
      "  Images: torch.Size([2, 6, 3, 256, 256])\n",
      "  Camera matrices: torch.Size([2, 6, 3, 4])\n",
      "  Number of queries: 900\n",
      "  Number of classes: 10\n",
      "\n",
      "Output structure:\n",
      "  Number of layers: 6\n",
      "\n",
      "  Layer 1:\n",
      "    Bounding boxes: torch.Size([2, 900, 9])\n",
      "    Classification logits: torch.Size([2, 900, 11])\n",
      "    Reference points: torch.Size([2, 900, 3])\n",
      "    Bbox mean: -0.0753\n",
      "    Max class probability: 0.9284\n",
      "\n",
      "  Layer 2:\n",
      "    Bounding boxes: torch.Size([2, 900, 9])\n",
      "    Classification logits: torch.Size([2, 900, 11])\n",
      "    Reference points: torch.Size([2, 900, 3])\n",
      "    Bbox mean: -0.0304\n",
      "    Max class probability: 0.9046\n",
      "\n",
      "  Layer 3:\n",
      "    Bounding boxes: torch.Size([2, 900, 9])\n",
      "    Classification logits: torch.Size([2, 900, 11])\n",
      "    Reference points: torch.Size([2, 900, 3])\n",
      "    Bbox mean: -0.1728\n",
      "    Max class probability: 0.9444\n",
      "\n",
      "  Layer 4:\n",
      "    Bounding boxes: torch.Size([2, 900, 9])\n",
      "    Classification logits: torch.Size([2, 900, 11])\n",
      "    Reference points: torch.Size([2, 900, 3])\n",
      "    Bbox mean: 0.0531\n",
      "    Max class probability: 0.9477\n",
      "\n",
      "  Layer 5:\n",
      "    Bounding boxes: torch.Size([2, 900, 9])\n",
      "    Classification logits: torch.Size([2, 900, 11])\n",
      "    Reference points: torch.Size([2, 900, 3])\n",
      "    Bbox mean: -0.4955\n",
      "    Max class probability: 0.8764\n",
      "\n",
      "  Layer 6:\n",
      "    Bounding boxes: torch.Size([2, 900, 9])\n",
      "    Classification logits: torch.Size([2, 900, 11])\n",
      "    Reference points: torch.Size([2, 900, 3])\n",
      "    Bbox mean: -0.3170\n",
      "    Max class probability: 0.7991\n",
      "\n",
      "Final queries shape: torch.Size([2, 900, 256])\n",
      "\n",
      "Post-processing example:\n",
      "  Batch 1: 42 confident detections (>0.5 confidence)\n",
      "    Top detection - Confidence: 0.7410\n",
      "    Box params: [0.51068514585495, 2.4818694591522217, 0.20873309671878815, -3.7021446228027344, 1.4819971323013306, 1.8767499923706055, -0.895315408706665, -1.5711607933044434, 0.33221980929374695]\n",
      "  Batch 2: 63 confident detections (>0.5 confidence)\n",
      "    Top detection - Confidence: 0.7991\n",
      "    Box params: [-1.127279281616211, -0.4675051271915436, 0.8765658140182495, -2.2111871242523193, 0.9939425587654114, 0.20783549547195435, 0.3339993357658386, -1.6742244958877563, -0.3236405551433563]\n"
     ]
    }
   ],
   "source": [
    "import torch  # 导入PyTorch库\n",
    "import torch.nn as nn  # 导入神经网络模块\n",
    "import torch.nn.functional as F  # 导入函数式API\n",
    "import math  # 导入数学函数\n",
    "from typing import List, Tuple, Optional  # 导入类型提示\n",
    "\n",
    "\n",
    "class DETR3D(nn.Module):\n",
    "    \"\"\"\n",
    "    DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_classes: int = 10,  # 类别数量\n",
    "                 num_queries: int = 900,  # 查询数量\n",
    "                 num_layers: int = 6,  # 层数\n",
    "                 hidden_dim: int = 256,  # 隐藏维度\n",
    "                 num_heads: int = 8,  # 注意力头数\n",
    "                 num_feature_levels: int = 4):  # 特征层级数\n",
    "        super().__init__()  # 调用父类初始化\n",
    "        \n",
    "        self.num_classes = num_classes  # 设置类别数量\n",
    "        self.num_queries = num_queries  # 设置查询数量\n",
    "        self.num_layers = num_layers  # 设置层数\n",
    "        self.hidden_dim = hidden_dim  # 设置隐藏维度\n",
    "        \n",
    "        # Backbone: ResNet + FPN (简化版)\n",
    "        self.backbone = SimplifiedBackbone(hidden_dim, num_feature_levels)  # 初始化骨干网络\n",
    "        \n",
    "        # Learnable object queries\n",
    "        self.query_embed = nn.Embedding(num_queries, hidden_dim)  # 可学习的对象查询嵌入\n",
    "        \n",
    "        # Detection head layers\n",
    "        self.transformer_layers = nn.ModuleList([  # 创建transformer层列表\n",
    "            DETR3DLayer(hidden_dim, num_heads, num_feature_levels)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Prediction heads\n",
    "        self.reference_points_head = nn.Linear(hidden_dim, 3)  # 预测3D参考点\n",
    "        self.bbox_head = nn.Linear(hidden_dim, 9)  # 预测边界框参数 (x,y,z,w,h,l,roll,pitch,yaw),roll,pitch,yaw是角度\n",
    "        self.cls_head = nn.Linear(hidden_dim, num_classes + 1)  # +1 for no-object class\n",
    "        \n",
    "        self._reset_parameters()  # 初始化参数\n",
    "    \n",
    "    def _reset_parameters(self):\n",
    "        \"\"\"初始化参数\"\"\"\n",
    "        for p in self.parameters():  # 遍历所有参数\n",
    "            if p.dim() > 1:  # 如果参数维度大于1\n",
    "                nn.init.xavier_uniform_(p)  # 使用xavier均匀初始化\n",
    "    \n",
    "    def forward(self, \n",
    "                images: torch.Tensor,  # 输入图像\n",
    "                camera_matrices: torch.Tensor,  # 相机矩阵\n",
    "                image_shapes: List[Tuple[int, int]]) -> dict:  # 图像形状\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images: [B, N_cams, 3, H, W] - 多视角图像\n",
    "            camera_matrices: [B, N_cams, 3, 4] - 相机变换矩阵\n",
    "            image_shapes: List of (H, W) for each image\n",
    "        \n",
    "        Returns:\n",
    "            dict: 包含所有层的预测结果\n",
    "        \"\"\"\n",
    "        batch_size, num_cams = images.shape[:2]  # 获取批次大小和相机数量\n",
    "        \n",
    "        # 1. Feature extraction using backbone\n",
    "        multi_level_features = self.backbone(images)  # List of [B*N_cams, C, H_i, W_i]\n",
    "        \n",
    "        # 2. Initialize object queries (2,900,256)\n",
    "        object_queries = self.query_embed.weight.unsqueeze(0).repeat(batch_size, 1, 1)  # [B, N_queries, C]\n",
    "        \n",
    "        # 3. Store predictions from each layer\n",
    "        all_predictions = []  # 存储所有层的预测结果\n",
    "        \n",
    "        # 4. Iterative refinement through transformer layers\n",
    "        for layer_idx, transformer_layer in enumerate(self.transformer_layers):  # 遍历每一层\n",
    "            # Predict reference points from current queries,3代表x,y,z\n",
    "            reference_points = self.reference_points_head(object_queries).sigmoid()  # [B, N_queries, 3]\n",
    "            \n",
    "            # Transform queries using multi-view features\n",
    "            object_queries = transformer_layer(  # 通过transformer层更新查询\n",
    "                object_queries, \n",
    "                multi_level_features, \n",
    "                reference_points,\n",
    "                camera_matrices,\n",
    "                image_shapes,\n",
    "                batch_size,\n",
    "                num_cams\n",
    "            )\n",
    "            \n",
    "            # Make predictions for current layer\n",
    "            bbox_pred = self.bbox_head(object_queries)  # [B, N_queries, 9]\n",
    "            cls_pred = self.cls_head(object_queries)    # [B, N_queries, num_classes+1]\n",
    "            \n",
    "            all_predictions.append({  # 添加当前层的预测结果\n",
    "                'pred_boxes': bbox_pred,\n",
    "                'pred_logits': cls_pred,\n",
    "                'reference_points': reference_points\n",
    "            })\n",
    "        \n",
    "        return {  # 返回所有预测结果\n",
    "            'predictions': all_predictions,\n",
    "            'final_queries': object_queries\n",
    "        }\n",
    "\n",
    "\n",
    "class DETR3DLayer(nn.Module):\n",
    "    \"\"\"DETR3D transformer layer\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim: int, num_heads: int, num_feature_levels: int):  # 初始化函数\n",
    "        super().__init__()  # 调用父类初始化\n",
    "        \n",
    "        self.hidden_dim = hidden_dim  # 设置隐藏维度\n",
    "        self.num_heads = num_heads  # 设置注意力头数\n",
    "        self.num_feature_levels = num_feature_levels  # 设置特征层级数\n",
    "        \n",
    "        # Multi-head self-attention\n",
    "        self.self_attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout=0.1)  # 多头自注意力机制\n",
    "        \n",
    "        # Feature transformation\n",
    "        self.feature_proj = nn.Linear(hidden_dim, hidden_dim)  # 特征投影变换\n",
    "        \n",
    "        # Normalization and feed-forward\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)  # 第一个层归一化\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)  # 第二个层归一化\n",
    "        \n",
    "        self.ffn = nn.Sequential(  # 前馈神经网络\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),  # 扩展维度\n",
    "            nn.ReLU(),  # ReLU激活函数\n",
    "            nn.Dropout(0.1),  # 防止过拟合的dropout\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim),  # 恢复维度\n",
    "            nn.Dropout(0.1)  # 再次应用dropout\n",
    "        )\n",
    "    \n",
    "    def forward(self,\n",
    "                queries: torch.Tensor,\n",
    "                multi_level_features: List[torch.Tensor],\n",
    "                reference_points: torch.Tensor,\n",
    "                camera_matrices: torch.Tensor,\n",
    "                image_shapes: List[Tuple[int, int]],\n",
    "                batch_size: int,\n",
    "                num_cams: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            queries: [B, N_queries, C]\n",
    "            multi_level_features: List of [B*N_cams, C, H_i, W_i]\n",
    "            reference_points: [B, N_queries, 3] - 3D reference points\n",
    "            camera_matrices: [B, N_cams, 3, 4]\n",
    "            image_shapes: List of (H, W)\n",
    "            batch_size: int\n",
    "            num_cams: int\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Sample features from multiple views and levels\n",
    "        sampled_features = self.sample_multi_view_features(  # 从多视角和多层级采样特征\n",
    "            reference_points, \n",
    "            multi_level_features, \n",
    "            camera_matrices,\n",
    "            image_shapes,\n",
    "            batch_size, \n",
    "            num_cams\n",
    "        )  # [B, N_queries, C]\n",
    "        \n",
    "        # 2. Add sampled features to queries\n",
    "        queries = queries + sampled_features  # 将采样特征添加到查询中\n",
    "        \n",
    "        # 3. Self-attention among object queries\n",
    "        queries_t = queries.transpose(0, 1)  # [N_queries, B, C]  # 转置查询以适应注意力机制\n",
    "        attn_queries, _ = self.self_attn(queries_t, queries_t, queries_t)  # 应用自注意力\n",
    "        attn_queries = attn_queries.transpose(0, 1)  # [B, N_queries, C]  # 转置回原始形状\n",
    "        \n",
    "        # 4. Residual connection and normalization\n",
    "        queries = self.norm1(queries + attn_queries)  # 残差连接和归一化\n",
    "        \n",
    "        # 5. Feed-forward network\n",
    "        ffn_output = self.ffn(queries)  # 通过前馈网络\n",
    "        queries = self.norm2(queries + ffn_output)  # 第二次残差连接和归一化\n",
    "        \n",
    "        return queries  # 返回更新后的查询\n",
    "    \n",
    "    def sample_multi_view_features(self,\n",
    "                                 reference_points: torch.Tensor,\n",
    "                                 multi_level_features: List[torch.Tensor],\n",
    "                                 camera_matrices: torch.Tensor,\n",
    "                                 image_shapes: List[Tuple[int, int]],\n",
    "                                 batch_size: int,\n",
    "                                 num_cams: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sample features from multiple camera views and feature levels\n",
    "        \n",
    "        Args:\n",
    "            reference_points: [B, N_queries, 3] - 3D points in world coordinates\n",
    "            multi_level_features: List of [B*N_cams, C, H_i, W_i]\n",
    "            camera_matrices: [B, N_cams, 3, 4] - Camera transformation matrices\n",
    "            image_shapes: List of (H, W) for normalization\n",
    "            batch_size: int\n",
    "            num_cams: int\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: [B, N_queries, C] - Aggregated features\n",
    "        \"\"\"\n",
    "        num_queries = reference_points.shape[1]  # 获取查询数量，900\n",
    "        aggregated_features = []  # 存储聚合特征的列表\n",
    "        \n",
    "        for b in range(batch_size):  # 遍历每个批次\n",
    "            batch_features = []  # 存储当前批次的特征\n",
    "            valid_count = 0  # 有效相机计数\n",
    "            \n",
    "            for cam_idx in range(num_cams):  # 遍历每个相机\n",
    "                # Get camera matrix for this batch and camera\n",
    "                cam_matrix = camera_matrices[b, cam_idx]  # [3, 4]  # 获取当前批次和相机的变换矩阵\n",
    "                \n",
    "                # Convert 3D points to homogeneous coordinates\n",
    "                points_3d_homo = torch.cat([  # 将3D点转换为齐次坐标\n",
    "                    reference_points[b], \n",
    "                    torch.ones(num_queries, 1, device=reference_points.device)\n",
    "                ], dim=1)  # [N_queries, 4] (900,4)\n",
    "                \n",
    "                # Project to 2D image coordinates\n",
    "                points_2d_homo = torch.mm(points_3d_homo, cam_matrix.T)  # [N_queries, 3]  # 投影到2D图像坐标\n",
    "                points_2d = points_2d_homo[:, :2] / (points_2d_homo[:, 2:3] + 1e-8)  # [N_queries, 2]  # 归一化坐标\n",
    "                \n",
    "                # Sample features from all levels for this camera\n",
    "                cam_features = []  # 存储当前相机的特征\n",
    "                for level_idx, features in enumerate(multi_level_features):  # 遍历每个特征层级\n",
    "                    H, W = features.shape[-2:]  # 获取特征图的高和宽\n",
    "                    \n",
    "                    # Normalize coordinates to [-1, 1] for grid_sample\n",
    "                    normalized_coords = points_2d.clone()  # 复制2D点坐标\n",
    "                    normalized_coords[:, 0] = 2.0 * points_2d[:, 0] / W - 1.0  # x  # 归一化x坐标到[-1,1]\n",
    "                    normalized_coords[:, 1] = 2.0 * points_2d[:, 1] / H - 1.0  # y  # 归一化y坐标到[-1,1]\n",
    "                    \n",
    "                    # Check if points are within image bounds\n",
    "                    valid_mask = (  # 检查点是否在图像边界内\n",
    "                        (normalized_coords[:, 0] >= -1) & (normalized_coords[:, 0] <= 1) &\n",
    "                        (normalized_coords[:, 1] >= -1) & (normalized_coords[:, 1] <= 1)\n",
    "                    )\n",
    "                    \n",
    "                    # Get features for this camera and level(1,256,256,256) 取其中一个特征图\n",
    "                    feat_map = features[b * num_cams + cam_idx].unsqueeze(0)  # [1, C, H, W]  # 获取当前相机和层级的特征图\n",
    "                    \n",
    "                    # Sample features using bilinear interpolation\n",
    "                    sample_coords = normalized_coords.unsqueeze(0).unsqueeze(0)  # [1, 1, N_queries, 2]  # 准备采样坐标(1,1,900,2)\n",
    "                    sampled_feat = F.grid_sample(  # 使用双线性插值采样特征,通过sample_coords去拿feat_map的信息\n",
    "                        feat_map, \n",
    "                        sample_coords, \n",
    "                        mode='bilinear', \n",
    "                        padding_mode='zeros',\n",
    "                        align_corners=False\n",
    "                    )  # [1, C, 1, N_queries] (1,256,1,900)\n",
    "                    \n",
    "                    sampled_feat = sampled_feat.squeeze(0).squeeze(1).T  # [N_queries, C]  # 调整维度(900,256)\n",
    "                    \n",
    "                    # Apply valid mask\n",
    "                    sampled_feat[~valid_mask] = 0  # 将无效点的特征设为0\n",
    "                    \n",
    "                    cam_features.append(sampled_feat)  # 添加到当前相机的特征列表\n",
    "                \n",
    "                # Average features across levels for this camera\n",
    "                if cam_features:  # 如果有特征\n",
    "                    cam_feat_avg = torch.stack(cam_features, dim=0).mean(dim=0)  # [N_queries, C]  # 计算所有层级的平均特征\n",
    "                    batch_features.append(cam_feat_avg)  # 添加到批次特征列表\n",
    "                    valid_count += 1  # 有效相机计数加1\n",
    "            \n",
    "            # Average features across cameras\n",
    "            if batch_features:  # 如果有批次特征\n",
    "                batch_feat_avg = torch.stack(batch_features, dim=0).sum(dim=0) / (valid_count + 1e-8)  # 计算所有相机的平均特征\n",
    "            else:  # 如果没有批次特征\n",
    "                batch_feat_avg = torch.zeros(num_queries, self.hidden_dim, device=reference_points.device)  # 创建零特征\n",
    "            \n",
    "            aggregated_features.append(batch_feat_avg)  # 添加到聚合特征列表\n",
    "        \n",
    "        return torch.stack(aggregated_features, dim=0)  # [B, N_queries, C]  # 返回堆叠后的聚合特征\n",
    "\n",
    "\n",
    "class SimplifiedBackbone(nn.Module):\n",
    "    \"\"\"简化版的backbone网络 (ResNet + FPN)\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim: int, num_levels: int = 4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_levels = num_levels\n",
    "        \n",
    "        # 简化的特征提取层\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(3 if i == 0 else hidden_dim, hidden_dim, 3, \n",
    "                         stride=2**i if i > 0 else 1, padding=1),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for i in range(num_levels)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, images: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images: [B, N_cams, 3, H, W]\n",
    "        \n",
    "        Returns:\n",
    "            List of feature maps: [B*N_cams, C, H_i, W_i]\n",
    "        \"\"\"\n",
    "        B, N, C, H, W = images.shape\n",
    "        \n",
    "        # Reshape to process all images together\n",
    "        x = images.view(B * N, C, H, W)\n",
    "        \n",
    "        features = []\n",
    "        for i, layer in enumerate(self.conv_layers):\n",
    "            x = layer(x)\n",
    "            features.append(x)\n",
    "            \n",
    "        return features\n",
    "\n",
    "\n",
    "def demo_forward_pass():\n",
    "    \"\"\"演示DETR3D的前向传播过程\"\"\"\n",
    "    \n",
    "    # 设置参数\n",
    "    batch_size = 2\n",
    "    num_cams = 6\n",
    "    num_queries = 900\n",
    "    num_classes = 10\n",
    "    image_size = (256, 256)\n",
    "    \n",
    "    # 创建模型\n",
    "    model = DETR3D(\n",
    "        num_classes=num_classes,\n",
    "        num_queries=num_queries,\n",
    "        num_layers=6,\n",
    "        hidden_dim=256\n",
    "    )\n",
    "    \n",
    "    # 创建示例输入\n",
    "    images = torch.randn(batch_size, num_cams, 3, *image_size)\n",
    "    \n",
    "    # 创建相机变换矩阵 (简化版)\n",
    "    camera_matrices = torch.randn(batch_size, num_cams, 3, 4)\n",
    "    \n",
    "    # 图像尺寸,列表中有12个元素\n",
    "    image_shapes = [image_size] * batch_size * num_cams\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"DETR3D Forward Pass Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"Input shapes:\")\n",
    "    print(f\"  Images: {images.shape}\")\n",
    "    print(f\"  Camera matrices: {camera_matrices.shape}\")\n",
    "    print(f\"  Number of queries: {num_queries}\")\n",
    "    print(f\"  Number of classes: {num_classes}\")\n",
    "    \n",
    "    # 前向传播\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images, camera_matrices, image_shapes)\n",
    "    \n",
    "    print(f\"\\nOutput structure:\")\n",
    "    print(f\"  Number of layers: {len(outputs['predictions'])}\")\n",
    "    \n",
    "    # 显示每层的输出\n",
    "    for i, pred in enumerate(outputs['predictions']):\n",
    "        print(f\"\\n  Layer {i+1}:\")\n",
    "        print(f\"    Bounding boxes: {pred['pred_boxes'].shape}\")\n",
    "        print(f\"    Classification logits: {pred['pred_logits'].shape}\")\n",
    "        print(f\"    Reference points: {pred['reference_points'].shape}\")\n",
    "        \n",
    "        # 显示一些统计信息\n",
    "        bbox_mean = pred['pred_boxes'].mean().item()\n",
    "        cls_max_prob = torch.softmax(pred['pred_logits'], dim=-1).max().item()\n",
    "        \n",
    "        print(f\"    Bbox mean: {bbox_mean:.4f}\")\n",
    "        print(f\"    Max class probability: {cls_max_prob:.4f}\")\n",
    "    \n",
    "    print(f\"\\nFinal queries shape: {outputs['final_queries'].shape}\")\n",
    "    \n",
    "    # 模拟后处理：获取置信度最高的检测结果\n",
    "    final_predictions = outputs['predictions'][-1]  # 使用最后一层的预测\n",
    "    class_probs = torch.softmax(final_predictions['pred_logits'], dim=-1)\n",
    "    \n",
    "    # 获取非背景类的最大概率\n",
    "    object_probs = class_probs[:, :, :-1].max(dim=-1)[0]  # [B, N_queries]\n",
    "    \n",
    "    print(f\"\\nPost-processing example:\")\n",
    "    for b in range(batch_size):\n",
    "        # 获取置信度大于阈值的检测\n",
    "        confident_mask = object_probs[b] > 0.5\n",
    "        num_detections = confident_mask.sum().item()\n",
    "        \n",
    "        print(f\"  Batch {b+1}: {num_detections} confident detections (>0.5 confidence)\")\n",
    "        \n",
    "        if num_detections > 0:\n",
    "            confident_boxes = final_predictions['pred_boxes'][b][confident_mask]\n",
    "            confident_probs = object_probs[b][confident_mask]\n",
    "            \n",
    "            print(f\"    Top detection - Confidence: {confident_probs.max().item():.4f}\")\n",
    "            print(f\"    Box params: {confident_boxes[confident_probs.argmax()].tolist()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_forward_pass()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
