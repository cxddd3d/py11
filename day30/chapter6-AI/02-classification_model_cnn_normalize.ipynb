{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看FashionMNIST原始数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:19.703675Z",
     "start_time": "2025-07-01T02:08:15.765458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x1C980070410>, 9)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+tbw1oNx4m8QWmkWx2yXD4LkZCADJJ+gFbviL4a63oc7COE3MW4hdn38duD976jNc9daDqllIsc9lKrMu4YGeMkdR7gj8KzcV7H8BtEvV16+1iWCeG1Wz8mOV02pIzupwCeuAp6Z98cZ90aIzLIlw0c0ZJ4KgjHoeOa+evjS9n/wnMcNxBPCYLKONFhA2FNzMpGenDcgd816V4K03wefC+m3NlpVhP+5QSXBiR5fMx825iMg5zwce3FdbOzTwgW90lu6uCm8eYrL02soIyCPQgggEdMGQ3cluiPNK0rJwrRQBNueuMkt+teNfGKxsdY8WWdxNqcNo66eieXMwVsb5DnH415Hp2rajpE5n02/urOUjBe3laMkehIPIrVm8eeLrhNknibVivoLtx/I1UPinxC3XXtUP1vJP8ay5JZJpGkldnduSzHJP41//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACS0lEQVR4AWKgA2BkYOD1ZGBgZAHZxcjIAKZBbBBm+quS8v3rj1N/GBiZGP8wMKNIMv91cnnCzuU65+X/vww8/76hSP5iMFVgZtpp2HXm8nUz02PHGUHGQTHjf9cugd//GE7f+cUo8ft0yDSEJCMDw/8TCgyMf34x/Ph3/vYfT0VphLH/GRgY3kt+Z2fl+cH5z8aSSWwHqmsZuJiZvn18p/CPkYnr7z9ZBiaofQwMjMwMPFI/frH++sr/j537K9sldhOE5H9mhnBJJg4Gbtlf7L//cQhvusaCkGT5xXDlBxsXl6rSD2Yunr9PoraeYAGZx8T4+x/DHwaGbV+/s/1/zczxm+H3P2a9jwxMDMz///z6+Y+BwW7ime9v//z78/XrXw6GbwxsX4NAYc3AICSlJhmk/oPpN+czVjbhX1zHeOz+fWR9qcnIYNkkKvCX+cMfrl+M36+HneEVVGC4x/v5GycPHxcj83GpP3+/MTB/Z2DgF0lwy3z24/49VeFfrLxsf+UBY0xqv8vDw87Ayv/4mSiTRACHIrexMdMvJjYGRlYLlpeP+X485mHje/eQ5/uPP+svKwj9+vD77y/Wf4xsaixP/z/mFvnw5jULOysHL9Mbza+P37O/+f3nN6fERwOWC+sTn937wcPGwcb88+//by/+/WX5wfPrw4fffxRfMjIweBWLv/7wl5mNhZnxPysrGysjA+NLBrZ/EpfCGJn+MTA4tYnxMzGz/GV8+f/pvy/MDP9/f2Paff0YJBAYGBg0RN/LPPx1Fx5HFDIAaCTYdiCc4RIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from wangdao_deeplearning_train import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from wangdao_deeplearning_train import evaluate_classification_model as evaluate_model\n",
    "# 加载Fashion MNIST数据集，张量就是和numpy数组一样\n",
    "transform = transforms.Compose([])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "print(train_dataset[0])\n",
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据并处理为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:19.747573Z",
     "start_time": "2025-07-01T02:08:19.705116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状: (60000, 28, 28)\n",
      "训练集标签数量: 60000\n",
      "测试集形状: (10000, 28, 28)\n",
      "测试集标签数量: 10000\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
      "    0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
      "   54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      "  144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
      "  107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
      "  216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
      "  223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
      "  180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
      "  169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
      "  198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
      "  232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
      "  222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
      "  211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
      "  224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
      "  255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
      "  168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
      "  239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
      "  199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
      "  195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
      "  210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
      "  182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载Fashion MNIST数据集，张量就是和numpy数组一样\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# 获取图像和标签\n",
    "# 注意：由于使用了transform，图像已经被转换为张量且标准化\n",
    "# 我们需要从dataset中提取原始图像用于显示\n",
    "train_images = train_dataset.data.numpy()\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "test_images = test_dataset.data.numpy()\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "# 定义类别名称\n",
    "class_names = ['T-shirt/top', '裤子', '套头衫', '连衣裙', '外套',\n",
    "               '凉鞋', '衬衫', '运动鞋', '包', '短靴']\n",
    "\n",
    "# 查看数据集基本信息\n",
    "print(f\"训练集形状: {train_images.shape}\")\n",
    "print(f\"训练集标签数量: {len(train_labels)}\")\n",
    "print(f\"测试集形状: {test_images.shape}\")\n",
    "print(f\"测试集标签数量: {len(test_labels)}\")\n",
    "\n",
    "print(train_images[0])\n",
    "\n",
    "train_labels[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:19.758647Z",
     "start_time": "2025-07-01T02:08:19.748088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看归一化后的效果\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:19.765162Z",
     "start_time": "2025-07-01T02:08:19.759651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:19.772589Z",
     "start_time": "2025-07-01T02:08:19.767195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把数据集划分为训练集55000和验证集5000，并给DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:19.782828Z",
     "start_time": "2025-07-01T02:08:19.773595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 55000\n",
      "验证集大小: 5000\n",
      "测试集大小: 10000\n",
      "批次大小: 64\n",
      "训练批次数: 860\n"
     ]
    }
   ],
   "source": [
    "# 从训练集中划分出验证集\n",
    "train_size = 55000\n",
    "val_size = 5000\n",
    "# 设置随机种子以确保每次得到相同的随机划分结果\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "    train_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=generator #设置随机种子，确保每次得到相同的随机划分结果\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 打印数据集大小信息\n",
    "print(f\"训练集大小: {len(train_subset)}\")\n",
    "print(f\"验证集大小: {len(val_subset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n",
    "print(f\"批次大小: {batch_size}\")\n",
    "print(f\"训练批次数: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:19.788319Z",
     "start_time": "2025-07-01T02:08:19.783835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55040"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.037852Z",
     "start_time": "2025-07-01T02:08:19.789471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55000, 1, 28, 28])\n",
      "训练数据集均值: 0.2856\n",
      "训练数据集标准差: 0.3527\n",
      "数据集中图像总数: 55000\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_std(train_dataset):\n",
    "    # 首先将所有图像数据堆叠为一个大张量\n",
    "    all_images = torch.stack([img_tensor for img_tensor, _ in train_dataset])\n",
    "    print(all_images.shape)\n",
    "    # 计算通道维度上的均值和标准差\n",
    "    # Fashion MNIST是灰度图像，只有一个通道\n",
    "    # 对所有像素值计算均值和标准差\n",
    "    mean = torch.mean(all_images)\n",
    "    std = torch.std(all_images)\n",
    "\n",
    "    print(f\"训练数据集均值: {mean.item():.4f}\")\n",
    "    print(f\"训练数据集标准差: {std.item():.4f}\")\n",
    "\n",
    "    # 检查数据集大小\n",
    "    print(f\"数据集中图像总数: {len(train_dataset)}\")\n",
    "calculate_mean_std(train_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.045686Z",
     "start_time": "2025-07-01T02:08:23.037852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#理解每个接口的方法，单独写例子\n",
    "import torch.nn as nn\n",
    "m=nn.BatchNorm1d(100) # 创建一个批量归一化层，输入特征维度为100\n",
    "x=torch.randn(20,100) # 创建一个20行100列的随机张量\n",
    "print(m(x).shape) # 打印批量归一化后的张量形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.054320Z",
     "start_time": "2025-07-01T02:08:23.046764Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #normalize\n",
    "        self.transform = nn.Sequential(\n",
    "            transforms.Normalize([0.2856], [0.3527])\n",
    "        )\n",
    "        \n",
    "        # 第一组卷积层 - 32个卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) # 输入通道数，输出通道数代表的是卷积核的个数\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 第二组卷积层 - 64个卷积核\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        \n",
    "        # 第三组卷积层 - 128个卷积核\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        \n",
    "        # 计算全连接层的输入特征数\n",
    "        # 经过3次池化，图像尺寸从28x28变为3x3x128\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "        # 初始化权重\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"使用 xavier 均匀分布来初始化卷积层和全连接层的权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape [batch size, 1, 28, 28]\n",
    "        \n",
    "        # 第一组卷积层\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f\"conv1后的形状: {x.shape}\")\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print(f\"conv2后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool1后的形状: {x.shape}\")\n",
    "        \n",
    "        # 第二组卷积层\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print(f\"conv3后的形状: {x.shape}\")\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # print(f\"conv4后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool2后的形状: {x.shape}\")\n",
    "        \n",
    "        # 第三组卷积层\n",
    "        x = F.relu(self.conv5(x))\n",
    "        # print(f\"conv5后的形状: {x.shape}\")\n",
    "        x = F.relu(self.conv6(x))\n",
    "        # print(f\"conv6后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool3后的形状: {x.shape}\")\n",
    "        \n",
    "        # 展平\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(f\"展平后的形状: {x.shape}\")\n",
    "        \n",
    "        # 全连接层\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(f\"fc1后的形状: {x.shape}\")\n",
    "        x = self.fc2(x)\n",
    "        # print(f\"fc2后的形状: {x.shape}\")\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.112145Z",
     "start_time": "2025-07-01T02:08:23.055598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次图像形状: torch.Size([64, 1, 28, 28])\n",
      "批次标签形状: torch.Size([64])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# 从train_loader获取第一个批次的数据\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 查看批次数据的形状\n",
    "print(\"批次图像形状:\", images.shape)\n",
    "print(\"批次标签形状:\", labels.shape)\n",
    "\n",
    "\n",
    "print('-'*100)\n",
    "# 进行前向传播\n",
    "with torch.no_grad():  # 不需要计算梯度\n",
    "    outputs = model(images)\n",
    "    \n",
    "\n",
    "print(outputs.shape)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.118358Z",
     "start_time": "2025-07-01T02:08:23.113151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要求梯度的参数总量: 584170\n",
      "模型总参数量: 584170\n",
      "\n",
      "各层参数量明细:\n",
      "conv1.weight: 288 参数\n",
      "conv1.bias: 32 参数\n",
      "conv2.weight: 9216 参数\n",
      "conv2.bias: 32 参数\n",
      "conv3.weight: 18432 参数\n",
      "conv3.bias: 64 参数\n",
      "conv4.weight: 36864 参数\n",
      "conv4.bias: 64 参数\n",
      "conv5.weight: 73728 参数\n",
      "conv5.bias: 128 参数\n",
      "conv6.weight: 147456 参数\n",
      "conv6.bias: 128 参数\n",
      "fc1.weight: 294912 参数\n",
      "fc1.bias: 256 参数\n",
      "fc2.weight: 2560 参数\n",
      "fc2.bias: 10 参数\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数量\n",
    "# 统计需要求梯度的参数总量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"需要求梯度的参数总量: {total_params}\")\n",
    "\n",
    "# 统计所有参数总量\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {all_params}\")\n",
    "\n",
    "# 查看每层参数量明细\n",
    "print(\"\\n各层参数量明细:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} 参数\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各层参数量明细\n",
    "conv1.weight: 288 参数\n",
    "conv1.bias: 32 参数\n",
    "conv2.weight: 9216 参数\n",
    "conv2.bias: 32 参数\n",
    "conv3.weight: 18432 参数\n",
    "conv3.bias: 64 参数\n",
    "conv4.weight: 36864 参数\n",
    "conv4.bias: 64 参数\n",
    "conv5.weight: 73728 参数\n",
    "conv5.bias: 128 参数\n",
    "conv6.weight: 147456 参数\n",
    "conv6.bias: 128 参数\n",
    "fc1.weight: 294912 参数\n",
    "fc1.bias: 256 参数\n",
    "fc2.weight: 2560 参数\n",
    "fc2.bias: 10 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.143701Z",
     "start_time": "2025-07-01T02:08:23.119363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 0.0684,  0.0397, -0.0627],\n",
       "                        [ 0.0566, -0.0164, -0.1035],\n",
       "                        [-0.0927, -0.0923,  0.1110]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0176, -0.0200,  0.1025],\n",
       "                        [ 0.0277, -0.0622,  0.0429],\n",
       "                        [ 0.1411,  0.0458, -0.0794]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1296,  0.1268,  0.1207],\n",
       "                        [-0.0007, -0.1057, -0.0435],\n",
       "                        [ 0.1045, -0.0273, -0.0581]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0232, -0.0895,  0.0818],\n",
       "                        [-0.0404,  0.1217, -0.0109],\n",
       "                        [-0.1402, -0.0210,  0.0734]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0665, -0.0647, -0.0630],\n",
       "                        [-0.0675,  0.1354,  0.1308],\n",
       "                        [-0.0019, -0.0846,  0.1092]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0675,  0.0959, -0.0197],\n",
       "                        [ 0.0829, -0.1181, -0.0309],\n",
       "                        [ 0.0483, -0.1348, -0.0895]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0057, -0.0776,  0.1236],\n",
       "                        [-0.1237, -0.0247,  0.0165],\n",
       "                        [ 0.0805, -0.0797, -0.0035]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1067,  0.1383, -0.1252],\n",
       "                        [ 0.1378,  0.0342, -0.0969],\n",
       "                        [ 0.0553,  0.0937,  0.0333]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0565, -0.0347, -0.1188],\n",
       "                        [-0.0522, -0.0396, -0.0396],\n",
       "                        [-0.1292,  0.0556, -0.0303]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0391,  0.0666, -0.1241],\n",
       "                        [-0.0660, -0.0241,  0.0148],\n",
       "                        [ 0.0852,  0.0121, -0.0631]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1259,  0.0588, -0.0165],\n",
       "                        [ 0.1192, -0.0150,  0.0320],\n",
       "                        [ 0.0560,  0.0768,  0.1144]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0432,  0.0102,  0.1031],\n",
       "                        [ 0.0731,  0.0207,  0.1420],\n",
       "                        [ 0.0691, -0.0601,  0.1158]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0020,  0.1373,  0.0042],\n",
       "                        [-0.1301,  0.0861, -0.0322],\n",
       "                        [ 0.1013, -0.0620, -0.0218]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0752, -0.1152,  0.1385],\n",
       "                        [-0.0200,  0.1193, -0.1245],\n",
       "                        [ 0.1186,  0.0824, -0.1027]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0252, -0.1305,  0.0314],\n",
       "                        [-0.0361, -0.0152,  0.1340],\n",
       "                        [ 0.0510,  0.0627, -0.0736]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0807, -0.1406, -0.1209],\n",
       "                        [-0.1186, -0.0927,  0.0620],\n",
       "                        [-0.1421,  0.0696,  0.0391]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1006, -0.0581, -0.0574],\n",
       "                        [ 0.0657,  0.0778,  0.0475],\n",
       "                        [ 0.1001, -0.0483, -0.1251]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1010, -0.1212,  0.0800],\n",
       "                        [ 0.0723, -0.0545, -0.0969],\n",
       "                        [ 0.0084,  0.0676,  0.0647]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0708,  0.0255,  0.0802],\n",
       "                        [ 0.0318, -0.0221, -0.1079],\n",
       "                        [-0.0917,  0.0990,  0.0316]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1224, -0.0341, -0.1237],\n",
       "                        [ 0.0149,  0.0439, -0.0096],\n",
       "                        [-0.1253, -0.0867, -0.0090]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0542,  0.0810, -0.1243],\n",
       "                        [ 0.0196, -0.0628, -0.0043],\n",
       "                        [ 0.0756, -0.0058,  0.0740]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0876,  0.0215,  0.0214],\n",
       "                        [ 0.0282,  0.0575,  0.0725],\n",
       "                        [-0.1081, -0.0964, -0.1400]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0006,  0.0481,  0.0480],\n",
       "                        [ 0.0333,  0.1417, -0.1140],\n",
       "                        [ 0.0604,  0.1000,  0.0695]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1168,  0.0146, -0.0350],\n",
       "                        [-0.0805,  0.1180,  0.0387],\n",
       "                        [ 0.0486,  0.1363,  0.1359]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0713, -0.0568,  0.1122],\n",
       "                        [-0.0336, -0.0686, -0.0620],\n",
       "                        [ 0.1313, -0.0941,  0.0169]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0161, -0.0277, -0.0787],\n",
       "                        [-0.0678, -0.0342, -0.1119],\n",
       "                        [ 0.1251, -0.1409,  0.1248]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0776, -0.0851, -0.0264],\n",
       "                        [ 0.0573,  0.0004,  0.0602],\n",
       "                        [ 0.0347, -0.0614, -0.0645]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0090,  0.0248,  0.0422],\n",
       "                        [-0.0226,  0.0148,  0.1365],\n",
       "                        [-0.0366,  0.1114,  0.0982]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0673, -0.1237,  0.1041],\n",
       "                        [ 0.0697, -0.0084,  0.0248],\n",
       "                        [-0.0269,  0.0758, -0.0512]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0659,  0.0865, -0.0839],\n",
       "                        [ 0.0505,  0.1113, -0.0468],\n",
       "                        [-0.1059,  0.0491,  0.0413]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0458, -0.0063,  0.0632],\n",
       "                        [ 0.0073,  0.0668,  0.0488],\n",
       "                        [ 0.0857, -0.1011, -0.0531]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0701,  0.0343,  0.0584],\n",
       "                        [ 0.1321,  0.1275, -0.1296],\n",
       "                        [ 0.0629, -0.0659, -0.1087]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 0.0630,  0.0984,  0.0529],\n",
       "                        [-0.0112,  0.0432,  0.0336],\n",
       "                        [ 0.0683, -0.0389,  0.0646]],\n",
       "              \n",
       "                       [[ 0.0732, -0.0931, -0.0578],\n",
       "                        [ 0.0164, -0.0033,  0.0633],\n",
       "                        [-0.0961, -0.0245,  0.0565]],\n",
       "              \n",
       "                       [[ 0.0137, -0.0284, -0.0354],\n",
       "                        [ 0.0078,  0.0252, -0.0780],\n",
       "                        [ 0.0408, -0.0745,  0.0920]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0922, -0.0059,  0.0109],\n",
       "                        [-0.0723, -0.0508, -0.0479],\n",
       "                        [ 0.0920, -0.0678, -0.0333]],\n",
       "              \n",
       "                       [[-0.0053, -0.0572, -0.0156],\n",
       "                        [-0.0343,  0.0447,  0.0079],\n",
       "                        [-0.0196,  0.0926, -0.0293]],\n",
       "              \n",
       "                       [[-0.0584,  0.0946,  0.0449],\n",
       "                        [-0.0508, -0.0092, -0.0986],\n",
       "                        [ 0.0116,  0.0518, -0.0962]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0753,  0.0188,  0.0901],\n",
       "                        [ 0.0495,  0.0457, -0.0555],\n",
       "                        [-0.0140, -0.0295,  0.0799]],\n",
       "              \n",
       "                       [[ 0.0763,  0.0160, -0.0361],\n",
       "                        [-0.0996, -0.0300,  0.0052],\n",
       "                        [-0.0473, -0.0972, -0.0726]],\n",
       "              \n",
       "                       [[-0.0050, -0.0911,  0.0121],\n",
       "                        [ 0.0358, -0.0698,  0.0520],\n",
       "                        [ 0.0358,  0.1020, -0.0138]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0400, -0.0280, -0.0544],\n",
       "                        [ 0.0260,  0.0176,  0.0851],\n",
       "                        [-0.0063,  0.0187, -0.0268]],\n",
       "              \n",
       "                       [[ 0.0348, -0.0560,  0.0279],\n",
       "                        [ 0.0515,  0.0402, -0.0485],\n",
       "                        [-0.0304,  0.0514,  0.0131]],\n",
       "              \n",
       "                       [[-0.0161, -0.0151, -0.0169],\n",
       "                        [-0.0491,  0.0602,  0.0445],\n",
       "                        [ 0.0569,  0.0714,  0.0442]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0919, -0.0467,  0.0362],\n",
       "                        [ 0.0229,  0.0704, -0.0559],\n",
       "                        [-0.0006,  0.0873, -0.0245]],\n",
       "              \n",
       "                       [[ 0.0907,  0.0530, -0.0872],\n",
       "                        [-0.0496, -0.0004, -0.0848],\n",
       "                        [ 0.0383, -0.0659, -0.0411]],\n",
       "              \n",
       "                       [[ 0.0368,  0.0302, -0.0657],\n",
       "                        [ 0.0956, -0.0862, -0.0066],\n",
       "                        [-0.0303,  0.0496, -0.0139]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0612,  0.0141,  0.0569],\n",
       "                        [-0.0781, -0.0502,  0.0218],\n",
       "                        [ 0.0800,  0.0166,  0.0455]],\n",
       "              \n",
       "                       [[ 0.0356,  0.0183,  0.0932],\n",
       "                        [ 0.0866,  0.0796,  0.0706],\n",
       "                        [-0.0022,  0.0310,  0.0688]],\n",
       "              \n",
       "                       [[-0.0329, -0.0311, -0.0282],\n",
       "                        [-0.0919, -0.0569, -0.0825],\n",
       "                        [ 0.0412, -0.0192,  0.0936]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0805, -0.0080,  0.0471],\n",
       "                        [ 0.0461, -0.0656, -0.0580],\n",
       "                        [ 0.0340, -0.0868, -0.1000]],\n",
       "              \n",
       "                       [[-0.0719, -0.0722, -0.0609],\n",
       "                        [-0.0865,  0.0727, -0.0791],\n",
       "                        [ 0.0979,  0.0335, -0.0943]],\n",
       "              \n",
       "                       [[-0.0361, -0.0528,  0.0636],\n",
       "                        [-0.0918, -0.0235, -0.0561],\n",
       "                        [-0.0331,  0.0371,  0.0293]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0031,  0.0957,  0.0417],\n",
       "                        [ 0.0943, -0.0288, -0.0499],\n",
       "                        [-0.0717, -0.0867, -0.0735]],\n",
       "              \n",
       "                       [[-0.0495,  0.0619, -0.0244],\n",
       "                        [ 0.0827, -0.0891,  0.0713],\n",
       "                        [-0.0292, -0.0819, -0.0165]],\n",
       "              \n",
       "                       [[ 0.0290, -0.0504,  0.0282],\n",
       "                        [-0.0394, -0.0886, -0.0856],\n",
       "                        [ 0.0987, -0.0983, -0.0536]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0011,  0.0713, -0.0370],\n",
       "                        [-0.0301,  0.0145, -0.1007],\n",
       "                        [ 0.0664, -0.1014, -0.0380]],\n",
       "              \n",
       "                       [[ 0.0758, -0.0949, -0.0927],\n",
       "                        [-0.0734,  0.0639,  0.0600],\n",
       "                        [ 0.0193, -0.0304, -0.0598]],\n",
       "              \n",
       "                       [[-0.0528, -0.0233, -0.0233],\n",
       "                        [-0.0031, -0.0476, -0.0792],\n",
       "                        [ 0.0916, -0.0685,  0.0574]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0117,  0.0884,  0.0472],\n",
       "                        [-0.0829,  0.0379, -0.0935],\n",
       "                        [-0.0780,  0.0378, -0.0509]],\n",
       "              \n",
       "                       [[-0.0937,  0.0749,  0.0986],\n",
       "                        [ 0.0867, -0.0093,  0.0232],\n",
       "                        [ 0.0162,  0.0405,  0.1011]],\n",
       "              \n",
       "                       [[-0.0477,  0.0236,  0.0569],\n",
       "                        [ 0.0161, -0.0167,  0.0084],\n",
       "                        [-0.0232,  0.0632, -0.0901]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1002, -0.0232, -0.1006],\n",
       "                        [ 0.0350, -0.0716, -0.0476],\n",
       "                        [-0.0712,  0.0838, -0.0290]],\n",
       "              \n",
       "                       [[-0.0810, -0.0604, -0.0467],\n",
       "                        [-0.0636, -0.0918,  0.0326],\n",
       "                        [ 0.0974, -0.0208, -0.0055]],\n",
       "              \n",
       "                       [[-0.0449, -0.0406, -0.0904],\n",
       "                        [-0.0348, -0.0022, -0.0567],\n",
       "                        [-0.0389,  0.0637,  0.0790]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0836,  0.0994,  0.0446],\n",
       "                        [-0.0572,  0.0651, -0.0789],\n",
       "                        [ 0.0734, -0.0984,  0.0846]],\n",
       "              \n",
       "                       [[-0.1016,  0.0176, -0.0827],\n",
       "                        [-0.0868,  0.0600, -0.0816],\n",
       "                        [ 0.0811,  0.0043,  0.0093]],\n",
       "              \n",
       "                       [[ 0.0446, -0.0051, -0.0513],\n",
       "                        [ 0.0148,  0.0229,  0.0560],\n",
       "                        [-0.0828,  0.0752, -0.0586]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[-0.0380, -0.0822, -0.0327],\n",
       "                        [-0.0167, -0.0150, -0.0382],\n",
       "                        [-0.0679,  0.0460, -0.0316]],\n",
       "              \n",
       "                       [[ 0.0440, -0.0563, -0.0822],\n",
       "                        [-0.0657, -0.0609,  0.0375],\n",
       "                        [ 0.0350, -0.0269,  0.0301]],\n",
       "              \n",
       "                       [[-0.0007,  0.0015, -0.0164],\n",
       "                        [-0.0133, -0.0482, -0.0787],\n",
       "                        [-0.0389, -0.0497, -0.0788]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0771, -0.0326, -0.0334],\n",
       "                        [ 0.0176, -0.0124,  0.0281],\n",
       "                        [-0.0769, -0.0280, -0.0700]],\n",
       "              \n",
       "                       [[-0.0539,  0.0501,  0.0526],\n",
       "                        [ 0.0135, -0.0130,  0.0053],\n",
       "                        [ 0.0761, -0.0207,  0.0070]],\n",
       "              \n",
       "                       [[-0.0390, -0.0830, -0.0123],\n",
       "                        [ 0.0051,  0.0064, -0.0687],\n",
       "                        [ 0.0581, -0.0328,  0.0631]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0467, -0.0548,  0.0588],\n",
       "                        [ 0.0541,  0.0028, -0.0124],\n",
       "                        [-0.0677,  0.0819, -0.0045]],\n",
       "              \n",
       "                       [[ 0.0673,  0.0064,  0.0522],\n",
       "                        [ 0.0243,  0.0758,  0.0791],\n",
       "                        [-0.0073,  0.0320, -0.0518]],\n",
       "              \n",
       "                       [[ 0.0476, -0.0162,  0.0310],\n",
       "                        [-0.0552,  0.0326, -0.0023],\n",
       "                        [ 0.0375, -0.0612, -0.0442]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0289, -0.0342,  0.0586],\n",
       "                        [-0.0650, -0.0401,  0.0272],\n",
       "                        [ 0.0376,  0.0284,  0.0239]],\n",
       "              \n",
       "                       [[-0.0649,  0.0243, -0.0777],\n",
       "                        [-0.0195,  0.0599,  0.0649],\n",
       "                        [ 0.0699,  0.0641,  0.0726]],\n",
       "              \n",
       "                       [[-0.0406, -0.0191,  0.0225],\n",
       "                        [ 0.0278,  0.0206, -0.0682],\n",
       "                        [-0.0721, -0.0747,  0.0698]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0758, -0.0651,  0.0781],\n",
       "                        [ 0.0180, -0.0071,  0.0746],\n",
       "                        [-0.0464,  0.0643, -0.0254]],\n",
       "              \n",
       "                       [[ 0.0709,  0.0439,  0.0385],\n",
       "                        [-0.0063, -0.0305, -0.0812],\n",
       "                        [-0.0046,  0.0512,  0.0374]],\n",
       "              \n",
       "                       [[ 0.0768,  0.0062,  0.0119],\n",
       "                        [-0.0268,  0.0245, -0.0522],\n",
       "                        [ 0.0425, -0.0455, -0.0212]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0814, -0.0244, -0.0028],\n",
       "                        [ 0.0432, -0.0115,  0.0603],\n",
       "                        [-0.0725,  0.0208,  0.0424]],\n",
       "              \n",
       "                       [[-0.0523, -0.0365,  0.0521],\n",
       "                        [-0.0215, -0.0478,  0.0372],\n",
       "                        [ 0.0669, -0.0625,  0.0396]],\n",
       "              \n",
       "                       [[-0.0129, -0.0414,  0.0463],\n",
       "                        [-0.0233, -0.0767,  0.0205],\n",
       "                        [-0.0117, -0.0612,  0.0643]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0171,  0.0541,  0.0204],\n",
       "                        [-0.0389,  0.0248, -0.0240],\n",
       "                        [-0.0826,  0.0153,  0.0819]],\n",
       "              \n",
       "                       [[-0.0743,  0.0077, -0.0737],\n",
       "                        [ 0.0050,  0.0442,  0.0028],\n",
       "                        [ 0.0445,  0.0447,  0.0712]],\n",
       "              \n",
       "                       [[ 0.0415, -0.0325, -0.0744],\n",
       "                        [ 0.0404,  0.0160,  0.0474],\n",
       "                        [-0.0713, -0.0352, -0.0186]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0623,  0.0047, -0.0331],\n",
       "                        [ 0.0494,  0.0672, -0.0163],\n",
       "                        [ 0.0051,  0.0485, -0.0351]],\n",
       "              \n",
       "                       [[-0.0762,  0.0651, -0.0662],\n",
       "                        [ 0.0415,  0.0815,  0.0704],\n",
       "                        [ 0.0387,  0.0818, -0.0345]],\n",
       "              \n",
       "                       [[ 0.0808, -0.0167, -0.0591],\n",
       "                        [ 0.0071,  0.0822, -0.0302],\n",
       "                        [-0.0013,  0.0133, -0.0070]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0021, -0.0240,  0.0468],\n",
       "                        [ 0.0039,  0.0322,  0.0253],\n",
       "                        [ 0.0357, -0.0127, -0.0079]],\n",
       "              \n",
       "                       [[-0.0742, -0.0830, -0.0110],\n",
       "                        [-0.0697, -0.0379,  0.0722],\n",
       "                        [-0.0702, -0.0074,  0.0614]],\n",
       "              \n",
       "                       [[-0.0078, -0.0818,  0.0134],\n",
       "                        [ 0.0150, -0.0741,  0.0167],\n",
       "                        [ 0.0681, -0.0404, -0.0013]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0790,  0.0763,  0.0545],\n",
       "                        [-0.0509, -0.0200, -0.0411],\n",
       "                        [ 0.0812, -0.0744, -0.0217]],\n",
       "              \n",
       "                       [[-0.0425,  0.0050, -0.0208],\n",
       "                        [-0.0029, -0.0215, -0.0247],\n",
       "                        [-0.0047, -0.0104,  0.0162]],\n",
       "              \n",
       "                       [[ 0.0578,  0.0369,  0.0385],\n",
       "                        [-0.0501,  0.0211,  0.0213],\n",
       "                        [-0.0578, -0.0487,  0.0652]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0699,  0.0536,  0.0795],\n",
       "                        [ 0.0611,  0.0104,  0.0159],\n",
       "                        [-0.0558,  0.0135, -0.0145]],\n",
       "              \n",
       "                       [[-0.0087,  0.0456, -0.0659],\n",
       "                        [ 0.0495,  0.0794,  0.0374],\n",
       "                        [ 0.0799,  0.0708, -0.0047]],\n",
       "              \n",
       "                       [[ 0.0735, -0.0506, -0.0240],\n",
       "                        [ 0.0179, -0.0156,  0.0635],\n",
       "                        [ 0.0201,  0.0830, -0.0816]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0638, -0.0533, -0.0429],\n",
       "                        [-0.0202,  0.0035, -0.0301],\n",
       "                        [-0.0306,  0.0415, -0.0781]],\n",
       "              \n",
       "                       [[-0.0229, -0.0478,  0.0626],\n",
       "                        [-0.0758, -0.0647, -0.0120],\n",
       "                        [ 0.0761,  0.0208, -0.0356]],\n",
       "              \n",
       "                       [[-0.0581, -0.0272, -0.0789],\n",
       "                        [-0.0314, -0.0623, -0.0250],\n",
       "                        [ 0.0221,  0.0554,  0.0581]]]])),\n",
       "             ('conv3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv4.weight',\n",
       "              tensor([[[[-0.0146,  0.0245,  0.0503],\n",
       "                        [-0.0165, -0.0408, -0.0497],\n",
       "                        [ 0.0318,  0.0424, -0.0320]],\n",
       "              \n",
       "                       [[-0.0704, -0.0334,  0.0465],\n",
       "                        [ 0.0631,  0.0489, -0.0305],\n",
       "                        [ 0.0390,  0.0569,  0.0290]],\n",
       "              \n",
       "                       [[-0.0142,  0.0504, -0.0244],\n",
       "                        [-0.0029, -0.0096, -0.0335],\n",
       "                        [ 0.0423,  0.0142, -0.0224]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0264, -0.0516, -0.0474],\n",
       "                        [-0.0605,  0.0420,  0.0453],\n",
       "                        [-0.0417,  0.0415, -0.0413]],\n",
       "              \n",
       "                       [[-0.0398, -0.0503,  0.0341],\n",
       "                        [-0.0287,  0.0454, -0.0680],\n",
       "                        [-0.0511,  0.0333,  0.0655]],\n",
       "              \n",
       "                       [[-0.0105,  0.0232,  0.0412],\n",
       "                        [ 0.0483, -0.0651,  0.0279],\n",
       "                        [-0.0544,  0.0308,  0.0280]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0059,  0.0388,  0.0448],\n",
       "                        [-0.0180, -0.0432,  0.0016],\n",
       "                        [ 0.0708,  0.0201, -0.0377]],\n",
       "              \n",
       "                       [[-0.0026,  0.0160,  0.0427],\n",
       "                        [-0.0592, -0.0533, -0.0662],\n",
       "                        [-0.0314,  0.0609, -0.0068]],\n",
       "              \n",
       "                       [[-0.0507,  0.0183, -0.0206],\n",
       "                        [ 0.0689,  0.0335,  0.0582],\n",
       "                        [ 0.0071, -0.0268, -0.0529]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0060,  0.0356, -0.0366],\n",
       "                        [ 0.0605, -0.0102,  0.0366],\n",
       "                        [-0.0601, -0.0535, -0.0500]],\n",
       "              \n",
       "                       [[-0.0057, -0.0067,  0.0109],\n",
       "                        [ 0.0367,  0.0145, -0.0130],\n",
       "                        [-0.0663, -0.0513,  0.0651]],\n",
       "              \n",
       "                       [[-0.0664,  0.0214,  0.0054],\n",
       "                        [-0.0201,  0.0593,  0.0429],\n",
       "                        [-0.0050, -0.0035,  0.0495]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0013, -0.0632, -0.0705],\n",
       "                        [-0.0450, -0.0337,  0.0651],\n",
       "                        [-0.0284, -0.0009, -0.0023]],\n",
       "              \n",
       "                       [[ 0.0687,  0.0457, -0.0676],\n",
       "                        [-0.0618, -0.0087,  0.0433],\n",
       "                        [ 0.0180,  0.0226,  0.0250]],\n",
       "              \n",
       "                       [[ 0.0441, -0.0482, -0.0011],\n",
       "                        [ 0.0050,  0.0344,  0.0002],\n",
       "                        [-0.0285, -0.0681, -0.0548]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0318, -0.0132, -0.0164],\n",
       "                        [-0.0089, -0.0092, -0.0649],\n",
       "                        [ 0.0066,  0.0508, -0.0558]],\n",
       "              \n",
       "                       [[-0.0590,  0.0169, -0.0241],\n",
       "                        [ 0.0229, -0.0583, -0.0577],\n",
       "                        [ 0.0180,  0.0660, -0.0673]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0046,  0.0449],\n",
       "                        [-0.0176, -0.0660, -0.0572],\n",
       "                        [-0.0212, -0.0469,  0.0347]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0576, -0.0211,  0.0089],\n",
       "                        [-0.0227, -0.0698, -0.0015],\n",
       "                        [ 0.0411, -0.0185, -0.0181]],\n",
       "              \n",
       "                       [[ 0.0419, -0.0279, -0.0429],\n",
       "                        [-0.0112,  0.0239,  0.0088],\n",
       "                        [ 0.0120,  0.0120,  0.0630]],\n",
       "              \n",
       "                       [[ 0.0275, -0.0543,  0.0531],\n",
       "                        [ 0.0468,  0.0104, -0.0394],\n",
       "                        [ 0.0287, -0.0545, -0.0004]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0615,  0.0249, -0.0663],\n",
       "                        [-0.0627, -0.0653, -0.0645],\n",
       "                        [ 0.0628, -0.0566, -0.0089]],\n",
       "              \n",
       "                       [[-0.0350,  0.0511,  0.0328],\n",
       "                        [ 0.0559,  0.0156,  0.0696],\n",
       "                        [ 0.0345, -0.0307,  0.0023]],\n",
       "              \n",
       "                       [[-0.0638, -0.0589,  0.0312],\n",
       "                        [ 0.0028,  0.0527,  0.0453],\n",
       "                        [-0.0688,  0.0109, -0.0628]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0160,  0.0508,  0.0263],\n",
       "                        [-0.0235,  0.0015, -0.0691],\n",
       "                        [ 0.0656, -0.0213,  0.0637]],\n",
       "              \n",
       "                       [[-0.0623,  0.0083,  0.0016],\n",
       "                        [-0.0052,  0.0043, -0.0633],\n",
       "                        [-0.0305, -0.0651,  0.0486]],\n",
       "              \n",
       "                       [[-0.0200,  0.0507, -0.0660],\n",
       "                        [-0.0064,  0.0041,  0.0184],\n",
       "                        [ 0.0293,  0.0053,  0.0631]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0421,  0.0522,  0.0292],\n",
       "                        [ 0.0140, -0.0418, -0.0116],\n",
       "                        [ 0.0375,  0.0283, -0.0522]],\n",
       "              \n",
       "                       [[ 0.0628,  0.0686,  0.0151],\n",
       "                        [ 0.0121,  0.0559,  0.0682],\n",
       "                        [ 0.0182, -0.0191,  0.0240]],\n",
       "              \n",
       "                       [[ 0.0306,  0.0039, -0.0018],\n",
       "                        [-0.0118, -0.0073, -0.0678],\n",
       "                        [-0.0639,  0.0467, -0.0610]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0134,  0.0527,  0.0460],\n",
       "                        [ 0.0079, -0.0618, -0.0602],\n",
       "                        [-0.0510,  0.0169, -0.0199]],\n",
       "              \n",
       "                       [[-0.0547,  0.0322,  0.0094],\n",
       "                        [ 0.0170, -0.0356, -0.0189],\n",
       "                        [ 0.0359, -0.0300,  0.0641]],\n",
       "              \n",
       "                       [[ 0.0594,  0.0661,  0.0045],\n",
       "                        [ 0.0694, -0.0300, -0.0701],\n",
       "                        [ 0.0225, -0.0071, -0.0408]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0091,  0.0479,  0.0520],\n",
       "                        [ 0.0605,  0.0127,  0.0453],\n",
       "                        [ 0.0385, -0.0480, -0.0366]],\n",
       "              \n",
       "                       [[-0.0720,  0.0427,  0.0664],\n",
       "                        [-0.0080,  0.0066, -0.0266],\n",
       "                        [-0.0245,  0.0475, -0.0659]],\n",
       "              \n",
       "                       [[-0.0417,  0.0614,  0.0084],\n",
       "                        [-0.0720,  0.0099,  0.0359],\n",
       "                        [-0.0401, -0.0451, -0.0357]]]])),\n",
       "             ('conv4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv5.weight',\n",
       "              tensor([[[[ 1.8978e-02,  4.7092e-03,  3.7440e-02],\n",
       "                        [ 5.3522e-02,  3.5813e-04,  2.4903e-02],\n",
       "                        [ 4.0725e-02, -4.0757e-02,  1.5526e-02]],\n",
       "              \n",
       "                       [[-2.3971e-02, -1.8714e-02,  1.8056e-02],\n",
       "                        [ 3.7963e-02, -4.2163e-02, -4.3554e-02],\n",
       "                        [ 3.9615e-02, -1.1127e-03,  5.0148e-02]],\n",
       "              \n",
       "                       [[ 4.6339e-02,  3.2912e-02,  4.1220e-02],\n",
       "                        [-2.7785e-02, -2.6660e-02,  3.8685e-02],\n",
       "                        [ 4.8284e-02, -2.5705e-03,  1.4482e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.1225e-02, -1.2784e-02, -1.5714e-02],\n",
       "                        [ 2.8964e-02, -5.1074e-02,  3.6248e-02],\n",
       "                        [-4.8637e-02,  2.9862e-02, -3.9919e-02]],\n",
       "              \n",
       "                       [[-1.7129e-02, -3.3686e-02,  2.8434e-02],\n",
       "                        [ 8.9197e-03, -2.4467e-02,  1.1243e-02],\n",
       "                        [ 4.5127e-02, -8.1672e-03,  5.2605e-02]],\n",
       "              \n",
       "                       [[ 4.9375e-02,  2.5364e-02, -5.2769e-02],\n",
       "                        [-1.5267e-03,  3.7809e-02, -3.3620e-03],\n",
       "                        [-2.2692e-02, -3.3024e-02,  4.7714e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1720e-02,  5.7168e-02, -3.2635e-02],\n",
       "                        [-4.3472e-02,  1.0453e-02, -4.3330e-02],\n",
       "                        [-5.3001e-02, -2.9507e-02,  1.1738e-02]],\n",
       "              \n",
       "                       [[-2.5253e-02, -1.5779e-02,  3.4297e-02],\n",
       "                        [ 1.3207e-02,  1.3481e-02,  5.3888e-02],\n",
       "                        [ 1.9366e-02, -5.7843e-02,  5.6537e-02]],\n",
       "              \n",
       "                       [[-1.1956e-02, -5.8496e-02, -2.1499e-02],\n",
       "                        [ 1.2193e-02, -2.9690e-02, -2.8425e-02],\n",
       "                        [ 1.5992e-02,  2.9690e-02,  3.4357e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.5070e-02,  1.7886e-02,  4.9981e-02],\n",
       "                        [-5.5205e-03, -3.3171e-02, -1.2248e-02],\n",
       "                        [ 1.4042e-03, -4.4383e-02, -5.7238e-02]],\n",
       "              \n",
       "                       [[ 1.4991e-02, -2.2138e-02,  5.3482e-02],\n",
       "                        [-2.3419e-02, -5.0295e-02,  3.8594e-02],\n",
       "                        [ 1.4597e-02,  1.1616e-02, -9.5841e-05]],\n",
       "              \n",
       "                       [[-5.2827e-02,  5.7256e-02,  4.0432e-02],\n",
       "                        [-3.9031e-02, -2.2777e-02, -2.9180e-02],\n",
       "                        [ 3.7373e-02,  1.1849e-02, -2.7951e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5661e-03,  4.1279e-02, -5.6953e-02],\n",
       "                        [-5.1805e-03, -2.7027e-02, -3.7144e-02],\n",
       "                        [ 2.7518e-02,  4.7283e-02,  9.4664e-03]],\n",
       "              \n",
       "                       [[ 5.1402e-02, -2.1524e-02,  3.6600e-02],\n",
       "                        [-5.6981e-02,  3.9675e-02, -2.7480e-02],\n",
       "                        [-5.0387e-02,  1.7133e-02, -4.6529e-02]],\n",
       "              \n",
       "                       [[ 1.9169e-02,  3.2005e-02,  1.0995e-02],\n",
       "                        [-4.6558e-02,  3.0313e-02,  3.2892e-02],\n",
       "                        [-1.5206e-02, -2.2851e-02,  7.7148e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.5370e-02,  4.5422e-02, -3.4465e-02],\n",
       "                        [ 3.4022e-02,  1.0738e-02,  3.7217e-02],\n",
       "                        [ 3.9241e-02,  2.7236e-02,  5.1693e-02]],\n",
       "              \n",
       "                       [[-5.5030e-02,  1.7094e-03, -5.4341e-02],\n",
       "                        [-3.3946e-02,  4.0656e-02, -1.2784e-02],\n",
       "                        [ 3.1684e-02,  2.1780e-02, -5.4291e-02]],\n",
       "              \n",
       "                       [[ 2.0810e-02, -4.5381e-02,  2.6793e-02],\n",
       "                        [ 4.9592e-02, -6.6406e-03,  4.1852e-02],\n",
       "                        [-3.5151e-02, -5.6715e-02,  1.8069e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7359e-02, -4.3743e-02,  4.6165e-02],\n",
       "                        [ 2.0620e-02, -4.7282e-02,  5.8894e-02],\n",
       "                        [ 4.4250e-02,  4.5013e-02,  5.2911e-02]],\n",
       "              \n",
       "                       [[ 5.3454e-02, -1.1725e-02, -2.6088e-02],\n",
       "                        [-5.5833e-02, -5.4977e-03,  4.7291e-02],\n",
       "                        [-3.0756e-02,  4.1857e-02, -3.9611e-02]],\n",
       "              \n",
       "                       [[ 2.2264e-03,  9.2930e-04,  1.4883e-02],\n",
       "                        [ 4.1942e-02, -2.6589e-03, -2.6841e-02],\n",
       "                        [ 1.2092e-02,  3.6832e-03, -2.9566e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.1297e-03,  5.6053e-02,  4.9749e-02],\n",
       "                        [ 2.4239e-02, -2.8116e-02,  2.6236e-02],\n",
       "                        [-2.9188e-02, -2.8687e-02,  5.8549e-02]],\n",
       "              \n",
       "                       [[-2.8258e-02, -5.2234e-03, -6.0338e-03],\n",
       "                        [-1.5823e-02, -1.3664e-02, -9.0069e-04],\n",
       "                        [-2.2870e-02,  5.5489e-02, -2.6870e-02]],\n",
       "              \n",
       "                       [[-2.2746e-02,  3.7852e-02, -1.0044e-02],\n",
       "                        [-2.2441e-02,  1.4696e-02,  5.0374e-03],\n",
       "                        [ 2.3287e-02,  4.4877e-02, -1.0492e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8506e-02,  5.5350e-02,  1.8175e-02],\n",
       "                        [-1.4125e-02, -4.6941e-02, -4.1003e-02],\n",
       "                        [ 2.3789e-02, -3.7719e-02,  1.9419e-03]],\n",
       "              \n",
       "                       [[-3.2281e-02,  2.9313e-02,  4.9569e-03],\n",
       "                        [-5.0487e-02, -8.6702e-03,  5.5330e-02],\n",
       "                        [-1.7502e-02,  1.9032e-02,  2.4123e-02]],\n",
       "              \n",
       "                       [[ 5.0800e-02, -5.5949e-02,  3.1478e-02],\n",
       "                        [-2.7571e-02,  2.2018e-02, -1.2838e-02],\n",
       "                        [ 1.8905e-02,  3.8312e-02,  2.6530e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.8439e-02, -3.9315e-02,  1.9784e-02],\n",
       "                        [ 1.2350e-02, -2.4309e-02, -3.3692e-02],\n",
       "                        [ 2.8096e-02,  4.5792e-02,  1.0863e-02]],\n",
       "              \n",
       "                       [[-5.0897e-02,  2.7652e-02, -1.6064e-02],\n",
       "                        [ 5.0639e-02, -1.6839e-02,  3.0262e-02],\n",
       "                        [-3.2675e-02,  4.0442e-02,  4.9966e-02]],\n",
       "              \n",
       "                       [[ 4.7573e-02, -3.3111e-02, -8.4507e-03],\n",
       "                        [-1.7066e-02,  4.6808e-02, -5.7762e-02],\n",
       "                        [ 2.2654e-02,  3.8643e-02, -4.9913e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2474e-02,  1.4436e-02,  1.9946e-02],\n",
       "                        [ 4.9028e-02,  1.8727e-02,  8.6075e-03],\n",
       "                        [-4.5496e-02,  2.2093e-03,  1.4622e-02]],\n",
       "              \n",
       "                       [[ 3.4235e-04,  1.7005e-02,  5.8103e-02],\n",
       "                        [ 4.6782e-02,  4.8256e-02, -8.7809e-04],\n",
       "                        [-2.2718e-02, -1.0547e-03,  3.5563e-02]],\n",
       "              \n",
       "                       [[ 3.8262e-02, -4.5658e-02,  2.9399e-02],\n",
       "                        [-4.3355e-02, -2.5447e-02,  2.7410e-02],\n",
       "                        [ 9.7755e-03, -3.8522e-03, -1.7858e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.3028e-03,  5.8914e-03, -4.3714e-02],\n",
       "                        [ 2.7817e-02,  5.0738e-02,  1.7159e-02],\n",
       "                        [ 2.0392e-02,  2.7240e-02,  1.1273e-02]],\n",
       "              \n",
       "                       [[-1.9604e-02,  4.0601e-02, -3.2021e-02],\n",
       "                        [ 1.4925e-02,  8.1327e-03, -2.4335e-02],\n",
       "                        [ 3.9010e-02, -5.3087e-02, -5.3215e-02]],\n",
       "              \n",
       "                       [[-5.2285e-02,  5.6556e-02, -2.4598e-02],\n",
       "                        [-3.6364e-02, -2.5088e-02,  1.7828e-02],\n",
       "                        [ 2.3737e-02,  2.3305e-02, -5.1789e-03]]]])),\n",
       "             ('conv5.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv6.weight',\n",
       "              tensor([[[[-0.0023, -0.0481, -0.0508],\n",
       "                        [ 0.0371,  0.0052,  0.0125],\n",
       "                        [ 0.0392, -0.0401, -0.0426]],\n",
       "              \n",
       "                       [[ 0.0277,  0.0102, -0.0123],\n",
       "                        [-0.0234,  0.0167,  0.0111],\n",
       "                        [ 0.0185,  0.0068,  0.0481]],\n",
       "              \n",
       "                       [[ 0.0002,  0.0152, -0.0021],\n",
       "                        [-0.0067, -0.0488, -0.0288],\n",
       "                        [-0.0171, -0.0375, -0.0484]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0174, -0.0030, -0.0339],\n",
       "                        [ 0.0096,  0.0325, -0.0050],\n",
       "                        [-0.0376, -0.0366,  0.0006]],\n",
       "              \n",
       "                       [[ 0.0074,  0.0299, -0.0295],\n",
       "                        [-0.0300, -0.0079,  0.0069],\n",
       "                        [-0.0235, -0.0212,  0.0259]],\n",
       "              \n",
       "                       [[-0.0268, -0.0441, -0.0106],\n",
       "                        [ 0.0231, -0.0313, -0.0293],\n",
       "                        [ 0.0455,  0.0277,  0.0055]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0430,  0.0243, -0.0285],\n",
       "                        [-0.0374,  0.0085, -0.0179],\n",
       "                        [ 0.0311, -0.0319, -0.0164]],\n",
       "              \n",
       "                       [[ 0.0311,  0.0154, -0.0283],\n",
       "                        [-0.0415, -0.0282,  0.0169],\n",
       "                        [ 0.0192, -0.0465, -0.0240]],\n",
       "              \n",
       "                       [[ 0.0288,  0.0079, -0.0111],\n",
       "                        [-0.0066,  0.0492, -0.0243],\n",
       "                        [ 0.0458, -0.0206, -0.0085]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0080, -0.0265,  0.0435],\n",
       "                        [-0.0458, -0.0026,  0.0361],\n",
       "                        [-0.0124,  0.0366, -0.0359]],\n",
       "              \n",
       "                       [[-0.0311,  0.0506, -0.0405],\n",
       "                        [ 0.0023, -0.0184,  0.0092],\n",
       "                        [-0.0492,  0.0079,  0.0224]],\n",
       "              \n",
       "                       [[ 0.0509,  0.0390, -0.0068],\n",
       "                        [ 0.0294, -0.0278, -0.0291],\n",
       "                        [ 0.0242, -0.0423, -0.0463]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0303, -0.0308,  0.0394],\n",
       "                        [-0.0113, -0.0147, -0.0227],\n",
       "                        [-0.0159,  0.0384, -0.0036]],\n",
       "              \n",
       "                       [[ 0.0368,  0.0050,  0.0286],\n",
       "                        [-0.0481, -0.0362, -0.0333],\n",
       "                        [ 0.0341,  0.0034,  0.0408]],\n",
       "              \n",
       "                       [[-0.0403, -0.0096,  0.0450],\n",
       "                        [-0.0064,  0.0202,  0.0043],\n",
       "                        [-0.0333, -0.0126, -0.0472]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0428,  0.0114, -0.0118],\n",
       "                        [-0.0427, -0.0246,  0.0195],\n",
       "                        [ 0.0091, -0.0151, -0.0293]],\n",
       "              \n",
       "                       [[ 0.0176, -0.0111, -0.0139],\n",
       "                        [-0.0422, -0.0426,  0.0243],\n",
       "                        [-0.0374, -0.0092, -0.0243]],\n",
       "              \n",
       "                       [[ 0.0003,  0.0126, -0.0426],\n",
       "                        [ 0.0022,  0.0412, -0.0332],\n",
       "                        [ 0.0099, -0.0284,  0.0065]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0446,  0.0374,  0.0111],\n",
       "                        [-0.0253, -0.0487,  0.0297],\n",
       "                        [ 0.0067, -0.0493, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0039,  0.0490,  0.0162],\n",
       "                        [ 0.0158, -0.0408,  0.0085],\n",
       "                        [-0.0321, -0.0325, -0.0402]],\n",
       "              \n",
       "                       [[-0.0326,  0.0097, -0.0343],\n",
       "                        [-0.0236,  0.0021, -0.0399],\n",
       "                        [-0.0328,  0.0195,  0.0447]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0282,  0.0502,  0.0102],\n",
       "                        [-0.0083, -0.0492,  0.0087],\n",
       "                        [-0.0244,  0.0277,  0.0294]],\n",
       "              \n",
       "                       [[-0.0351, -0.0094, -0.0142],\n",
       "                        [ 0.0444, -0.0068, -0.0199],\n",
       "                        [-0.0259, -0.0004,  0.0295]],\n",
       "              \n",
       "                       [[ 0.0247,  0.0460, -0.0404],\n",
       "                        [-0.0235,  0.0345, -0.0283],\n",
       "                        [-0.0296,  0.0034,  0.0024]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0274, -0.0482,  0.0119],\n",
       "                        [ 0.0009,  0.0042,  0.0121],\n",
       "                        [ 0.0049, -0.0033,  0.0289]],\n",
       "              \n",
       "                       [[-0.0201,  0.0324, -0.0310],\n",
       "                        [ 0.0137, -0.0160, -0.0035],\n",
       "                        [ 0.0234,  0.0227, -0.0213]],\n",
       "              \n",
       "                       [[-0.0339, -0.0120, -0.0203],\n",
       "                        [ 0.0100,  0.0329, -0.0040],\n",
       "                        [ 0.0138, -0.0239, -0.0489]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0265, -0.0030, -0.0138],\n",
       "                        [ 0.0502, -0.0257,  0.0299],\n",
       "                        [ 0.0018, -0.0107,  0.0368]],\n",
       "              \n",
       "                       [[-0.0275,  0.0216,  0.0363],\n",
       "                        [-0.0166, -0.0083,  0.0392],\n",
       "                        [-0.0276, -0.0350,  0.0164]],\n",
       "              \n",
       "                       [[ 0.0213,  0.0369,  0.0509],\n",
       "                        [ 0.0303,  0.0017, -0.0213],\n",
       "                        [ 0.0147,  0.0459, -0.0127]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0493, -0.0037, -0.0067],\n",
       "                        [ 0.0199,  0.0463,  0.0349],\n",
       "                        [ 0.0013, -0.0328,  0.0192]],\n",
       "              \n",
       "                       [[ 0.0074, -0.0375, -0.0018],\n",
       "                        [ 0.0317,  0.0489,  0.0231],\n",
       "                        [-0.0438, -0.0476,  0.0199]],\n",
       "              \n",
       "                       [[-0.0028, -0.0150,  0.0285],\n",
       "                        [ 0.0172,  0.0337,  0.0507],\n",
       "                        [ 0.0383, -0.0292,  0.0212]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0131, -0.0259, -0.0201],\n",
       "                        [ 0.0249,  0.0327, -0.0074],\n",
       "                        [ 0.0379,  0.0008,  0.0377]],\n",
       "              \n",
       "                       [[ 0.0166, -0.0359, -0.0427],\n",
       "                        [ 0.0046, -0.0368,  0.0262],\n",
       "                        [-0.0044, -0.0320,  0.0216]],\n",
       "              \n",
       "                       [[-0.0119,  0.0091,  0.0447],\n",
       "                        [-0.0424, -0.0013,  0.0118],\n",
       "                        [ 0.0106, -0.0459,  0.0090]]]])),\n",
       "             ('conv6.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0327,  0.0200, -0.0005,  ...,  0.0280,  0.0522, -0.0452],\n",
       "                      [ 0.0137, -0.0041, -0.0565,  ..., -0.0079,  0.0471,  0.0357],\n",
       "                      [ 0.0147,  0.0539, -0.0547,  ..., -0.0110, -0.0532,  0.0566],\n",
       "                      ...,\n",
       "                      [-0.0424, -0.0414,  0.0332,  ..., -0.0651, -0.0439,  0.0181],\n",
       "                      [ 0.0173,  0.0100,  0.0245,  ..., -0.0002,  0.0055,  0.0478],\n",
       "                      [-0.0336,  0.0433,  0.0067,  ..., -0.0116, -0.0413,  0.0129]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0604, -0.1138, -0.0147,  ...,  0.0447,  0.1094, -0.0725],\n",
       "                      [-0.1323, -0.1377, -0.0193,  ..., -0.0557,  0.1190, -0.0692],\n",
       "                      [ 0.0279,  0.0594, -0.0671,  ..., -0.1254, -0.1442,  0.0253],\n",
       "                      ...,\n",
       "                      [ 0.1277,  0.1208,  0.0420,  ..., -0.1199,  0.0789, -0.0692],\n",
       "                      [ 0.0180,  0.1045,  0.1016,  ..., -0.0503,  0.1184, -0.1106],\n",
       "                      [ 0.0122, -0.0600,  0.0363,  ...,  0.0199, -0.0632,  0.1131]])),\n",
       "             ('fc2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.253581Z",
     "start_time": "2025-07-01T02:08:23.145707Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class TensorboardLogger:\n",
    "    \"\"\"\n",
    "    Tensorboard日志记录类：记录训练过程中的损失和准确率\n",
    "    \n",
    "    参数:\n",
    "        log_dir: 日志保存目录,log_dir的父目录不要有中文\n",
    "    \"\"\"\n",
    "    def __init__(self, log_dir='tensorboard_logs'):\n",
    "\n",
    "        import os\n",
    "        \n",
    "        # 确保日志目录存在\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "            \n",
    "        self.writer = SummaryWriter(log_dir) # 实例化SummaryWriter, log_dir是log存放路径，flush_secs是每隔多少秒写入磁盘\n",
    "        \n",
    "    def log_training(self, epoch, train_loss, train_acc):\n",
    "        \"\"\"\n",
    "        记录训练数据\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            train_loss: 训练损失\n",
    "            train_acc: 训练准确率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('训练/损失', train_loss, epoch)\n",
    "        self.writer.add_scalar('训练/准确率', train_acc, epoch)\n",
    "        \n",
    "    def log_validation(self, epoch, val_loss, val_acc):\n",
    "        \"\"\"\n",
    "        记录验证数据\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            val_loss: 验证损失\n",
    "            val_acc: 验证准确率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('验证/损失', val_loss, epoch)\n",
    "        self.writer.add_scalar('验证/准确率', val_acc, epoch)\n",
    "    \n",
    "    def log_lr(self, epoch, lr):\n",
    "        \"\"\"\n",
    "        记录学习率\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            lr: 学习率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('学习率', lr, epoch)\n",
    "        \n",
    "    def log_model_graph(self, model, images):\n",
    "        \"\"\"\n",
    "        记录模型结构图\n",
    "        \n",
    "        参数:\n",
    "            model: 模型\n",
    "            images: 输入图像样本\n",
    "        \"\"\"\n",
    "        self.writer.add_graph(model, images)\n",
    "        \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        关闭Tensorboard写入器\n",
    "        \"\"\"\n",
    "        self.writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置交叉熵损失函数，SGD优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.263968Z",
     "start_time": "2025-07-01T02:08:23.254586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数，适用于多分类问题，里边会做softmax，还有会把0-9标签转换成one-hot编码\n",
    "\n",
    "print(\"损失函数:\", loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:08:23.273557Z",
     "start_time": "2025-07-01T02:08:23.264977Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD优化器，学习率为0.01，动量为0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:12:10.641291Z",
     "start_time": "2025-07-01T02:08:23.275073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n",
      "训练开始，共43000步\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccbcc7faad347d0be4a0fa39fa657c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "早停触发! 最佳验证准确率(如果是回归，这里是损失): 85.3600\n",
      "早停: 在2950 步\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "model = model.to(device) #将模型移动到GPU\n",
    "early_stopping=EarlyStopping(patience=5, delta=0.001)\n",
    "model_saver=ModelSaver(save_dir='model_weights', save_best_only=True)\n",
    "tensorboard_logger=TensorboardLogger(log_dir='logs')\n",
    "\n",
    "model, history = train_classification_model(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=50, early_stopping=early_stopping, model_saver=model_saver, tensorboard_logger=tensorboard_logger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:12:10.649324Z",
     "start_time": "2025-07-01T02:12:10.642297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.38798391819000244, 'acc': 85.9375, 'step': 2851},\n",
       " {'loss': 0.3735359311103821, 'acc': 85.9375, 'step': 2852},\n",
       " {'loss': 0.32468026876449585, 'acc': 87.5, 'step': 2853},\n",
       " {'loss': 0.33423346281051636, 'acc': 85.9375, 'step': 2854},\n",
       " {'loss': 0.41404426097869873, 'acc': 82.8125, 'step': 2855},\n",
       " {'loss': 0.46258026361465454, 'acc': 81.25, 'step': 2856},\n",
       " {'loss': 0.3360635042190552, 'acc': 87.5, 'step': 2857},\n",
       " {'loss': 0.45003122091293335, 'acc': 85.9375, 'step': 2858},\n",
       " {'loss': 0.5153988599777222, 'acc': 79.6875, 'step': 2859},\n",
       " {'loss': 0.41708558797836304, 'acc': 87.5, 'step': 2860},\n",
       " {'loss': 0.6200683116912842, 'acc': 76.5625, 'step': 2861},\n",
       " {'loss': 0.225714311003685, 'acc': 92.1875, 'step': 2862},\n",
       " {'loss': 0.38097307085990906, 'acc': 92.1875, 'step': 2863},\n",
       " {'loss': 0.475285142660141, 'acc': 81.25, 'step': 2864},\n",
       " {'loss': 0.37844160199165344, 'acc': 87.5, 'step': 2865},\n",
       " {'loss': 0.3097662925720215, 'acc': 92.1875, 'step': 2866},\n",
       " {'loss': 0.31228068470954895, 'acc': 90.625, 'step': 2867},\n",
       " {'loss': 0.3169848322868347, 'acc': 92.1875, 'step': 2868},\n",
       " {'loss': 0.36223798990249634, 'acc': 89.0625, 'step': 2869},\n",
       " {'loss': 0.43857109546661377, 'acc': 84.375, 'step': 2870},\n",
       " {'loss': 0.5376589298248291, 'acc': 85.9375, 'step': 2871},\n",
       " {'loss': 0.26612886786460876, 'acc': 89.0625, 'step': 2872},\n",
       " {'loss': 0.4202256500720978, 'acc': 84.375, 'step': 2873},\n",
       " {'loss': 0.4267832636833191, 'acc': 81.25, 'step': 2874},\n",
       " {'loss': 0.2977274954319, 'acc': 85.9375, 'step': 2875},\n",
       " {'loss': 0.31499698758125305, 'acc': 85.9375, 'step': 2876},\n",
       " {'loss': 0.5573943853378296, 'acc': 76.5625, 'step': 2877},\n",
       " {'loss': 0.566741943359375, 'acc': 82.8125, 'step': 2878},\n",
       " {'loss': 0.33506107330322266, 'acc': 90.625, 'step': 2879},\n",
       " {'loss': 0.35122308135032654, 'acc': 89.0625, 'step': 2880},\n",
       " {'loss': 0.33515313267707825, 'acc': 85.9375, 'step': 2881},\n",
       " {'loss': 0.31159794330596924, 'acc': 93.75, 'step': 2882},\n",
       " {'loss': 0.5337215662002563, 'acc': 87.5, 'step': 2883},\n",
       " {'loss': 0.4003205895423889, 'acc': 87.5, 'step': 2884},\n",
       " {'loss': 0.37951725721359253, 'acc': 82.8125, 'step': 2885},\n",
       " {'loss': 0.42778798937797546, 'acc': 87.5, 'step': 2886},\n",
       " {'loss': 0.38428786396980286, 'acc': 82.8125, 'step': 2887},\n",
       " {'loss': 0.3940827548503876, 'acc': 87.5, 'step': 2888},\n",
       " {'loss': 0.4088118076324463, 'acc': 78.125, 'step': 2889},\n",
       " {'loss': 0.27340787649154663, 'acc': 89.0625, 'step': 2890},\n",
       " {'loss': 0.5245798230171204, 'acc': 84.375, 'step': 2891},\n",
       " {'loss': 0.4515169858932495, 'acc': 85.9375, 'step': 2892},\n",
       " {'loss': 0.5396751761436462, 'acc': 75.0, 'step': 2893},\n",
       " {'loss': 0.4012449085712433, 'acc': 81.25, 'step': 2894},\n",
       " {'loss': 0.4156782925128937, 'acc': 78.125, 'step': 2895},\n",
       " {'loss': 0.52199786901474, 'acc': 78.125, 'step': 2896},\n",
       " {'loss': 0.3749311566352844, 'acc': 90.625, 'step': 2897},\n",
       " {'loss': 0.21114753186702728, 'acc': 96.875, 'step': 2898},\n",
       " {'loss': 0.4754507839679718, 'acc': 79.6875, 'step': 2899},\n",
       " {'loss': 0.2527037560939789, 'acc': 90.625, 'step': 2900},\n",
       " {'loss': 0.4329814314842224, 'acc': 87.5, 'step': 2901},\n",
       " {'loss': 0.32494762539863586, 'acc': 87.5, 'step': 2902},\n",
       " {'loss': 0.33180221915245056, 'acc': 89.0625, 'step': 2903},\n",
       " {'loss': 0.4541432559490204, 'acc': 84.375, 'step': 2904},\n",
       " {'loss': 0.4250510632991791, 'acc': 87.5, 'step': 2905},\n",
       " {'loss': 0.5510855913162231, 'acc': 79.6875, 'step': 2906},\n",
       " {'loss': 0.27172526717185974, 'acc': 92.1875, 'step': 2907},\n",
       " {'loss': 0.34724631905555725, 'acc': 90.625, 'step': 2908},\n",
       " {'loss': 0.3827674388885498, 'acc': 93.75, 'step': 2909},\n",
       " {'loss': 0.5314205884933472, 'acc': 79.6875, 'step': 2910},\n",
       " {'loss': 0.3432658016681671, 'acc': 87.5, 'step': 2911},\n",
       " {'loss': 0.3492264151573181, 'acc': 87.5, 'step': 2912},\n",
       " {'loss': 0.1994851678609848, 'acc': 95.3125, 'step': 2913},\n",
       " {'loss': 0.6404562592506409, 'acc': 81.25, 'step': 2914},\n",
       " {'loss': 0.6156826615333557, 'acc': 78.125, 'step': 2915},\n",
       " {'loss': 0.3552106022834778, 'acc': 84.375, 'step': 2916},\n",
       " {'loss': 0.7041632533073425, 'acc': 79.6875, 'step': 2917},\n",
       " {'loss': 0.5319028496742249, 'acc': 76.5625, 'step': 2918},\n",
       " {'loss': 0.4407682418823242, 'acc': 85.9375, 'step': 2919},\n",
       " {'loss': 0.311423122882843, 'acc': 87.5, 'step': 2920},\n",
       " {'loss': 0.4268357455730438, 'acc': 82.8125, 'step': 2921},\n",
       " {'loss': 0.30327364802360535, 'acc': 93.75, 'step': 2922},\n",
       " {'loss': 0.29306796193122864, 'acc': 92.1875, 'step': 2923},\n",
       " {'loss': 0.4091688096523285, 'acc': 82.8125, 'step': 2924},\n",
       " {'loss': 0.4088535010814667, 'acc': 87.5, 'step': 2925},\n",
       " {'loss': 0.47648313641548157, 'acc': 84.375, 'step': 2926},\n",
       " {'loss': 0.3322567939758301, 'acc': 84.375, 'step': 2927},\n",
       " {'loss': 0.3249768018722534, 'acc': 84.375, 'step': 2928},\n",
       " {'loss': 0.3826221823692322, 'acc': 84.375, 'step': 2929},\n",
       " {'loss': 0.4729467034339905, 'acc': 79.6875, 'step': 2930},\n",
       " {'loss': 0.3942934274673462, 'acc': 82.8125, 'step': 2931},\n",
       " {'loss': 0.3189782202243805, 'acc': 92.1875, 'step': 2932},\n",
       " {'loss': 0.5110663771629333, 'acc': 82.8125, 'step': 2933},\n",
       " {'loss': 0.6803709864616394, 'acc': 76.5625, 'step': 2934},\n",
       " {'loss': 0.28567418456077576, 'acc': 95.3125, 'step': 2935},\n",
       " {'loss': 0.565512478351593, 'acc': 79.6875, 'step': 2936},\n",
       " {'loss': 0.4994018077850342, 'acc': 76.5625, 'step': 2937},\n",
       " {'loss': 0.3621228039264679, 'acc': 87.5, 'step': 2938},\n",
       " {'loss': 0.40001073479652405, 'acc': 79.6875, 'step': 2939},\n",
       " {'loss': 0.36176207661628723, 'acc': 87.5, 'step': 2940},\n",
       " {'loss': 0.3425690531730652, 'acc': 90.625, 'step': 2941},\n",
       " {'loss': 0.30373525619506836, 'acc': 92.1875, 'step': 2942},\n",
       " {'loss': 0.4426393508911133, 'acc': 85.9375, 'step': 2943},\n",
       " {'loss': 0.4501921534538269, 'acc': 84.375, 'step': 2944},\n",
       " {'loss': 0.30872952938079834, 'acc': 89.0625, 'step': 2945},\n",
       " {'loss': 0.27539095282554626, 'acc': 90.625, 'step': 2946},\n",
       " {'loss': 0.45876649022102356, 'acc': 84.375, 'step': 2947},\n",
       " {'loss': 0.3228302299976349, 'acc': 84.375, 'step': 2948},\n",
       " {'loss': 0.2588226795196533, 'acc': 90.625, 'step': 2949}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['train'][-100:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制损失曲线和准确率曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:12:10.756208Z",
     "start_time": "2025-07-01T02:12:10.650331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(history, sample_step=500)  #横坐标是 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:12:13.697066Z",
     "start_time": "2025-07-01T02:12:10.756208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84.01, 0.4510127933502197)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在测试集上评估模型\n",
    "test_accuracy = evaluate_model(model, test_loader, device, loss_fn)\n",
    "test_accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
