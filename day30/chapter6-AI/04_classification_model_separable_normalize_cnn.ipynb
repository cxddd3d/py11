{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrKLbsAe3ZsK"
   },
   "source": [
    "# 查看FashionMNIST原始数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:19.171199Z",
     "start_time": "2025-07-01T02:13:15.741111Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "wvOVS_Ll3ZsL",
    "outputId": "7b9b07b6-fc85-4efc-ed77-85882730372e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x1C424795D90>, 9)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+tbw1oNx4m8QWmkWx2yXD4LkZCADJJ+gFbviL4a63oc7COE3MW4hdn38duD976jNc9daDqllIsc9lKrMu4YGeMkdR7gj8KzcV7H8BtEvV16+1iWCeG1Wz8mOV02pIzupwCeuAp6Z98cZ90aIzLIlw0c0ZJ4KgjHoeOa+evjS9n/wnMcNxBPCYLKONFhA2FNzMpGenDcgd816V4K03wefC+m3NlpVhP+5QSXBiR5fMx825iMg5zwce3FdbOzTwgW90lu6uCm8eYrL02soIyCPQgggEdMGQ3cluiPNK0rJwrRQBNueuMkt+teNfGKxsdY8WWdxNqcNo66eieXMwVsb5DnH415Hp2rajpE5n02/urOUjBe3laMkehIPIrVm8eeLrhNknibVivoLtx/I1UPinxC3XXtUP1vJP8ay5JZJpGkldnduSzHJP41//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACS0lEQVR4AWKgA2BkYOD1ZGBgZAHZxcjIAKZBbBBm+quS8v3rj1N/GBiZGP8wMKNIMv91cnnCzuU65+X/vww8/76hSP5iMFVgZtpp2HXm8nUz02PHGUHGQTHjf9cugd//GE7f+cUo8ft0yDSEJCMDw/8TCgyMf34x/Ph3/vYfT0VphLH/GRgY3kt+Z2fl+cH5z8aSSWwHqmsZuJiZvn18p/CPkYnr7z9ZBiaofQwMjMwMPFI/frH++sr/j537K9sldhOE5H9mhnBJJg4Gbtlf7L//cQhvusaCkGT5xXDlBxsXl6rSD2Yunr9PoraeYAGZx8T4+x/DHwaGbV+/s/1/zczxm+H3P2a9jwxMDMz///z6+Y+BwW7ime9v//z78/XrXw6GbwxsX4NAYc3AICSlJhmk/oPpN+czVjbhX1zHeOz+fWR9qcnIYNkkKvCX+cMfrl+M36+HneEVVGC4x/v5GycPHxcj83GpP3+/MTB/Z2DgF0lwy3z24/49VeFfrLxsf+UBY0xqv8vDw87Ayv/4mSiTRACHIrexMdMvJjYGRlYLlpeP+X485mHje/eQ5/uPP+svKwj9+vD77y/Wf4xsaixP/z/mFvnw5jULOysHL9Mbza+P37O/+f3nN6fERwOWC+sTn937wcPGwcb88+//by/+/WX5wfPrw4fffxRfMjIweBWLv/7wl5mNhZnxPysrGysjA+NLBrZ/EpfCGJn+MTA4tYnxMzGz/GV8+f/pvy/MDP9/f2Paff0YJBAYGBg0RN/LPPx1Fx5HFDIAaCTYdiCc4RIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from wangdao_deeplearning_train import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from wangdao_deeplearning_train import evaluate_classification_model as evaluate_model\n",
    "# 加载Fashion MNIST数据集，张量就是和numpy数组一样\n",
    "transform = transforms.Compose([])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "print(train_dataset[0])\n",
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geDUCUf73ZsM"
   },
   "source": [
    "# 加载数据并处理为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:19.213541Z",
     "start_time": "2025-07-01T02:13:19.173477Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcvE1JTb3ZsM",
    "outputId": "c0788dfb-ddad-499a-ba1e-d126b5829fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状: (60000, 28, 28)\n",
      "训练集标签数量: 60000\n",
      "测试集形状: (10000, 28, 28)\n",
      "测试集标签数量: 10000\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
      "    0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
      "   54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      "  144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
      "  107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
      "  216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
      "  223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
      "  180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
      "  169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
      "  198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
      "  232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
      "  222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
      "  211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
      "  224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
      "  255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
      "  168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
      "  239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
      "  199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
      "  195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
      "  210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
      "  182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载Fashion MNIST数据集，张量就是和numpy数组一样\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# 获取图像和标签\n",
    "# 注意：由于使用了transform，图像已经被转换为张量且标准化\n",
    "# 我们需要从dataset中提取原始图像用于显示\n",
    "train_images = train_dataset.data.numpy()\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "test_images = test_dataset.data.numpy()\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "# 定义类别名称\n",
    "class_names = ['T-shirt/top', '裤子', '套头衫', '连衣裙', '外套',\n",
    "               '凉鞋', '衬衫', '运动鞋', '包', '短靴']\n",
    "\n",
    "# 查看数据集基本信息\n",
    "print(f\"训练集形状: {train_images.shape}\")\n",
    "print(f\"训练集标签数量: {len(train_labels)}\")\n",
    "print(f\"测试集形状: {test_images.shape}\")\n",
    "print(f\"测试集标签数量: {len(test_labels)}\")\n",
    "\n",
    "print(train_images[0])\n",
    "\n",
    "train_labels[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:19.226911Z",
     "start_time": "2025-07-01T02:13:19.215788Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V709pV6l3ZsM",
    "outputId": "bf893bc4-5724-4865-9a2f-c4643226893d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看归一化后的效果\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:19.235598Z",
     "start_time": "2025-07-01T02:13:19.229918Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQJ2eGJB3ZsN",
    "outputId": "ca5bea24-830a-4a5d-cb53-ccd8aa133745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:19.243983Z",
     "start_time": "2025-07-01T02:13:19.237604Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pi0p8M2N3ZsN",
    "outputId": "07fe24d7-8164-4d00-f400-df9898a3857f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZRjZoWH3ZsN"
   },
   "source": [
    "# 把数据集划分为训练集55000和验证集5000，并给DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:19.252617Z",
     "start_time": "2025-07-01T02:13:19.244989Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4k_Rrl_3ZsN",
    "outputId": "50ae79bc-6366-4610-ff96-9371f14c5dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 55000\n",
      "验证集大小: 5000\n",
      "测试集大小: 10000\n",
      "批次大小: 64\n",
      "训练批次数: 860\n"
     ]
    }
   ],
   "source": [
    "# 从训练集中划分出验证集\n",
    "train_size = 55000\n",
    "val_size = 5000\n",
    "# 设置随机种子以确保每次得到相同的随机划分结果\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "    train_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=generator #设置随机种子，确保每次得到相同的随机划分结果\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 打印数据集大小信息\n",
    "print(f\"训练集大小: {len(train_subset)}\")\n",
    "print(f\"验证集大小: {len(val_subset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n",
    "print(f\"批次大小: {batch_size}\")\n",
    "print(f\"训练批次数: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:19.257856Z",
     "start_time": "2025-07-01T02:13:19.253624Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7sBo1c63ZsN",
    "outputId": "4a2cecca-3eb1-4298-f751-d0096a5ccbeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55040"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.453555Z",
     "start_time": "2025-07-01T02:13:19.258864Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8P6pbv_3ZsN",
    "outputId": "e51a24bf-c492-430e-e83b-18295740d4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55000, 1, 28, 28])\n",
      "训练数据集均值: 0.2856\n",
      "训练数据集标准差: 0.3527\n",
      "数据集中图像总数: 55000\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_std(train_dataset):\n",
    "    # 首先将所有图像数据堆叠为一个大张量\n",
    "    all_images = torch.stack([img_tensor for img_tensor, _ in train_dataset])\n",
    "    print(all_images.shape)\n",
    "    # 计算通道维度上的均值和标准差\n",
    "    # Fashion MNIST是灰度图像，只有一个通道\n",
    "    # 对所有像素值计算均值和标准差\n",
    "    mean = torch.mean(all_images)\n",
    "    std = torch.std(all_images)\n",
    "\n",
    "    print(f\"训练数据集均值: {mean.item():.4f}\")\n",
    "    print(f\"训练数据集标准差: {std.item():.4f}\")\n",
    "\n",
    "    # 检查数据集大小\n",
    "    print(f\"数据集中图像总数: {len(train_dataset)}\")\n",
    "calculate_mean_std(train_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbHJFFlo3ZsN"
   },
   "source": [
    "# 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.460443Z",
     "start_time": "2025-07-01T02:13:22.454760Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0rQCiSI3ZsO",
    "outputId": "f82d312e-2414-456d-befa-0bbd3bd7c921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#理解每个接口的方法，单独写例子\n",
    "import torch.nn as nn\n",
    "m=nn.BatchNorm1d(100) # 创建一个批量归一化层，输入特征维度为100\n",
    "x=torch.randn(20,100) # 创建一个20行100列的随机张量\n",
    "print(m(x).shape) # 打印批量归一化后的张量形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.472504Z",
     "start_time": "2025-07-01T02:13:22.461448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([1, 3, 28, 28])\n",
      "输出形状: torch.Size([1, 16, 28, 28])\n",
      "标准卷积参数数量: 448\n",
      "深度可分离卷积参数数量: 94\n",
      "参数减少比例: 79.02%\n"
     ]
    }
   ],
   "source": [
    "class DepthwiseSeparableConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    深度可分离卷积模块\n",
    "    \n",
    "    参数:\n",
    "        in_channels: 输入通道数\n",
    "        out_channels: 输出通道数\n",
    "        kernel_size: 卷积核大小\n",
    "        stride: 步长，默认为1\n",
    "        padding: 填充，默认为0\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DepthwiseSeparableConv2d, self).__init__()\n",
    "        \n",
    "        # 深度卷积 - 每个输入通道使用一个卷积核\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels=in_channels, # 输入通道数\n",
    "            out_channels=in_channels, # 输出通道数\n",
    "            kernel_size=kernel_size, # 卷积核大小\n",
    "            stride=stride, # 步长\n",
    "            padding=padding, # 填充\n",
    "            groups=in_channels  # 分组卷积，每个输入通道单独卷积\n",
    "        )\n",
    "        \n",
    "        # 逐点卷积 - 使用1x1卷积进行通道融合\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 先进行深度卷积\n",
    "        x = self.depthwise(x)\n",
    "        # 再进行逐点卷积\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "# 测试深度可分离卷积\n",
    "input_tensor = torch.randn(1, 3, 28, 28)  # 批次大小为1，3个输入通道，28x28图像\n",
    "conv = DepthwiseSeparableConv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "output = conv(input_tensor)\n",
    "print(f\"输入形状: {input_tensor.shape}\")\n",
    "print(f\"输出形状: {output.shape}\")\n",
    "\n",
    "# 比较参数数量\n",
    "standard_conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "print(f\"标准卷积参数数量: {sum(p.numel() for p in standard_conv.parameters())}\")\n",
    "print(f\"深度可分离卷积参数数量: {sum(p.numel() for p in conv.parameters())}\")\n",
    "print(f\"参数减少比例: {1 - sum(p.numel() for p in conv.parameters()) / sum(p.numel() for p in standard_conv.parameters()):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.479664Z",
     "start_time": "2025-07-01T02:13:22.473508Z"
    },
    "id": "E2pNNuIN3ZsO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #normalize\n",
    "        self.transform = nn.Sequential(\n",
    "            transforms.Normalize([0.2856], [0.3527])\n",
    "        )\n",
    "\n",
    "        # 第一组卷积层 - 32个卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) # 输入通道数，输出通道数代表的是卷积核的个数\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 第二组卷积层 - 64个卷积核\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "        # 第三组卷积层 - 128个卷积核\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "        # 计算全连接层的输入特征数\n",
    "        # 经过3次池化，图像尺寸从28x28变为3x3x128\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "        # 初始化权重\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"使用 xavier 均匀分布来初始化卷积层和全连接层的权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape [batch size, 1, 28, 28]\n",
    "\n",
    "        # 第一组卷积层\n",
    "        x = F.selu(self.conv1(x))\n",
    "        # print(f\"conv1后的形状: {x.shape}\")\n",
    "        x = F.selu(self.conv2(x))\n",
    "        # print(f\"conv2后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool1后的形状: {x.shape}\")\n",
    "\n",
    "        # 第二组卷积层\n",
    "        x = F.selu(self.conv3(x))\n",
    "        # print(f\"conv3后的形状: {x.shape}\")\n",
    "        x = F.selu(self.conv4(x))\n",
    "        # print(f\"conv4后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool2后的形状: {x.shape}\")\n",
    "\n",
    "        # 第三组卷积层\n",
    "        x = F.selu(self.conv5(x))\n",
    "        # print(f\"conv5后的形状: {x.shape}\")\n",
    "        x = F.selu(self.conv6(x))\n",
    "        # print(f\"conv6后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool3后的形状: {x.shape}\")\n",
    "\n",
    "        # 展平\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(f\"展平后的形状: {x.shape}\")\n",
    "\n",
    "        # 全连接层\n",
    "        x = F.selu(self.fc1(x))\n",
    "        # print(f\"fc1后的形状: {x.shape}\")\n",
    "        x = self.fc2(x)\n",
    "        # print(f\"fc2后的形状: {x.shape}\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.515167Z",
     "start_time": "2025-07-01T02:13:22.479664Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYobn1gA3ZsO",
    "outputId": "aa5ea145-8be4-45ea-cf49-c303ee218778"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次图像形状: torch.Size([64, 1, 28, 28])\n",
      "批次标签形状: torch.Size([64])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# 从train_loader获取第一个批次的数据\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 查看批次数据的形状\n",
    "print(\"批次图像形状:\", images.shape)\n",
    "print(\"批次标签形状:\", labels.shape)\n",
    "\n",
    "\n",
    "print('-'*100)\n",
    "# 进行前向传播\n",
    "with torch.no_grad():  # 不需要计算梯度\n",
    "    outputs = model(images)\n",
    "\n",
    "\n",
    "print(outputs.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.521787Z",
     "start_time": "2025-07-01T02:13:22.516285Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4uABxd83ZsO",
    "outputId": "dd7db3e5-b464-477b-c550-749014e64d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要求梯度的参数总量: 584170\n",
      "模型总参数量: 584170\n",
      "\n",
      "各层参数量明细:\n",
      "conv1.weight: 288 参数\n",
      "conv1.bias: 32 参数\n",
      "conv2.weight: 9216 参数\n",
      "conv2.bias: 32 参数\n",
      "conv3.weight: 18432 参数\n",
      "conv3.bias: 64 参数\n",
      "conv4.weight: 36864 参数\n",
      "conv4.bias: 64 参数\n",
      "conv5.weight: 73728 参数\n",
      "conv5.bias: 128 参数\n",
      "conv6.weight: 147456 参数\n",
      "conv6.bias: 128 参数\n",
      "fc1.weight: 294912 参数\n",
      "fc1.bias: 256 参数\n",
      "fc2.weight: 2560 参数\n",
      "fc2.bias: 10 参数\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数量\n",
    "# 统计需要求梯度的参数总量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"需要求梯度的参数总量: {total_params}\")\n",
    "\n",
    "# 统计所有参数总量\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {all_params}\")\n",
    "\n",
    "# 查看每层参数量明细\n",
    "print(\"\\n各层参数量明细:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} 参数\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uYqakyJ3ZsO"
   },
   "source": [
    "# 各层参数量明细\n",
    "conv1.weight: 288 参数\n",
    "conv1.bias: 32 参数\n",
    "conv2.weight: 9216 参数\n",
    "conv2.bias: 32 参数\n",
    "conv3.weight: 18432 参数\n",
    "conv3.bias: 64 参数\n",
    "conv4.weight: 36864 参数\n",
    "conv4.bias: 64 参数\n",
    "conv5.weight: 73728 参数\n",
    "conv5.bias: 128 参数\n",
    "conv6.weight: 147456 参数\n",
    "conv6.bias: 128 参数\n",
    "fc1.weight: 294912 参数\n",
    "fc1.bias: 256 参数\n",
    "fc2.weight: 2560 参数\n",
    "fc2.bias: 10 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.547943Z",
     "start_time": "2025-07-01T02:13:22.523794Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IPp6ckG3ZsO",
    "outputId": "9ec717c4-854a-4381-c815-1eb6e49a1515"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 0.1044, -0.0078, -0.0549],\n",
       "                        [ 0.0379,  0.0221, -0.0053],\n",
       "                        [-0.0117, -0.0939,  0.0921]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0923, -0.0244, -0.0640],\n",
       "                        [ 0.0397,  0.0647, -0.0628],\n",
       "                        [-0.0634,  0.0640, -0.0038]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0879,  0.1009,  0.0268],\n",
       "                        [-0.1151, -0.0952,  0.0219],\n",
       "                        [ 0.1167, -0.0632,  0.0198]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0028,  0.0634,  0.0259],\n",
       "                        [ 0.0506,  0.0351,  0.0910],\n",
       "                        [ 0.0738, -0.1275,  0.1118]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0516, -0.0776, -0.0738],\n",
       "                        [-0.1229, -0.0775, -0.0156],\n",
       "                        [-0.0437, -0.0931, -0.0873]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1214, -0.1172,  0.0684],\n",
       "                        [ 0.1057, -0.0781, -0.1280],\n",
       "                        [ 0.0514, -0.0465, -0.0613]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1263,  0.1067, -0.0863],\n",
       "                        [-0.0362,  0.0784, -0.0507],\n",
       "                        [ 0.0593,  0.1046, -0.0870]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0530,  0.0983, -0.0994],\n",
       "                        [-0.0408, -0.1396, -0.0818],\n",
       "                        [-0.0352, -0.1063,  0.1214]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0589, -0.0559, -0.0852],\n",
       "                        [-0.1190, -0.0751,  0.0438],\n",
       "                        [-0.0367,  0.0814,  0.1316]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1243, -0.0649, -0.0343],\n",
       "                        [ 0.0892,  0.0290,  0.1022],\n",
       "                        [ 0.1119,  0.0581,  0.0919]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0561, -0.1296,  0.0363],\n",
       "                        [-0.0942,  0.0855,  0.1345],\n",
       "                        [-0.0267,  0.1248,  0.0205]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0670, -0.0581,  0.0585],\n",
       "                        [ 0.1160, -0.0793,  0.0166],\n",
       "                        [-0.0202,  0.0558, -0.0096]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1258, -0.0105, -0.0285],\n",
       "                        [ 0.0860, -0.0680, -0.0256],\n",
       "                        [-0.1286,  0.1194, -0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0283, -0.0030,  0.0710],\n",
       "                        [-0.0957, -0.0462, -0.0175],\n",
       "                        [-0.0011,  0.0928, -0.0021]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1253, -0.0420, -0.0750],\n",
       "                        [-0.0231, -0.1185, -0.1393],\n",
       "                        [ 0.0002, -0.0930, -0.1286]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174,  0.0154, -0.0329],\n",
       "                        [ 0.0686, -0.0016, -0.0886],\n",
       "                        [-0.0583,  0.0079,  0.0424]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0425,  0.0397, -0.1384],\n",
       "                        [-0.1002, -0.0485, -0.1241],\n",
       "                        [-0.0628,  0.1362, -0.1409]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1180,  0.1292, -0.1102],\n",
       "                        [-0.0840,  0.1183, -0.1138],\n",
       "                        [ 0.0068,  0.1034, -0.1314]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1381,  0.0756,  0.0475],\n",
       "                        [-0.0783,  0.1072, -0.0176],\n",
       "                        [ 0.1094,  0.0326,  0.0517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0249,  0.1140, -0.0859],\n",
       "                        [ 0.0714,  0.0731, -0.0828],\n",
       "                        [-0.1093,  0.0365,  0.1026]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1326,  0.0468,  0.0377],\n",
       "                        [-0.1391,  0.0714,  0.0706],\n",
       "                        [ 0.0014, -0.0896, -0.0638]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0787, -0.0803, -0.0023],\n",
       "                        [ 0.0020,  0.0454,  0.0454],\n",
       "                        [ 0.0719, -0.1113,  0.0840]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1198,  0.1237,  0.0065],\n",
       "                        [-0.0764, -0.1318,  0.0025],\n",
       "                        [-0.1136,  0.0696,  0.1127]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1085,  0.0228,  0.1094],\n",
       "                        [ 0.0774, -0.0335,  0.0925],\n",
       "                        [ 0.0966,  0.1219, -0.0177]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1241, -0.1153,  0.0382],\n",
       "                        [-0.0041,  0.0232, -0.0137],\n",
       "                        [-0.0275, -0.1325,  0.0128]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0380,  0.0467, -0.1131],\n",
       "                        [-0.0654,  0.0160,  0.0404],\n",
       "                        [-0.0352, -0.0512,  0.0414]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1208, -0.0452, -0.1074],\n",
       "                        [ 0.0549,  0.0881,  0.1105],\n",
       "                        [-0.0362,  0.0550,  0.0695]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1167,  0.0984, -0.0956],\n",
       "                        [-0.1071,  0.1036, -0.0031],\n",
       "                        [-0.1106, -0.1130,  0.0542]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1154, -0.0283, -0.0231],\n",
       "                        [ 0.1122,  0.0512, -0.0825],\n",
       "                        [ 0.0892, -0.0262, -0.0190]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1349,  0.0729, -0.0255],\n",
       "                        [ 0.0177,  0.1082,  0.1345],\n",
       "                        [-0.0115, -0.0279, -0.0966]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0479, -0.0520, -0.0120],\n",
       "                        [-0.0846, -0.1069,  0.0633],\n",
       "                        [-0.1418, -0.1188, -0.0646]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0203, -0.1180,  0.0447],\n",
       "                        [ 0.1039, -0.0007,  0.0747],\n",
       "                        [-0.0759,  0.0419,  0.0456]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-0.0485, -0.0268, -0.0650],\n",
       "                        [-0.0107,  0.0934, -0.0910],\n",
       "                        [ 0.0185, -0.0147,  0.0363]],\n",
       "              \n",
       "                       [[ 0.0187,  0.0792, -0.0786],\n",
       "                        [ 0.0319,  0.1001,  0.0745],\n",
       "                        [-0.0147, -0.0809,  0.0568]],\n",
       "              \n",
       "                       [[ 0.0705, -0.0313, -0.0144],\n",
       "                        [-0.0193, -0.0191, -0.0219],\n",
       "                        [-0.0553,  0.0586, -0.0884]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0406,  0.0052,  0.0454],\n",
       "                        [ 0.0529,  0.0585,  0.0256],\n",
       "                        [-0.0260,  0.0369, -0.0887]],\n",
       "              \n",
       "                       [[ 0.0074, -0.0431,  0.0685],\n",
       "                        [-0.0851, -0.0791,  0.0272],\n",
       "                        [-0.0030, -0.0112,  0.0596]],\n",
       "              \n",
       "                       [[ 0.0687, -0.0416, -0.0022],\n",
       "                        [-0.0226, -0.0444, -0.0735],\n",
       "                        [-0.0277,  0.0002,  0.0579]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0603,  0.1000, -0.0503],\n",
       "                        [ 0.0351,  0.0909,  0.0211],\n",
       "                        [-0.0447,  0.0009,  0.0012]],\n",
       "              \n",
       "                       [[ 0.0579,  0.0268,  0.0508],\n",
       "                        [-0.0663,  0.0806, -0.0169],\n",
       "                        [-0.0570,  0.0182,  0.0684]],\n",
       "              \n",
       "                       [[ 0.0061,  0.0174,  0.0427],\n",
       "                        [-0.0042,  0.0510,  0.0272],\n",
       "                        [ 0.0550, -0.0130,  0.0479]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0512,  0.1012, -0.0976],\n",
       "                        [ 0.0847, -0.0869,  0.0113],\n",
       "                        [ 0.0525,  0.0603, -0.0302]],\n",
       "              \n",
       "                       [[ 0.0680,  0.0090,  0.0589],\n",
       "                        [-0.0242,  0.0285,  0.0641],\n",
       "                        [-0.0107, -0.0627,  0.0655]],\n",
       "              \n",
       "                       [[ 0.0455, -0.0411, -0.0370],\n",
       "                        [-0.0020,  0.0807, -0.0420],\n",
       "                        [ 0.0580,  0.0387, -0.0776]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0186, -0.0727,  0.0069],\n",
       "                        [ 0.0573, -0.0945,  0.0055],\n",
       "                        [-0.0756,  0.0721,  0.0225]],\n",
       "              \n",
       "                       [[-0.0071, -0.0060,  0.0290],\n",
       "                        [ 0.0956,  0.0450, -0.0301],\n",
       "                        [ 0.0662, -0.0193, -0.0489]],\n",
       "              \n",
       "                       [[-0.0153,  0.0168, -0.0340],\n",
       "                        [-0.1018, -0.0290, -0.0685],\n",
       "                        [-0.0618, -0.0402, -0.0331]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0495,  0.0961, -0.0530],\n",
       "                        [-0.0881,  0.0158, -0.0782],\n",
       "                        [ 0.0887,  0.0185, -0.0197]],\n",
       "              \n",
       "                       [[-0.0581,  0.0931, -0.0378],\n",
       "                        [-0.0342, -0.0576, -0.0516],\n",
       "                        [ 0.0913, -0.0616, -0.0963]],\n",
       "              \n",
       "                       [[-0.0512,  0.0350, -0.0402],\n",
       "                        [ 0.0486, -0.0221, -0.0227],\n",
       "                        [-0.0665,  0.0697, -0.0105]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0127,  0.0365,  0.0552],\n",
       "                        [ 0.0278,  0.1003, -0.0845],\n",
       "                        [-0.0581, -0.0815, -0.0641]],\n",
       "              \n",
       "                       [[-0.0392,  0.0884,  0.0918],\n",
       "                        [ 0.0714,  0.0727, -0.0221],\n",
       "                        [ 0.0218,  0.0563,  0.0549]],\n",
       "              \n",
       "                       [[-0.0275, -0.0462, -0.0255],\n",
       "                        [ 0.0227, -0.0107, -0.0292],\n",
       "                        [ 0.0662, -0.0326, -0.0480]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0991,  0.0601, -0.0436],\n",
       "                        [-0.0576,  0.0790, -0.0311],\n",
       "                        [-0.0183, -0.0279,  0.0767]],\n",
       "              \n",
       "                       [[ 0.0828, -0.0231,  0.1010],\n",
       "                        [ 0.0043, -0.0561, -0.0479],\n",
       "                        [-0.0590,  0.0111, -0.0090]],\n",
       "              \n",
       "                       [[ 0.0487, -0.0319, -0.0683],\n",
       "                        [ 0.0373,  0.0070,  0.0209],\n",
       "                        [-0.0807, -0.1013, -0.0269]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0352, -0.0108,  0.0156],\n",
       "                        [-0.0214, -0.0405,  0.0704],\n",
       "                        [ 0.0457,  0.0424, -0.0236]],\n",
       "              \n",
       "                       [[-0.0668, -0.0813, -0.0213],\n",
       "                        [ 0.0346, -0.0576, -0.0537],\n",
       "                        [-0.0711,  0.0374, -0.0253]],\n",
       "              \n",
       "                       [[ 0.0404, -0.0515,  0.0893],\n",
       "                        [ 0.0723, -0.0308, -0.0278],\n",
       "                        [ 0.0423,  0.0788,  0.0674]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0956,  0.0289,  0.0548],\n",
       "                        [ 0.0225,  0.0137,  0.0285],\n",
       "                        [ 0.0254, -0.0876, -0.0694]],\n",
       "              \n",
       "                       [[-0.0445,  0.0145, -0.0578],\n",
       "                        [ 0.0077,  0.0048,  0.0408],\n",
       "                        [ 0.0013,  0.0241,  0.0685]],\n",
       "              \n",
       "                       [[ 0.0707, -0.0925,  0.0491],\n",
       "                        [ 0.0830,  0.0356, -0.0480],\n",
       "                        [-0.0793,  0.0785, -0.0866]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0488, -0.0010, -0.0572],\n",
       "                        [-0.0298, -0.0866, -0.0350],\n",
       "                        [-0.0479, -0.0562,  0.0785]],\n",
       "              \n",
       "                       [[ 0.0191,  0.0257,  0.0440],\n",
       "                        [-0.0500,  0.0677,  0.0664],\n",
       "                        [-0.0046, -0.0444, -0.0468]],\n",
       "              \n",
       "                       [[ 0.1010, -0.0148,  0.0710],\n",
       "                        [-0.0932,  0.0013,  0.1001],\n",
       "                        [-0.0240,  0.0029, -0.0864]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0686, -0.0604, -0.0604],\n",
       "                        [-0.0480,  0.0671,  0.0978],\n",
       "                        [ 0.0614,  0.0120, -0.0476]],\n",
       "              \n",
       "                       [[-0.0878,  0.0659,  0.0538],\n",
       "                        [ 0.0162, -0.0049, -0.0231],\n",
       "                        [ 0.0812, -0.0608,  0.0692]],\n",
       "              \n",
       "                       [[-0.0107,  0.0755,  0.0097],\n",
       "                        [-0.0412,  0.0840,  0.0776],\n",
       "                        [ 0.0261, -0.0387,  0.0592]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[-6.5966e-02,  7.1351e-02, -7.8433e-02],\n",
       "                        [-3.0760e-03, -1.1101e-02, -2.5036e-02],\n",
       "                        [-2.8828e-02, -5.5725e-02, -8.2757e-02]],\n",
       "              \n",
       "                       [[ 3.0986e-02, -5.3167e-02,  7.0837e-02],\n",
       "                        [-6.9071e-02, -7.1182e-02,  2.8227e-02],\n",
       "                        [ 1.4677e-02, -7.0943e-02, -4.6209e-03]],\n",
       "              \n",
       "                       [[ 1.0286e-02,  8.2232e-02, -8.9254e-03],\n",
       "                        [-4.3196e-02, -3.1031e-02, -5.6881e-02],\n",
       "                        [ 1.6009e-03,  4.1777e-02,  4.9375e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.8100e-02, -7.6601e-02,  3.1058e-02],\n",
       "                        [-4.3781e-02, -5.2341e-02, -1.4577e-02],\n",
       "                        [-5.5652e-02,  1.7058e-02,  8.0975e-02]],\n",
       "              \n",
       "                       [[-6.8590e-02, -2.6056e-03,  3.8721e-02],\n",
       "                        [-1.4961e-02, -6.2144e-02,  2.8983e-02],\n",
       "                        [ 6.5814e-02, -5.0574e-02, -8.0557e-02]],\n",
       "              \n",
       "                       [[ 7.8170e-02,  4.9197e-02, -4.5582e-02],\n",
       "                        [-4.4194e-02, -3.4608e-02, -2.2702e-02],\n",
       "                        [-8.1413e-02, -4.1957e-02, -3.3408e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.8925e-02, -2.6655e-02,  4.3584e-02],\n",
       "                        [ 7.5882e-02,  1.8079e-02, -3.5276e-02],\n",
       "                        [ 3.0103e-02,  1.9306e-02, -4.9793e-03]],\n",
       "              \n",
       "                       [[ 8.0830e-02,  3.5064e-02, -2.8238e-02],\n",
       "                        [-9.6722e-03,  2.8457e-02,  6.0474e-02],\n",
       "                        [ 3.6019e-02, -1.2625e-02,  6.8249e-02]],\n",
       "              \n",
       "                       [[-7.7394e-02,  6.1416e-02, -2.8427e-02],\n",
       "                        [ 3.4545e-02, -6.2318e-02,  1.2504e-02],\n",
       "                        [-4.3189e-02, -3.0372e-03,  4.2910e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.0815e-02, -5.6394e-02,  8.0648e-03],\n",
       "                        [-6.7014e-02, -6.9819e-02,  2.8074e-02],\n",
       "                        [-5.2479e-02,  2.5423e-02,  3.9720e-02]],\n",
       "              \n",
       "                       [[ 3.8358e-02, -4.7285e-02, -2.7096e-02],\n",
       "                        [ 7.8024e-02,  5.3408e-02,  1.0179e-02],\n",
       "                        [ 5.0584e-02, -2.5468e-02, -5.0536e-02]],\n",
       "              \n",
       "                       [[-3.5597e-02, -2.1103e-02, -6.7833e-02],\n",
       "                        [-3.9516e-02,  3.0297e-02,  3.9371e-02],\n",
       "                        [ 5.0867e-03, -6.1719e-02,  7.1819e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4995e-02,  2.7060e-02,  9.2450e-04],\n",
       "                        [ 3.6756e-02,  6.1037e-02,  6.6350e-02],\n",
       "                        [ 1.6896e-02, -1.0127e-02, -6.1315e-02]],\n",
       "              \n",
       "                       [[-3.2804e-02,  2.8070e-02,  2.1752e-02],\n",
       "                        [-8.1465e-02,  4.6147e-02,  9.5091e-04],\n",
       "                        [ 7.7959e-02,  4.3208e-02, -2.5694e-02]],\n",
       "              \n",
       "                       [[ 4.9159e-02,  3.1708e-02,  5.9529e-02],\n",
       "                        [-7.1355e-02,  3.9478e-02, -8.0137e-02],\n",
       "                        [ 5.9403e-02, -4.2795e-02, -7.2123e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.2046e-02,  2.3066e-02,  2.5587e-02],\n",
       "                        [-7.0750e-02, -2.2184e-02, -9.6491e-03],\n",
       "                        [ 1.5277e-02, -7.2919e-02,  6.0822e-02]],\n",
       "              \n",
       "                       [[-1.5198e-02,  7.4541e-02, -7.8958e-02],\n",
       "                        [ 2.2261e-02, -8.2108e-02, -6.3400e-02],\n",
       "                        [-1.8801e-02, -6.8404e-03, -2.8578e-02]],\n",
       "              \n",
       "                       [[-6.8144e-02,  6.4513e-02, -3.5780e-02],\n",
       "                        [-6.7783e-02,  7.6401e-02,  7.2496e-02],\n",
       "                        [-1.6686e-02,  3.3199e-02, -5.9112e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 9.3857e-03, -4.6290e-02, -1.8194e-03],\n",
       "                        [-1.6495e-02, -1.0045e-02, -5.8821e-02],\n",
       "                        [-2.0495e-02,  8.7637e-03,  4.7722e-02]],\n",
       "              \n",
       "                       [[-6.9127e-02,  5.1614e-02,  6.8833e-03],\n",
       "                        [-5.1885e-02, -2.7514e-02,  6.2911e-02],\n",
       "                        [-1.9172e-02, -7.6002e-02, -2.5912e-02]],\n",
       "              \n",
       "                       [[-3.7876e-02,  4.9600e-02,  6.3095e-02],\n",
       "                        [-3.7254e-04, -2.2849e-02,  7.3143e-04],\n",
       "                        [ 5.8474e-03,  9.4128e-03,  4.0934e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.8148e-02,  9.5311e-03,  1.2683e-02],\n",
       "                        [-2.7721e-02,  6.3140e-02, -7.4029e-02],\n",
       "                        [-3.5127e-02, -2.0509e-02, -5.9051e-03]],\n",
       "              \n",
       "                       [[-6.0959e-02,  8.1059e-03,  4.0755e-02],\n",
       "                        [ 6.7725e-02,  7.8453e-02,  5.6560e-02],\n",
       "                        [ 3.6079e-02,  7.8531e-02, -4.4105e-02]],\n",
       "              \n",
       "                       [[ 8.1060e-02, -1.3288e-02, -7.5813e-03],\n",
       "                        [ 3.9610e-02,  9.6450e-03,  1.4543e-02],\n",
       "                        [-2.9942e-03,  6.0542e-02,  4.7789e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.7480e-02,  6.9652e-02,  1.9431e-03],\n",
       "                        [ 7.9941e-03, -2.8713e-02,  4.5295e-02],\n",
       "                        [ 6.3429e-02,  1.3481e-02, -3.0527e-03]],\n",
       "              \n",
       "                       [[ 1.5518e-02, -7.2496e-02,  7.2074e-02],\n",
       "                        [-6.3194e-03, -3.4980e-02, -7.7907e-02],\n",
       "                        [ 4.1067e-02, -7.0225e-02,  1.3573e-02]],\n",
       "              \n",
       "                       [[ 3.0881e-02,  6.5605e-02,  6.1987e-02],\n",
       "                        [-3.3319e-03,  4.5545e-02, -7.9223e-02],\n",
       "                        [-7.8831e-02,  8.1846e-03, -2.6394e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3787e-02, -7.3260e-02,  5.3324e-02],\n",
       "                        [-7.8181e-02, -5.1153e-02,  5.7864e-02],\n",
       "                        [-3.4073e-02,  7.1205e-02, -2.8133e-05]],\n",
       "              \n",
       "                       [[-6.8773e-02, -6.8835e-02,  3.8222e-02],\n",
       "                        [ 1.4122e-03,  4.8025e-02,  6.0028e-02],\n",
       "                        [-7.9774e-02, -7.4561e-02,  1.6288e-02]],\n",
       "              \n",
       "                       [[ 4.7474e-02, -4.6641e-02,  1.7553e-02],\n",
       "                        [ 6.2587e-02, -6.8703e-02, -2.8480e-02],\n",
       "                        [ 1.4722e-02,  1.1388e-03,  5.8933e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.4979e-03,  7.9607e-02, -6.9783e-02],\n",
       "                        [ 5.1755e-02, -1.5925e-02,  6.0703e-02],\n",
       "                        [ 6.0785e-03, -5.0694e-02,  1.4878e-02]],\n",
       "              \n",
       "                       [[ 7.9980e-02, -9.3669e-04,  9.2857e-03],\n",
       "                        [-4.1359e-02, -2.8102e-02,  1.6205e-02],\n",
       "                        [ 3.5807e-02,  3.5971e-03, -1.1255e-02]],\n",
       "              \n",
       "                       [[ 9.4158e-03, -7.9923e-02, -7.9298e-02],\n",
       "                        [ 6.2084e-02, -4.8929e-02, -2.5499e-03],\n",
       "                        [ 4.5794e-02,  7.6247e-02,  6.0656e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.1267e-02,  4.3550e-02, -5.3729e-02],\n",
       "                        [ 4.7591e-02,  7.6610e-02, -3.9829e-02],\n",
       "                        [ 3.3310e-02, -1.4238e-02,  7.9083e-02]],\n",
       "              \n",
       "                       [[-5.7750e-02,  1.3814e-02,  3.4305e-02],\n",
       "                        [-7.0349e-02, -5.9818e-02, -6.0727e-02],\n",
       "                        [-5.7724e-02,  1.2989e-02,  5.6824e-02]],\n",
       "              \n",
       "                       [[ 8.4254e-03, -2.4690e-02, -6.3999e-02],\n",
       "                        [-5.2155e-02,  5.9659e-02,  3.6176e-02],\n",
       "                        [ 6.9877e-02, -4.3509e-02,  1.5837e-02]]]])),\n",
       "             ('conv3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv4.weight',\n",
       "              tensor([[[[-5.3111e-02,  1.4814e-02,  4.6897e-02],\n",
       "                        [-4.8118e-02, -5.5650e-03,  4.9331e-02],\n",
       "                        [ 1.9130e-02,  5.7268e-02, -2.6791e-02]],\n",
       "              \n",
       "                       [[-1.7733e-02,  6.4464e-02,  6.0128e-02],\n",
       "                        [ 2.6009e-02, -3.0148e-02, -2.1646e-02],\n",
       "                        [-6.8869e-02, -4.1767e-03,  6.3221e-02]],\n",
       "              \n",
       "                       [[-2.7954e-02,  6.3389e-02,  6.3923e-02],\n",
       "                        [ 3.0548e-02,  5.4256e-02,  3.7621e-02],\n",
       "                        [-1.5738e-03, -2.8280e-03,  1.8305e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.4805e-02, -3.0423e-02,  3.6172e-02],\n",
       "                        [ 6.1717e-02,  3.8945e-03,  2.9993e-02],\n",
       "                        [ 2.5037e-02,  7.1731e-02,  8.6985e-04]],\n",
       "              \n",
       "                       [[-3.3909e-02, -6.3953e-02,  2.4718e-02],\n",
       "                        [ 3.4763e-02,  6.0694e-02,  2.0035e-03],\n",
       "                        [ 8.2632e-03, -2.8442e-02,  1.3019e-02]],\n",
       "              \n",
       "                       [[-1.0096e-02, -1.9530e-02, -6.6941e-02],\n",
       "                        [-2.5070e-03, -5.2465e-02, -6.5278e-02],\n",
       "                        [ 4.4905e-02, -4.7334e-02, -1.8173e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3421e-02, -3.9285e-02,  3.0413e-02],\n",
       "                        [ 6.8801e-02, -1.7960e-02,  2.4834e-02],\n",
       "                        [-5.7373e-02, -6.1397e-02, -1.9618e-02]],\n",
       "              \n",
       "                       [[ 5.5902e-02, -1.9906e-02, -5.6829e-02],\n",
       "                        [ 4.4192e-02,  1.5184e-03, -1.3797e-02],\n",
       "                        [-5.0383e-02, -3.1062e-03,  9.5983e-03]],\n",
       "              \n",
       "                       [[ 3.3937e-02, -2.6149e-02,  6.9977e-02],\n",
       "                        [ 7.3540e-03,  6.6607e-02, -4.0173e-02],\n",
       "                        [ 7.0790e-02,  6.0867e-02, -2.3263e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.0957e-02, -2.6243e-02,  5.0229e-02],\n",
       "                        [ 7.0535e-02,  4.8430e-02, -3.9760e-03],\n",
       "                        [-1.5781e-02, -6.7019e-02,  5.2379e-03]],\n",
       "              \n",
       "                       [[ 2.2815e-02, -6.5348e-02, -4.0773e-03],\n",
       "                        [ 1.8053e-02,  8.1708e-03, -4.7709e-02],\n",
       "                        [ 1.4864e-02, -8.2476e-03,  6.8382e-02]],\n",
       "              \n",
       "                       [[-6.1244e-05,  2.0908e-02, -6.2065e-02],\n",
       "                        [-1.2382e-02,  5.6524e-02,  5.6469e-02],\n",
       "                        [ 7.2123e-02,  2.9532e-02, -5.0774e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.0179e-02,  5.1686e-02,  3.9855e-02],\n",
       "                        [ 4.7338e-02,  4.2613e-02,  5.8181e-02],\n",
       "                        [-1.0642e-02,  4.9784e-02, -4.2732e-02]],\n",
       "              \n",
       "                       [[-1.5779e-02, -6.7774e-02, -5.3993e-02],\n",
       "                        [ 4.5270e-03, -6.6944e-02,  8.6498e-04],\n",
       "                        [ 4.9693e-02,  1.2000e-02, -6.2045e-02]],\n",
       "              \n",
       "                       [[ 6.4217e-02, -4.8979e-02,  6.6079e-02],\n",
       "                        [ 2.1655e-02, -1.2064e-02,  3.4640e-02],\n",
       "                        [-4.9545e-02,  7.9707e-03,  6.1164e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.9065e-03, -1.8525e-02, -3.6511e-02],\n",
       "                        [-5.7384e-02, -1.2615e-02, -5.2020e-02],\n",
       "                        [-2.0575e-02,  3.1977e-02, -7.1480e-02]],\n",
       "              \n",
       "                       [[-3.5502e-02,  1.8899e-02, -7.5281e-03],\n",
       "                        [-1.8040e-02,  4.0321e-02, -4.2014e-02],\n",
       "                        [-6.6029e-02, -2.7651e-02, -6.8989e-03]],\n",
       "              \n",
       "                       [[ 1.3953e-02, -1.4100e-02,  5.0787e-02],\n",
       "                        [-1.3064e-03,  8.2813e-03,  2.0137e-02],\n",
       "                        [ 4.0004e-02, -6.7482e-03, -2.4017e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.3956e-02, -2.0984e-02, -6.2581e-02],\n",
       "                        [ 5.9860e-02, -4.5552e-02,  4.7835e-02],\n",
       "                        [-2.1939e-02,  6.1605e-04, -5.2071e-02]],\n",
       "              \n",
       "                       [[-8.8957e-03, -3.2488e-02,  3.0793e-02],\n",
       "                        [-3.9484e-02, -4.1610e-02,  7.9944e-03],\n",
       "                        [-2.9759e-02,  5.0785e-03,  4.1501e-02]],\n",
       "              \n",
       "                       [[-1.2086e-03,  4.1648e-02, -3.5490e-03],\n",
       "                        [-1.8788e-03,  6.7891e-02,  2.2461e-03],\n",
       "                        [ 6.8507e-02,  5.1110e-02, -2.8399e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7861e-02,  5.8756e-02, -3.5068e-03],\n",
       "                        [ 7.1666e-02, -3.9926e-02, -1.6452e-02],\n",
       "                        [ 5.4489e-02, -4.9263e-02,  6.7778e-02]],\n",
       "              \n",
       "                       [[ 2.9696e-02,  6.0465e-02, -5.5212e-02],\n",
       "                        [ 2.4881e-02, -6.5137e-02, -1.1670e-02],\n",
       "                        [ 6.1604e-02,  2.0839e-02, -5.8551e-02]],\n",
       "              \n",
       "                       [[-3.3091e-02, -6.1979e-02,  5.0351e-02],\n",
       "                        [-6.1535e-02, -2.4012e-02, -4.4771e-02],\n",
       "                        [ 4.0125e-02,  2.9035e-02, -3.9415e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4466e-02, -2.2573e-03, -3.1400e-02],\n",
       "                        [ 6.3170e-02, -7.0888e-02, -1.2104e-03],\n",
       "                        [-4.9606e-02, -5.7815e-02,  2.1889e-02]],\n",
       "              \n",
       "                       [[-7.0338e-02, -4.6095e-02, -1.2617e-02],\n",
       "                        [-3.0731e-02,  2.5139e-02, -1.4211e-02],\n",
       "                        [ 4.9545e-02, -6.8345e-02, -4.9197e-02]],\n",
       "              \n",
       "                       [[-4.5503e-02,  1.4063e-02,  5.5845e-02],\n",
       "                        [-2.2745e-02,  5.1483e-03,  5.6339e-02],\n",
       "                        [-8.1678e-03,  3.4947e-02,  1.4275e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9346e-02, -1.6768e-02, -2.1709e-02],\n",
       "                        [ 4.5033e-02, -4.1804e-03,  6.9362e-02],\n",
       "                        [ 1.8343e-02,  6.9200e-02, -1.1925e-02]],\n",
       "              \n",
       "                       [[-4.7058e-02,  7.6621e-03, -6.6381e-02],\n",
       "                        [-3.7027e-02,  4.8366e-02,  2.3544e-02],\n",
       "                        [-8.1874e-03,  6.0308e-03, -3.6933e-02]],\n",
       "              \n",
       "                       [[ 7.2919e-03,  7.0923e-02, -4.0766e-02],\n",
       "                        [ 3.2987e-02, -6.0247e-02, -2.3876e-03],\n",
       "                        [ 7.0976e-02,  4.0445e-02, -5.2789e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3675e-02,  3.0106e-02,  6.5947e-02],\n",
       "                        [-6.2321e-03, -3.8433e-02, -3.5787e-02],\n",
       "                        [-5.1338e-02,  1.8488e-02, -2.3875e-02]],\n",
       "              \n",
       "                       [[ 3.8639e-02,  2.1459e-02,  8.9769e-03],\n",
       "                        [ 3.9643e-02,  1.3917e-02,  6.1092e-03],\n",
       "                        [ 2.9627e-02, -3.1531e-02,  4.0986e-02]],\n",
       "              \n",
       "                       [[ 2.9965e-03, -2.0209e-02,  1.7717e-02],\n",
       "                        [-3.2637e-02, -3.6657e-02, -2.9403e-02],\n",
       "                        [-1.2678e-02, -5.0132e-02,  4.6837e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4362e-02, -1.2831e-02,  5.8947e-02],\n",
       "                        [ 6.4833e-03, -2.9994e-02,  5.8132e-02],\n",
       "                        [-5.4690e-02, -5.6284e-02,  8.8034e-03]],\n",
       "              \n",
       "                       [[ 3.8299e-02, -2.2643e-02,  5.5366e-02],\n",
       "                        [-1.4005e-02, -6.4643e-02,  3.3835e-02],\n",
       "                        [ 4.9836e-02,  6.1060e-04, -2.2214e-02]],\n",
       "              \n",
       "                       [[ 3.0109e-02,  4.9491e-02, -1.8883e-02],\n",
       "                        [-4.0812e-02,  1.8886e-02, -1.7893e-02],\n",
       "                        [ 1.7961e-02,  2.6603e-02, -5.8626e-02]]]])),\n",
       "             ('conv4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv5.weight',\n",
       "              tensor([[[[ 0.0183,  0.0055,  0.0271],\n",
       "                        [ 0.0066,  0.0409,  0.0241],\n",
       "                        [ 0.0122,  0.0005,  0.0195]],\n",
       "              \n",
       "                       [[ 0.0045,  0.0540,  0.0487],\n",
       "                        [ 0.0325,  0.0550, -0.0174],\n",
       "                        [ 0.0571,  0.0080,  0.0052]],\n",
       "              \n",
       "                       [[ 0.0278, -0.0309,  0.0352],\n",
       "                        [-0.0298, -0.0118,  0.0437],\n",
       "                        [ 0.0534, -0.0012, -0.0236]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0410, -0.0558,  0.0492],\n",
       "                        [-0.0548, -0.0429,  0.0485],\n",
       "                        [-0.0569, -0.0010,  0.0291]],\n",
       "              \n",
       "                       [[ 0.0324,  0.0381,  0.0352],\n",
       "                        [-0.0107, -0.0119, -0.0503],\n",
       "                        [ 0.0586, -0.0217,  0.0007]],\n",
       "              \n",
       "                       [[ 0.0174,  0.0466, -0.0204],\n",
       "                        [ 0.0118, -0.0305, -0.0373],\n",
       "                        [-0.0487,  0.0439,  0.0088]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0467, -0.0341,  0.0494],\n",
       "                        [ 0.0023,  0.0415, -0.0292],\n",
       "                        [-0.0053, -0.0114, -0.0540]],\n",
       "              \n",
       "                       [[ 0.0110,  0.0314,  0.0541],\n",
       "                        [-0.0144,  0.0388, -0.0045],\n",
       "                        [-0.0524,  0.0127, -0.0073]],\n",
       "              \n",
       "                       [[ 0.0310,  0.0183, -0.0444],\n",
       "                        [-0.0368,  0.0008,  0.0428],\n",
       "                        [ 0.0505, -0.0427, -0.0181]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0550,  0.0171,  0.0067],\n",
       "                        [ 0.0072,  0.0477, -0.0367],\n",
       "                        [ 0.0101,  0.0141, -0.0035]],\n",
       "              \n",
       "                       [[ 0.0021,  0.0428,  0.0546],\n",
       "                        [ 0.0469,  0.0125,  0.0115],\n",
       "                        [ 0.0451,  0.0059, -0.0238]],\n",
       "              \n",
       "                       [[-0.0557,  0.0412,  0.0529],\n",
       "                        [-0.0267,  0.0249,  0.0057],\n",
       "                        [ 0.0230, -0.0244, -0.0315]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0219, -0.0145,  0.0006],\n",
       "                        [-0.0038, -0.0049,  0.0331],\n",
       "                        [ 0.0247,  0.0397,  0.0507]],\n",
       "              \n",
       "                       [[-0.0579,  0.0194, -0.0509],\n",
       "                        [-0.0133, -0.0531, -0.0245],\n",
       "                        [ 0.0489, -0.0172,  0.0054]],\n",
       "              \n",
       "                       [[-0.0207,  0.0410, -0.0495],\n",
       "                        [-0.0356,  0.0045, -0.0318],\n",
       "                        [-0.0573,  0.0318, -0.0045]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0515, -0.0095,  0.0176],\n",
       "                        [-0.0025,  0.0471, -0.0028],\n",
       "                        [-0.0177,  0.0054,  0.0247]],\n",
       "              \n",
       "                       [[ 0.0307,  0.0468,  0.0090],\n",
       "                        [-0.0040, -0.0103, -0.0412],\n",
       "                        [ 0.0495,  0.0463, -0.0165]],\n",
       "              \n",
       "                       [[ 0.0177,  0.0466, -0.0454],\n",
       "                        [-0.0039, -0.0349,  0.0364],\n",
       "                        [-0.0029, -0.0148,  0.0403]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0482,  0.0299,  0.0363],\n",
       "                        [-0.0070,  0.0485,  0.0348],\n",
       "                        [-0.0064,  0.0011, -0.0337]],\n",
       "              \n",
       "                       [[-0.0586, -0.0421, -0.0184],\n",
       "                        [ 0.0518,  0.0578,  0.0407],\n",
       "                        [-0.0324, -0.0584,  0.0314]],\n",
       "              \n",
       "                       [[ 0.0461,  0.0371, -0.0284],\n",
       "                        [ 0.0005, -0.0349,  0.0524],\n",
       "                        [ 0.0071, -0.0432,  0.0077]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0426,  0.0086,  0.0157],\n",
       "                        [-0.0001,  0.0213,  0.0011],\n",
       "                        [ 0.0445, -0.0147, -0.0238]],\n",
       "              \n",
       "                       [[-0.0390,  0.0447, -0.0258],\n",
       "                        [-0.0454,  0.0063, -0.0467],\n",
       "                        [-0.0049, -0.0422, -0.0047]],\n",
       "              \n",
       "                       [[-0.0366, -0.0374,  0.0143],\n",
       "                        [ 0.0522,  0.0195, -0.0204],\n",
       "                        [-0.0367,  0.0159,  0.0041]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0393,  0.0473, -0.0543],\n",
       "                        [ 0.0104, -0.0091,  0.0020],\n",
       "                        [ 0.0181, -0.0273,  0.0386]],\n",
       "              \n",
       "                       [[-0.0033,  0.0002, -0.0531],\n",
       "                        [ 0.0491, -0.0441,  0.0177],\n",
       "                        [ 0.0514,  0.0472,  0.0495]],\n",
       "              \n",
       "                       [[ 0.0554, -0.0084,  0.0206],\n",
       "                        [ 0.0480,  0.0094, -0.0268],\n",
       "                        [-0.0447,  0.0418,  0.0218]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0330,  0.0189, -0.0146],\n",
       "                        [ 0.0586,  0.0205,  0.0374],\n",
       "                        [ 0.0394,  0.0201, -0.0011]],\n",
       "              \n",
       "                       [[ 0.0437, -0.0584,  0.0142],\n",
       "                        [ 0.0542,  0.0234, -0.0243],\n",
       "                        [ 0.0404,  0.0176,  0.0299]],\n",
       "              \n",
       "                       [[ 0.0533,  0.0279, -0.0382],\n",
       "                        [-0.0308,  0.0340,  0.0505],\n",
       "                        [ 0.0447, -0.0473,  0.0160]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0356,  0.0217, -0.0024],\n",
       "                        [-0.0019,  0.0030,  0.0024],\n",
       "                        [ 0.0309, -0.0093,  0.0302]],\n",
       "              \n",
       "                       [[ 0.0428,  0.0226,  0.0524],\n",
       "                        [-0.0534,  0.0209,  0.0244],\n",
       "                        [-0.0263, -0.0191, -0.0191]],\n",
       "              \n",
       "                       [[-0.0104, -0.0349, -0.0103],\n",
       "                        [ 0.0474,  0.0530,  0.0412],\n",
       "                        [ 0.0174, -0.0167,  0.0145]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0045, -0.0315, -0.0047],\n",
       "                        [ 0.0180, -0.0064,  0.0412],\n",
       "                        [ 0.0319,  0.0448,  0.0514]],\n",
       "              \n",
       "                       [[-0.0155, -0.0491,  0.0328],\n",
       "                        [-0.0044,  0.0364, -0.0218],\n",
       "                        [ 0.0402, -0.0447,  0.0271]],\n",
       "              \n",
       "                       [[-0.0023,  0.0588,  0.0034],\n",
       "                        [ 0.0163, -0.0343, -0.0080],\n",
       "                        [-0.0280,  0.0362, -0.0525]]]])),\n",
       "             ('conv5.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv6.weight',\n",
       "              tensor([[[[ 0.0160, -0.0393,  0.0437],\n",
       "                        [ 0.0393, -0.0068,  0.0200],\n",
       "                        [ 0.0135, -0.0224,  0.0213]],\n",
       "              \n",
       "                       [[-0.0306, -0.0183,  0.0250],\n",
       "                        [-0.0197,  0.0038,  0.0458],\n",
       "                        [-0.0044,  0.0170,  0.0357]],\n",
       "              \n",
       "                       [[ 0.0350, -0.0362, -0.0222],\n",
       "                        [ 0.0177,  0.0453,  0.0364],\n",
       "                        [-0.0351, -0.0354, -0.0220]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0428, -0.0304, -0.0195],\n",
       "                        [-0.0333,  0.0357,  0.0423],\n",
       "                        [-0.0306,  0.0095, -0.0228]],\n",
       "              \n",
       "                       [[-0.0128,  0.0112,  0.0390],\n",
       "                        [ 0.0203, -0.0185,  0.0288],\n",
       "                        [-0.0254, -0.0164, -0.0300]],\n",
       "              \n",
       "                       [[ 0.0435,  0.0329,  0.0089],\n",
       "                        [-0.0025,  0.0187, -0.0227],\n",
       "                        [-0.0422, -0.0126,  0.0086]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0135,  0.0126, -0.0119],\n",
       "                        [ 0.0488,  0.0215, -0.0155],\n",
       "                        [ 0.0268,  0.0442,  0.0090]],\n",
       "              \n",
       "                       [[ 0.0414,  0.0461,  0.0226],\n",
       "                        [ 0.0202,  0.0379,  0.0126],\n",
       "                        [ 0.0009,  0.0039, -0.0507]],\n",
       "              \n",
       "                       [[-0.0500,  0.0338,  0.0152],\n",
       "                        [ 0.0132,  0.0156,  0.0255],\n",
       "                        [ 0.0181, -0.0274,  0.0428]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0245,  0.0325,  0.0444],\n",
       "                        [ 0.0117, -0.0159, -0.0025],\n",
       "                        [-0.0285,  0.0150,  0.0180]],\n",
       "              \n",
       "                       [[-0.0158,  0.0186, -0.0103],\n",
       "                        [ 0.0166,  0.0110,  0.0432],\n",
       "                        [ 0.0191, -0.0272,  0.0327]],\n",
       "              \n",
       "                       [[-0.0225, -0.0098, -0.0350],\n",
       "                        [-0.0461, -0.0330, -0.0291],\n",
       "                        [ 0.0194, -0.0373, -0.0122]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0168, -0.0239, -0.0033],\n",
       "                        [-0.0061, -0.0327, -0.0428],\n",
       "                        [-0.0262,  0.0330, -0.0065]],\n",
       "              \n",
       "                       [[-0.0438, -0.0280, -0.0360],\n",
       "                        [ 0.0098,  0.0168, -0.0259],\n",
       "                        [ 0.0412, -0.0375, -0.0384]],\n",
       "              \n",
       "                       [[ 0.0420, -0.0354,  0.0071],\n",
       "                        [-0.0385,  0.0173,  0.0190],\n",
       "                        [ 0.0056, -0.0391, -0.0212]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0027, -0.0353, -0.0166],\n",
       "                        [-0.0128,  0.0311, -0.0214],\n",
       "                        [-0.0148, -0.0215, -0.0367]],\n",
       "              \n",
       "                       [[ 0.0116,  0.0056, -0.0374],\n",
       "                        [ 0.0068,  0.0219, -0.0458],\n",
       "                        [-0.0498,  0.0325,  0.0272]],\n",
       "              \n",
       "                       [[ 0.0276,  0.0408, -0.0094],\n",
       "                        [ 0.0031, -0.0145, -0.0161],\n",
       "                        [-0.0133,  0.0373, -0.0069]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0086,  0.0207,  0.0072],\n",
       "                        [ 0.0429,  0.0271, -0.0453],\n",
       "                        [ 0.0388,  0.0321, -0.0489]],\n",
       "              \n",
       "                       [[-0.0138,  0.0069, -0.0015],\n",
       "                        [ 0.0348, -0.0155,  0.0045],\n",
       "                        [-0.0189,  0.0489, -0.0476]],\n",
       "              \n",
       "                       [[ 0.0316, -0.0246,  0.0420],\n",
       "                        [ 0.0345,  0.0266, -0.0251],\n",
       "                        [-0.0396, -0.0192, -0.0313]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0158,  0.0382,  0.0196],\n",
       "                        [ 0.0394, -0.0244, -0.0125],\n",
       "                        [ 0.0413,  0.0074, -0.0394]],\n",
       "              \n",
       "                       [[ 0.0370, -0.0118, -0.0473],\n",
       "                        [ 0.0154,  0.0125, -0.0209],\n",
       "                        [-0.0149, -0.0415,  0.0269]],\n",
       "              \n",
       "                       [[-0.0370, -0.0276,  0.0040],\n",
       "                        [ 0.0447,  0.0023,  0.0289],\n",
       "                        [ 0.0485, -0.0226,  0.0476]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0469,  0.0388, -0.0399],\n",
       "                        [ 0.0071,  0.0329, -0.0106],\n",
       "                        [ 0.0496,  0.0035,  0.0105]],\n",
       "              \n",
       "                       [[-0.0157,  0.0416,  0.0111],\n",
       "                        [-0.0458,  0.0414,  0.0300],\n",
       "                        [-0.0317, -0.0315, -0.0416]],\n",
       "              \n",
       "                       [[-0.0466,  0.0035, -0.0352],\n",
       "                        [ 0.0146,  0.0044,  0.0393],\n",
       "                        [ 0.0360, -0.0190,  0.0137]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0476,  0.0275, -0.0387],\n",
       "                        [-0.0382,  0.0163, -0.0115],\n",
       "                        [-0.0061, -0.0072,  0.0505]],\n",
       "              \n",
       "                       [[ 0.0398, -0.0125, -0.0167],\n",
       "                        [ 0.0481, -0.0169, -0.0021],\n",
       "                        [ 0.0129, -0.0140,  0.0096]],\n",
       "              \n",
       "                       [[ 0.0172, -0.0106, -0.0256],\n",
       "                        [ 0.0031,  0.0468, -0.0207],\n",
       "                        [ 0.0113,  0.0401,  0.0291]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0356, -0.0274, -0.0275],\n",
       "                        [ 0.0339, -0.0344, -0.0213],\n",
       "                        [ 0.0138,  0.0336,  0.0312]],\n",
       "              \n",
       "                       [[-0.0130, -0.0036, -0.0196],\n",
       "                        [-0.0431, -0.0033, -0.0288],\n",
       "                        [ 0.0030, -0.0446,  0.0144]],\n",
       "              \n",
       "                       [[ 0.0224,  0.0418,  0.0103],\n",
       "                        [-0.0013,  0.0027,  0.0166],\n",
       "                        [ 0.0325, -0.0465, -0.0089]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0125,  0.0252,  0.0031],\n",
       "                        [ 0.0291,  0.0485, -0.0006],\n",
       "                        [-0.0250, -0.0432, -0.0149]],\n",
       "              \n",
       "                       [[-0.0258, -0.0392,  0.0444],\n",
       "                        [ 0.0111,  0.0037, -0.0166],\n",
       "                        [ 0.0203, -0.0459, -0.0232]],\n",
       "              \n",
       "                       [[ 0.0131, -0.0482, -0.0170],\n",
       "                        [-0.0485,  0.0498, -0.0270],\n",
       "                        [-0.0059,  0.0357,  0.0415]]]])),\n",
       "             ('conv6.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0545,  0.0189, -0.0615,  ..., -0.0206,  0.0133,  0.0029],\n",
       "                      [-0.0085, -0.0342,  0.0619,  ...,  0.0564,  0.0411,  0.0478],\n",
       "                      [-0.0609,  0.0005, -0.0153,  ..., -0.0207,  0.0048,  0.0316],\n",
       "                      ...,\n",
       "                      [-0.0129, -0.0463,  0.0064,  ...,  0.0400, -0.0531,  0.0316],\n",
       "                      [ 0.0073, -0.0463, -0.0397,  ...,  0.0641, -0.0083,  0.0082],\n",
       "                      [-0.0275,  0.0154,  0.0010,  ...,  0.0636, -0.0378, -0.0449]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0966, -0.0435, -0.0885,  ...,  0.1015,  0.0927, -0.1047],\n",
       "                      [ 0.0024, -0.1101, -0.0444,  ...,  0.0126, -0.0422, -0.0087],\n",
       "                      [ 0.0382, -0.1053,  0.0373,  ..., -0.0067, -0.0509, -0.1302],\n",
       "                      ...,\n",
       "                      [ 0.0820, -0.1367, -0.0311,  ..., -0.0949, -0.1328,  0.1266],\n",
       "                      [ 0.0397,  0.0374, -0.0198,  ...,  0.0174,  0.0649,  0.0410],\n",
       "                      [ 0.0463,  0.0526, -0.0514,  ..., -0.0766,  0.0185,  0.1001]])),\n",
       "             ('fc2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.665169Z",
     "start_time": "2025-07-01T02:13:22.548953Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class TensorboardLogger:\n",
    "    \"\"\"\n",
    "    Tensorboard日志记录类：记录训练过程中的损失和准确率\n",
    "    \n",
    "    参数:\n",
    "        log_dir: 日志保存目录,log_dir的父目录不要有中文\n",
    "    \"\"\"\n",
    "    def __init__(self, log_dir='tensorboard_logs'):\n",
    "\n",
    "        import os\n",
    "        \n",
    "        # 确保日志目录存在\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "            \n",
    "        self.writer = SummaryWriter(log_dir) # 实例化SummaryWriter, log_dir是log存放路径，flush_secs是每隔多少秒写入磁盘\n",
    "        \n",
    "    def log_training(self, epoch, train_loss, train_acc):\n",
    "        \"\"\"\n",
    "        记录训练数据\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            train_loss: 训练损失\n",
    "            train_acc: 训练准确率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('训练/损失', train_loss, epoch)\n",
    "        self.writer.add_scalar('训练/准确率', train_acc, epoch)\n",
    "        \n",
    "    def log_validation(self, epoch, val_loss, val_acc):\n",
    "        \"\"\"\n",
    "        记录验证数据\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            val_loss: 验证损失\n",
    "            val_acc: 验证准确率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('验证/损失', val_loss, epoch)\n",
    "        self.writer.add_scalar('验证/准确率', val_acc, epoch)\n",
    "    \n",
    "    def log_lr(self, epoch, lr):\n",
    "        \"\"\"\n",
    "        记录学习率\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            lr: 学习率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('学习率', lr, epoch)\n",
    "        \n",
    "    def log_model_graph(self, model, images):\n",
    "        \"\"\"\n",
    "        记录模型结构图\n",
    "        \n",
    "        参数:\n",
    "            model: 模型\n",
    "            images: 输入图像样本\n",
    "        \"\"\"\n",
    "        self.writer.add_graph(model, images)\n",
    "        \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        关闭Tensorboard写入器\n",
    "        \"\"\"\n",
    "        self.writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxWaF1Mj3ZsP"
   },
   "source": [
    "# 设置交叉熵损失函数，SGD优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.675661Z",
     "start_time": "2025-07-01T02:13:22.666177Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kd7ob0RW3ZsP",
    "outputId": "4b9530fb-4219-4f8d-e916-bbac479d045e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数，适用于多分类问题，里边会做softmax，还有会把0-9标签转换成one-hot编码\n",
    "\n",
    "print(\"损失函数:\", loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:13:22.684539Z",
     "start_time": "2025-07-01T02:13:22.676722Z"
    },
    "id": "V4JvZH5A3ZsP"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD优化器，学习率为0.01，动量为0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:17:15.133570Z",
     "start_time": "2025-07-01T02:13:22.685553Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "63674fd015574f7b9fda61005ee8a276",
      "3a9d6117a7084f32b4d5f541b895d0cf",
      "e01804ba087b440189e550b2f6b10b28",
      "128b78035bcf4f83919171cbe9412b3e",
      "06f695c1968746a38e68bb9ae2b78c9e",
      "6ede46a9351848ff94d1a6615974b200",
      "bf4d7d40e5444faa8de57cae717ee12c",
      "67752e508a9e4a55ba01d78f7eb24812",
      "dedc5721230f4939aceccee3c74dc76d",
      "f2baf5bc15974f42be322c0482ea5a02",
      "a61e350e0d134a4497b26b6120ce0931"
     ]
    },
    "id": "9ITLINaX3ZsP",
    "outputId": "f1f1d53b-621f-4586-f42a-33c8e48f3128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n",
      "训练开始，共43000步\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a707de3c6a46b28d6ad9cc3fb8da9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "早停触发! 最佳验证准确率(如果是回归，这里是损失): 88.3000\n",
      "早停: 在2100 步\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "model = model.to(device) #将模型移动到GPU\n",
    "early_stopping=EarlyStopping(patience=5, delta=0.001)\n",
    "model_saver=ModelSaver(save_dir='model_weights', save_best_only=True)\n",
    "tensorboard_logger=TensorboardLogger(log_dir='logs')\n",
    "\n",
    "model, history = train_classification_model(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=50, early_stopping=early_stopping, model_saver=model_saver, tensorboard_logger=tensorboard_logger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:17:15.151374Z",
     "start_time": "2025-07-01T02:17:15.135485Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHbISde23ZsP",
    "outputId": "24128833-3236-4ea7-a2a1-eb60880a58ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.22937209904193878, 'acc': 92.1875, 'step': 2001},\n",
       " {'loss': 0.34775739908218384, 'acc': 90.625, 'step': 2002},\n",
       " {'loss': 0.31689170002937317, 'acc': 87.5, 'step': 2003},\n",
       " {'loss': 0.34336090087890625, 'acc': 89.0625, 'step': 2004},\n",
       " {'loss': 0.27070340514183044, 'acc': 89.0625, 'step': 2005},\n",
       " {'loss': 0.2890358567237854, 'acc': 85.9375, 'step': 2006},\n",
       " {'loss': 0.2212531715631485, 'acc': 90.625, 'step': 2007},\n",
       " {'loss': 0.24080488085746765, 'acc': 90.625, 'step': 2008},\n",
       " {'loss': 0.2552148699760437, 'acc': 87.5, 'step': 2009},\n",
       " {'loss': 0.18686842918395996, 'acc': 92.1875, 'step': 2010},\n",
       " {'loss': 0.2623376250267029, 'acc': 90.625, 'step': 2011},\n",
       " {'loss': 0.2595924437046051, 'acc': 87.5, 'step': 2012},\n",
       " {'loss': 0.31547096371650696, 'acc': 85.9375, 'step': 2013},\n",
       " {'loss': 0.413108229637146, 'acc': 84.375, 'step': 2014},\n",
       " {'loss': 0.3884847164154053, 'acc': 87.5, 'step': 2015},\n",
       " {'loss': 0.24032583832740784, 'acc': 89.0625, 'step': 2016},\n",
       " {'loss': 0.4536895155906677, 'acc': 82.8125, 'step': 2017},\n",
       " {'loss': 0.22514699399471283, 'acc': 93.75, 'step': 2018},\n",
       " {'loss': 0.3132956027984619, 'acc': 92.1875, 'step': 2019},\n",
       " {'loss': 0.2623523771762848, 'acc': 84.375, 'step': 2020},\n",
       " {'loss': 0.30831584334373474, 'acc': 92.1875, 'step': 2021},\n",
       " {'loss': 0.2750956118106842, 'acc': 85.9375, 'step': 2022},\n",
       " {'loss': 0.32125693559646606, 'acc': 89.0625, 'step': 2023},\n",
       " {'loss': 0.2831844091415405, 'acc': 90.625, 'step': 2024},\n",
       " {'loss': 0.6398051381111145, 'acc': 84.375, 'step': 2025},\n",
       " {'loss': 0.1716320812702179, 'acc': 93.75, 'step': 2026},\n",
       " {'loss': 0.2992120087146759, 'acc': 90.625, 'step': 2027},\n",
       " {'loss': 0.3197309672832489, 'acc': 89.0625, 'step': 2028},\n",
       " {'loss': 0.28180041909217834, 'acc': 85.9375, 'step': 2029},\n",
       " {'loss': 0.29782164096832275, 'acc': 90.625, 'step': 2030},\n",
       " {'loss': 0.3431677222251892, 'acc': 85.9375, 'step': 2031},\n",
       " {'loss': 0.41144323348999023, 'acc': 84.375, 'step': 2032},\n",
       " {'loss': 0.15956835448741913, 'acc': 98.4375, 'step': 2033},\n",
       " {'loss': 0.38371631503105164, 'acc': 85.9375, 'step': 2034},\n",
       " {'loss': 0.2319851964712143, 'acc': 89.0625, 'step': 2035},\n",
       " {'loss': 0.23645693063735962, 'acc': 92.1875, 'step': 2036},\n",
       " {'loss': 0.2648390233516693, 'acc': 93.75, 'step': 2037},\n",
       " {'loss': 0.291426420211792, 'acc': 87.5, 'step': 2038},\n",
       " {'loss': 0.19692879915237427, 'acc': 92.1875, 'step': 2039},\n",
       " {'loss': 0.29484331607818604, 'acc': 85.9375, 'step': 2040},\n",
       " {'loss': 0.2868877947330475, 'acc': 87.5, 'step': 2041},\n",
       " {'loss': 0.2530163526535034, 'acc': 92.1875, 'step': 2042},\n",
       " {'loss': 0.19201312959194183, 'acc': 93.75, 'step': 2043},\n",
       " {'loss': 0.3233833611011505, 'acc': 85.9375, 'step': 2044},\n",
       " {'loss': 0.2782595455646515, 'acc': 90.625, 'step': 2045},\n",
       " {'loss': 0.2540184259414673, 'acc': 92.1875, 'step': 2046},\n",
       " {'loss': 0.3909778892993927, 'acc': 85.9375, 'step': 2047},\n",
       " {'loss': 0.20105554163455963, 'acc': 95.3125, 'step': 2048},\n",
       " {'loss': 0.2093001902103424, 'acc': 89.0625, 'step': 2049},\n",
       " {'loss': 0.3485557436943054, 'acc': 89.0625, 'step': 2050},\n",
       " {'loss': 0.3356945812702179, 'acc': 85.9375, 'step': 2051},\n",
       " {'loss': 0.3518086075782776, 'acc': 89.0625, 'step': 2052},\n",
       " {'loss': 0.47778719663619995, 'acc': 84.375, 'step': 2053},\n",
       " {'loss': 0.22930514812469482, 'acc': 90.625, 'step': 2054},\n",
       " {'loss': 0.34318533539772034, 'acc': 79.6875, 'step': 2055},\n",
       " {'loss': 0.2506832778453827, 'acc': 90.625, 'step': 2056},\n",
       " {'loss': 0.26738959550857544, 'acc': 90.625, 'step': 2057},\n",
       " {'loss': 0.4499279856681824, 'acc': 87.5, 'step': 2058},\n",
       " {'loss': 0.21437077224254608, 'acc': 90.625, 'step': 2059},\n",
       " {'loss': 0.2629167139530182, 'acc': 93.75, 'step': 2060},\n",
       " {'loss': 0.28834956884384155, 'acc': 89.0625, 'step': 2061},\n",
       " {'loss': 0.43881723284721375, 'acc': 87.5, 'step': 2062},\n",
       " {'loss': 0.34029239416122437, 'acc': 87.5, 'step': 2063},\n",
       " {'loss': 0.37480589747428894, 'acc': 87.5, 'step': 2064},\n",
       " {'loss': 0.5030387043952942, 'acc': 85.9375, 'step': 2065},\n",
       " {'loss': 0.21232973039150238, 'acc': 93.75, 'step': 2066},\n",
       " {'loss': 0.16392433643341064, 'acc': 95.3125, 'step': 2067},\n",
       " {'loss': 0.24706986546516418, 'acc': 90.625, 'step': 2068},\n",
       " {'loss': 0.3589794635772705, 'acc': 89.0625, 'step': 2069},\n",
       " {'loss': 0.34318026900291443, 'acc': 82.8125, 'step': 2070},\n",
       " {'loss': 0.3044722080230713, 'acc': 89.0625, 'step': 2071},\n",
       " {'loss': 0.30483564734458923, 'acc': 90.625, 'step': 2072},\n",
       " {'loss': 0.37735170125961304, 'acc': 85.9375, 'step': 2073},\n",
       " {'loss': 0.3676280975341797, 'acc': 87.5, 'step': 2074},\n",
       " {'loss': 0.27457430958747864, 'acc': 90.625, 'step': 2075},\n",
       " {'loss': 0.257428377866745, 'acc': 93.75, 'step': 2076},\n",
       " {'loss': 0.39826062321662903, 'acc': 84.375, 'step': 2077},\n",
       " {'loss': 0.2378573715686798, 'acc': 90.625, 'step': 2078},\n",
       " {'loss': 0.3988649845123291, 'acc': 84.375, 'step': 2079},\n",
       " {'loss': 0.2910851240158081, 'acc': 87.5, 'step': 2080},\n",
       " {'loss': 0.4055900573730469, 'acc': 85.9375, 'step': 2081},\n",
       " {'loss': 0.22450441122055054, 'acc': 90.625, 'step': 2082},\n",
       " {'loss': 0.48355409502983093, 'acc': 87.5, 'step': 2083},\n",
       " {'loss': 0.42003101110458374, 'acc': 85.9375, 'step': 2084},\n",
       " {'loss': 0.2221168428659439, 'acc': 93.75, 'step': 2085},\n",
       " {'loss': 0.12161749601364136, 'acc': 96.875, 'step': 2086},\n",
       " {'loss': 0.4325123131275177, 'acc': 84.375, 'step': 2087},\n",
       " {'loss': 0.22933189570903778, 'acc': 92.1875, 'step': 2088},\n",
       " {'loss': 0.2510395050048828, 'acc': 93.75, 'step': 2089},\n",
       " {'loss': 0.38120031356811523, 'acc': 87.5, 'step': 2090},\n",
       " {'loss': 0.3162629008293152, 'acc': 90.625, 'step': 2091},\n",
       " {'loss': 0.1866615116596222, 'acc': 95.3125, 'step': 2092},\n",
       " {'loss': 0.3363606035709381, 'acc': 90.625, 'step': 2093},\n",
       " {'loss': 0.23339180648326874, 'acc': 87.5, 'step': 2094},\n",
       " {'loss': 0.39395180344581604, 'acc': 85.9375, 'step': 2095},\n",
       " {'loss': 0.424650102853775, 'acc': 82.8125, 'step': 2096},\n",
       " {'loss': 0.44293081760406494, 'acc': 84.375, 'step': 2097},\n",
       " {'loss': 0.3033179044723511, 'acc': 85.9375, 'step': 2098},\n",
       " {'loss': 0.46048325300216675, 'acc': 89.0625, 'step': 2099}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['train'][-100:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f26vOoYl3ZsP"
   },
   "source": [
    "# 绘制损失曲线和准确率曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:17:15.389049Z",
     "start_time": "2025-07-01T02:17:15.154200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "4x1QPxe13ZsP",
    "outputId": "85a37d12-936d-4035-88d8-31edfab8ac61"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(history, sample_step=500)  #横坐标是 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T02:17:23.460309Z",
     "start_time": "2025-07-01T02:17:15.390142Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmMA8UFe3ZsP",
    "outputId": "36a5479d-8cfc-4ccd-d88e-2d0360525d05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.18, 0.32635277364253995)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在测试集上评估模型\n",
    "test_accuracy = evaluate_model(model, test_loader, device, loss_fn)\n",
    "test_accuracy\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06f695c1968746a38e68bb9ae2b78c9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "128b78035bcf4f83919171cbe9412b3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2baf5bc15974f42be322c0482ea5a02",
      "placeholder": "​",
      "style": "IPY_MODEL_a61e350e0d134a4497b26b6120ce0931",
      "value": " 11000/43000 [03:18&lt;08:21, 63.80it/s, epoch=12, loss=0.1496, acc=95.31%]"
     }
    },
    "3a9d6117a7084f32b4d5f541b895d0cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ede46a9351848ff94d1a6615974b200",
      "placeholder": "​",
      "style": "IPY_MODEL_bf4d7d40e5444faa8de57cae717ee12c",
      "value": " 26%"
     }
    },
    "63674fd015574f7b9fda61005ee8a276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a9d6117a7084f32b4d5f541b895d0cf",
       "IPY_MODEL_e01804ba087b440189e550b2f6b10b28",
       "IPY_MODEL_128b78035bcf4f83919171cbe9412b3e"
      ],
      "layout": "IPY_MODEL_06f695c1968746a38e68bb9ae2b78c9e"
     }
    },
    "67752e508a9e4a55ba01d78f7eb24812": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ede46a9351848ff94d1a6615974b200": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a61e350e0d134a4497b26b6120ce0931": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf4d7d40e5444faa8de57cae717ee12c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dedc5721230f4939aceccee3c74dc76d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e01804ba087b440189e550b2f6b10b28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67752e508a9e4a55ba01d78f7eb24812",
      "max": 43000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dedc5721230f4939aceccee3c74dc76d",
      "value": 11000
     }
    },
    "f2baf5bc15974f42be322c0482ea5a02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
